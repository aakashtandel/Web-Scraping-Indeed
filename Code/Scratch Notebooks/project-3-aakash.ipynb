{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title, and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use a random forest classifier, as well as another classifier of your choice; either logistic regression, SVM, or KNN. \n",
    "\n",
    "- **Question**: Why would we want this to be a classification problem?\n",
    "- **Answer**: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "The URL here has many query parameters\n",
    "- q for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- l for a location\n",
    "- start for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one result more closely. A single result looks like\n",
    "```JSON\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&campaignid=serp-linkcompanyname&fromjk=2480d203f7e97210&jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a nobr element inside of a td element with class='snip.\n",
    "- The title of a job is in a link with class set to jobtitle and a data-tn-element=\"jobTitle.\n",
    "- The location is set in a span with class='location'.\n",
    "- The company is set in a span with class='company'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#html = requests.get(URL)\n",
    "#b = BeautifulSoup(html.text)\n",
    "#print b.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# html = urllib.urlopen(url).read()\n",
    "# soup = BeautifulSoup(html, 'html.parser', from_encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_page(url):\n",
    "#     html = urllib.urlopen(url).read()\n",
    "#     return html\n",
    "#     #html = requests.get(ull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# html = requests.get(URL)\n",
    "# soup = BeautifulSoup(html)\n",
    "# df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "# for each in soup.findAll('div', {'class':\"  row  result\" }):\n",
    "#     try: \n",
    "#         title = each.find('hs', {'class':'jobtitle'}).text\n",
    "#         print title\n",
    "#     except:\n",
    "#         title = 'asdfdsafdsafdsa'\n",
    "#         print title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# soup = get_page(URL)\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def get_story(content):\n",
    "   # b = BeautifulSoup(html.text,'html.parser')\n",
    "   # return b.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for each in soup.findAll(class_='jobtitle'):\n",
    "#    print each.text\n",
    "\n",
    "# def get_job(contents):\n",
    "#     soup = BeautifulSoup(contents)\n",
    "#     title = []\n",
    "#     for each in soup.findAll(class_='jobtitle'):\n",
    "#         title.append(each.text.replace('\\n', ''))\n",
    "#     return title\n",
    "\n",
    "#def get_stories(content):\n",
    "    #soup = BeautifulSoup(content)\n",
    "    #titles = []\n",
    "\n",
    "   # for td in soup.findAll(\"td\", { \"class\":\"title\" }):\n",
    "       # a_element = td.find(\"a\")\n",
    "        #if a_element:\n",
    "            #titles.append(a_element.string)\n",
    "\n",
    "    #return titles    \n",
    "    #soup.find_all(class_='rest-row-name-text')   \n",
    "#soupp = soup.find_all(class_='jobtitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_job(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def job_find(section):\n",
    "#     try:\n",
    "#         soup.find(class_='jobtitle')\n",
    "#     except:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write 4 functions to extract these items (one function for each): location, company, job title, and salary.¶\n",
    "Example\n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "##### - Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    ">- Remember to check if a field is empty or None for attempting to call methods on it\n",
    ">- Remember to use try/except if you anticipate errors.\n",
    "\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Rithika suggested I merge all of the find_alls into one large function, so the code below was created with her assistance. \n",
    "\n",
    "def parse(url):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "    for each in soup.find_all(class_= \"result\" ):\n",
    "        try: \n",
    "            title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "        except:\n",
    "            title = 'None'\n",
    "        try:\n",
    "            location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "        except:\n",
    "            location = 'None'\n",
    "        try: \n",
    "            company = each.find(class_='company').text.replace('\\n', '')\n",
    "        except:\n",
    "            company = 'None'\n",
    "        try:\n",
    "            salary = each.find('span', {'class':'no-wrap'}).text\n",
    "        except:\n",
    "            salary = 'None'\n",
    "        synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "        df = df.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Big Data &amp; Analytics</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>None</td>\n",
       "      <td>KPMG is currently seeking a Data Scientist - B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>None</td>\n",
       "      <td>KPMG is currently seeking a Data Scientist to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientist - Business Process Modeling and Simu...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>AIG</td>\n",
       "      <td>None</td>\n",
       "      <td>AIG Science is the hub for decision sciences a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entry Level – Research Analyst/Editor/Content ...</td>\n",
       "      <td>New York, NY 10017 (Midtown area)</td>\n",
       "      <td>XG Consultants Group, Inc.</td>\n",
       "      <td>$15 an hour</td>\n",
       "      <td>Job Overview: XG Consultants Group is looking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Armonk, NY</td>\n",
       "      <td>IBM</td>\n",
       "      <td>None</td>\n",
       "      <td>Create tools for data ingestion and processing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>ITL USA</td>\n",
       "      <td>None</td>\n",
       "      <td>Infosys – Analytics – US - Senior Associate - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>MetroPlus Health Plan</td>\n",
       "      <td>$90,000 - $115,000 a year</td>\n",
       "      <td>The Data Scientist will be tasked with leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Blue State Digital</td>\n",
       "      <td>None</td>\n",
       "      <td>Use data to build a better world. You will be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Database Analyst, Junior</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NYU Langone Health</td>\n",
       "      <td>None</td>\n",
       "      <td>Collects and enters data into data registries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY 10012 (Little Italy area)</td>\n",
       "      <td>Meetup</td>\n",
       "      <td>None</td>\n",
       "      <td>3+ years working with data analytics, data war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>ThreatMetrix</td>\n",
       "      <td>None</td>\n",
       "      <td>As a Data Scientist, you’ll use data from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ipsos Behavioral Data Group - Behavioral Data ...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Ipsos North America</td>\n",
       "      <td>None</td>\n",
       "      <td>We are the Ipsos Behavioral Data Group. We’re ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior NLP Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Elevano</td>\n",
       "      <td>None</td>\n",
       "      <td>Parsing of structured/unstructured data. Our c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist | NYC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Avanade</td>\n",
       "      <td>None</td>\n",
       "      <td>Design, implement and deploy ETL to load data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Healthcare &amp; Life Sciences - Data Scientist</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>None</td>\n",
       "      <td>KPMG is currently seeking a Healthcare &amp; Life ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0               Data Scientist - Big Data & Analytics   \n",
       "1                                      Data Scientist   \n",
       "2   Scientist - Business Process Modeling and Simu...   \n",
       "3   Entry Level – Research Analyst/Editor/Content ...   \n",
       "4                           Machine Learning Engineer   \n",
       "5                            Associate Data Scientist   \n",
       "6                                      Data Scientist   \n",
       "7                                      Data Scientist   \n",
       "8                            Database Analyst, Junior   \n",
       "9                                      Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "11  Ipsos Behavioral Data Group - Behavioral Data ...   \n",
       "12                          Senior NLP Data Scientist   \n",
       "13                               Data Scientist | NYC   \n",
       "14        Healthcare & Life Sciences - Data Scientist   \n",
       "\n",
       "                                  Location                         Company  \\\n",
       "0                       New York, NY 10154                            KPMG   \n",
       "1                       New York, NY 10154                            KPMG   \n",
       "2                             New York, NY                             AIG   \n",
       "3        New York, NY 10017 (Midtown area)      XG Consultants Group, Inc.   \n",
       "4                               Armonk, NY                             IBM   \n",
       "5                             New York, NY                         ITL USA   \n",
       "6                             New York, NY           MetroPlus Health Plan   \n",
       "7                             New York, NY              Blue State Digital   \n",
       "8                             New York, NY              NYU Langone Health   \n",
       "9   New York, NY 10012 (Little Italy area)                          Meetup   \n",
       "10                            New York, NY                    ThreatMetrix   \n",
       "11                            New York, NY             Ipsos North America   \n",
       "12                            New York, NY                         Elevano   \n",
       "13                            New York, NY                         Avanade   \n",
       "14                      New York, NY 10154                            KPMG   \n",
       "\n",
       "                       Salary  \\\n",
       "0                        None   \n",
       "1                        None   \n",
       "2                        None   \n",
       "3                 $15 an hour   \n",
       "4                        None   \n",
       "5                        None   \n",
       "6   $90,000 - $115,000 a year   \n",
       "7                        None   \n",
       "8                        None   \n",
       "9                        None   \n",
       "10                       None   \n",
       "11                       None   \n",
       "12                       None   \n",
       "13                       None   \n",
       "14                       None   \n",
       "\n",
       "                                             Synopsis  \n",
       "0   KPMG is currently seeking a Data Scientist - B...  \n",
       "1   KPMG is currently seeking a Data Scientist to ...  \n",
       "2   AIG Science is the hub for decision sciences a...  \n",
       "3   Job Overview: XG Consultants Group is looking ...  \n",
       "4   Create tools for data ingestion and processing...  \n",
       "5   Infosys – Analytics – US - Senior Associate - ...  \n",
       "6   The Data Scientist will be tasked with leading...  \n",
       "7   Use data to build a better world. You will be ...  \n",
       "8   Collects and enters data into data registries ...  \n",
       "9   3+ years working with data analytics, data war...  \n",
       "10  As a Data Scientist, you’ll use data from the ...  \n",
       "11  We are the Ipsos Behavioral Data Group. We’re ...  \n",
       "12  Parsing of structured/unstructured data. Our c...  \n",
       "13  Design, implement and deploy ETL to load data ...  \n",
       "14  KPMG is currently seeking a Healthcare & Life ...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#html = requests.get(URL)\n",
    "#b = BeautifulSoup(html.text)\n",
    "#print b.prettify()\n",
    "#b is result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def extract_title(result):\n",
    "    #return [each.text.replace('\\n', '') for each in result.find_all(class_='jobtitle')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract_title(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_location(contents):\n",
    "#     soup = BeautifulSoup(contents)\n",
    "#     location = []\n",
    "#     for each in soup.findAll('span', {'class':\"location\" }):\n",
    "#         location.append(each.text.replace('\\n', ''))\n",
    "#     return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_location(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def extract_location(result):\n",
    "    #return [each.text for each in result.find_all('span', {'class':\"location\" })]\n",
    "#return [each.text for each in result.find_all('span', {'class':\"location\" })]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def extract_locationn(result):\n",
    "    #return [each.text for each in result.find_all('span', {'itemprop': 'addressLocality'})]\n",
    "#    locs = []\n",
    "#    for each in result.find_all('span', {'itemprop': 'addressLocality'}):\n",
    "#        if each.text:\n",
    "#            locs.append(each)\n",
    "#        else:\n",
    "#            locs.append('NaN')\n",
    "#    return locs\n",
    "    #return result.find_all('span', {'itemprop': 'addressLocality'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#locs = extract_location(b)\n",
    "#locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract_locationn(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_company(contents):\n",
    "#     soup = BeautifulSoup(contents)\n",
    "#     company = []\n",
    "#     for each in soup.find_all(class_='company'):\n",
    "#         company.append(each.text.replace('\\n', ''))\n",
    "#     return company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_company(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def extract_company(result):\n",
    "    #return [each.text.replace('\\n', '') for each in result.find_all(class_='company')]\n",
    "#return [each.text for each in result.find_all(class_='company')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#coms = extract_company(b)\n",
    "#coms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_salary(contents):\n",
    "#     soup = BeautifulSoup(contents)\n",
    "#     salary = []\n",
    "#     for each in soup:  \n",
    "#         try:\n",
    "#             a = soup.find_all('span', class_='no-wrap')\n",
    "#             salary.append(a.renderContents)\n",
    "#         except: \n",
    "#             salary.append('None')\n",
    "#     return salary\n",
    "       \n",
    "# def get_salary(contents):\n",
    "#     soup = BeautifulSoup(contents)\n",
    "#     salary = []\n",
    "#     for each in soup.findAll('div', {'class':\"  row  result\" }):\n",
    "#         try: \n",
    "#             soup.find('span', class_='no-wrap')\n",
    "#             salary.append(each.text)\n",
    "#         except: \n",
    "#             salary.append('NA')\n",
    "#     return salary\n",
    "    \n",
    "    \n",
    "    \n",
    "        #match = re.search('[+-]?[0-9]{1,3}(?:,?[0-9]{3})*(?:\\.[0-9]{2})?', each.text)\n",
    "        #if match:\n",
    "            #salary.append(match)\n",
    "        #elif mathc = each.findAll(r'', each.text)\n",
    "        #else:\n",
    "            #salary.append(None)\n",
    "    #return salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_salary(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def extract_salary(result):\n",
    "#     salaries = []\n",
    "#     for each in result.find_all('td', class_='snip'):\n",
    "#         match = re.find_all(r'[\\$][+-]?[0-9]{1,3}(?:,?[0-9]{3})*(?:\\.[0-9]{2})', each.text)\n",
    "#         if match:\n",
    "#             salaries.append(match)\n",
    "#         else:\n",
    "#             salaries.append(None)\n",
    "#     return salaries\n",
    "    #return [each.text.replace('\\n', '') for each in result.find_all(class_='snip')]\n",
    "\n",
    "#for booking in html.find_all('div', {'class':'booking'}):\n",
    "    # match all digits\n",
    "    #match = re.search(r'\\d+', booking.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract_salary(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the l=New+York and the start=10. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list).\n",
    "##### Complete the following code to collect results from multiple cities and starting points.\n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = 'Washington%2C+DC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1000 results. 13 of these aren't rubbish.\n",
      "You have 2000 results. 61 of these aren't rubbish.\n",
      "You have 3000 results. 66 of these aren't rubbish.\n",
      "You have 4000 results. 243 of these aren't rubbish.\n",
      "You have 5000 results. 432 of these aren't rubbish.\n",
      "You have 6000 results. 882 of these aren't rubbish.\n",
      "You have 7000 results. 1415 of these aren't rubbish.\n",
      "You have 8000 results. 1416 of these aren't rubbish.\n",
      "You have 9000 results. 1862 of these aren't rubbish.\n",
      "You have 10000 results. 2037 of these aren't rubbish.\n",
      "You have 11000 results. 2190 of these aren't rubbish.\n",
      "You have 12000 results. 2257 of these aren't rubbish.\n",
      "You have 13000 results. 2274 of these aren't rubbish.\n",
      "You have 14000 results. 2307 of these aren't rubbish.\n",
      "You have 15000 results. 2307 of these aren't rubbish.\n",
      "You have 16000 results. 2332 of these aren't rubbish.\n",
      "You have 17000 results. 2379 of these aren't rubbish.\n",
      "You have 18000 results. 2488 of these aren't rubbish.\n",
      "You have 19000 results. 2488 of these aren't rubbish.\n",
      "You have 20000 results. 2564 of these aren't rubbish.\n",
      "You have 21000 results. 2564 of these aren't rubbish.\n",
      "You have 22000 results. 2647 of these aren't rubbish.\n",
      "You have 23000 results. 2647 of these aren't rubbish.\n",
      "You have 24000 results. 3180 of these aren't rubbish.\n",
      "You have 25000 results. 3543 of these aren't rubbish.\n",
      "You have 26000 results. 3543 of these aren't rubbish.\n",
      "You have 27000 results. 3718 of these aren't rubbish.\n",
      "You have 28000 results. 3737 of these aren't rubbish.\n",
      "You have 29000 results. 3737 of these aren't rubbish.\n",
      "You have 30000 results. 3792 of these aren't rubbish.\n",
      "You have 31000 results. 3926 of these aren't rubbish.\n",
      "You have 32000 results. 3926 of these aren't rubbish.\n",
      "You have 33000 results. 3935 of these aren't rubbish.\n",
      "You have 34000 results. 4023 of these aren't rubbish.\n",
      "You have 35000 results. 4039 of these aren't rubbish.\n",
      "You have 36000 results. 4099 of these aren't rubbish.\n",
      "You have 37000 results. 4325 of these aren't rubbish.\n",
      "You have 38000 results. 4350 of these aren't rubbish.\n",
      "You have 39000 results. 4378 of these aren't rubbish.\n",
      "You have 40000 results. 4408 of these aren't rubbish.\n",
      "You have 41000 results. 4548 of these aren't rubbish.\n",
      "You have 42000 results. 4631 of these aren't rubbish.\n",
      "You have 43000 results. 4651 of these aren't rubbish.\n",
      "You have 44000 results. 4652 of these aren't rubbish.\n",
      "You have 45000 results. 4687 of these aren't rubbish.\n",
      "You have 46000 results. 4721 of these aren't rubbish.\n",
      "You have 47000 results. 4791 of these aren't rubbish.\n",
      "You have 48000 results. 4793 of these aren't rubbish.\n",
      "You have 49000 results. 4878 of these aren't rubbish.\n",
      "You have 50000 results. 4890 of these aren't rubbish.\n",
      "You have 51000 results. 4890 of these aren't rubbish.\n",
      "You have 52000 results. 4890 of these aren't rubbish.\n",
      "You have 53000 results. 4950 of these aren't rubbish.\n",
      "You have 54000 results. 4962 of these aren't rubbish.\n",
      "You have 55000 results. 4962 of these aren't rubbish.\n",
      "You have 56000 results. 4975 of these aren't rubbish.\n",
      "You have 57000 results. 5120 of these aren't rubbish.\n",
      "You have 58000 results. 5135 of these aren't rubbish.\n",
      "You have 59000 results. 5536 of these aren't rubbish.\n",
      "You have 60000 results. 5657 of these aren't rubbish.\n",
      "You have 61000 results. 5657 of these aren't rubbish.\n",
      "You have 62000 results. 5685 of these aren't rubbish.\n",
      "You have 63000 results. 5892 of these aren't rubbish.\n",
      "You have 64000 results. 5937 of these aren't rubbish.\n",
      "You have 65000 results. 6079 of these aren't rubbish.\n",
      "You have 66000 results. 6100 of these aren't rubbish.\n",
      "You have 67000 results. 6100 of these aren't rubbish.\n",
      "You have 68000 results. 6104 of these aren't rubbish.\n",
      "You have 69000 results. 6284 of these aren't rubbish.\n",
      "You have 70000 results. 6795 of these aren't rubbish.\n",
      "You have 71000 results. 6929 of these aren't rubbish.\n",
      "You have 72000 results. 7034 of these aren't rubbish.\n",
      "You have 73000 results. 7116 of these aren't rubbish.\n",
      "You have 74000 results. 7289 of these aren't rubbish.\n",
      "You have 75000 results. 7315 of these aren't rubbish.\n",
      "You have 76000 results. 7477 of these aren't rubbish.\n",
      "You have 77000 results. 7613 of these aren't rubbish.\n",
      "You have 78000 results. 7625 of these aren't rubbish.\n",
      "You have 79000 results. 7628 of these aren't rubbish.\n",
      "You have 80000 results. 7639 of these aren't rubbish.\n",
      "You have 81000 results. 7639 of these aren't rubbish.\n",
      "You have 82000 results. 7642 of these aren't rubbish.\n",
      "You have 83000 results. 7838 of these aren't rubbish.\n",
      "You have 84000 results. 8343 of these aren't rubbish.\n",
      "You have 85000 results. 8459 of these aren't rubbish.\n",
      "You have 86000 results. 8613 of these aren't rubbish.\n",
      "You have 87000 results. 8613 of these aren't rubbish.\n",
      "You have 88000 results. 8641 of these aren't rubbish.\n",
      "You have 89000 results. 8868 of these aren't rubbish.\n",
      "You have 90000 results. 8992 of these aren't rubbish.\n",
      "You have 91000 results. 8992 of these aren't rubbish.\n",
      "You have 92000 results. 9140 of these aren't rubbish.\n",
      "You have 93000 results. 9150 of these aren't rubbish.\n",
      "You have 94000 results. 9193 of these aren't rubbish.\n",
      "You have 95000 results. 9196 of these aren't rubbish.\n",
      "You have 96000 results. 9233 of these aren't rubbish.\n",
      "You have 97000 results. 9262 of these aren't rubbish.\n",
      "You have 98000 results. 9368 of these aren't rubbish.\n",
      "You have 99000 results. 9394 of these aren't rubbish.\n",
      "You have 100000 results. 9878 of these aren't rubbish.\n"
     ]
    }
   ],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 1000 # Set this to a high-value (5000) to generate more results. \n",
    "# Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "\n",
    "i = 0\n",
    "\n",
    "results = []\n",
    "df_more = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY, \n",
    "    'Charlottesville', 'Richmond', 'Baltimore', 'Harrisonburg', 'San+Antonio', 'San+Diego', 'San+Jose'\n",
    "    'Austin', 'Jacksonville', 'Indianapolis', 'Columbus', 'Fort+Worth', 'Charlotte', 'Detroit', 'El+Paso', \n",
    "    'Memphis', 'Boston', 'Nashville', 'Louisville', 'Milwaukee', 'Las+Vegas', 'Albuquerque', 'Tucson', \n",
    "    'Fresno', 'Sacramento', 'Long+Beach', 'Mesa', 'Virginia+Beach', 'Norfolk', 'Atlanta', 'Colorado+Springs',\n",
    "    'Raleigh', 'Omaha', 'Oakland', 'Tulsa', 'Minneapolis', 'Cleveland', 'Wichita', 'Arlington', 'New+Orleans', \n",
    "    'Bakersfield', 'Tampa', 'Honolulu', 'Anaheim', 'Aurora', 'Santa+Ana', 'Riverside', 'Corpus+Christi', 'Pittsburgh', \n",
    "    'Lexington', 'Anchorage', 'Cincinnati', 'Baton+Rouge', 'Chesapeake', 'Alexandria', 'Fairfax', 'Herndon',\n",
    "    'Reston', 'Roanoke']):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        url = url_template.format(city, start)\n",
    "        # Append to the full set of results\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        for each in soup.find_all(class_= \"result\" ):\n",
    "            try: \n",
    "                title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "            except:\n",
    "                title = None\n",
    "            try:\n",
    "                location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "            except:\n",
    "                location = None\n",
    "            try: \n",
    "                company = each.find(class_='company').text.replace('\\n', '')\n",
    "            except:\n",
    "                company = None\n",
    "            try:\n",
    "                salary = each.find('span', {'class':'no-wrap'}).text\n",
    "            except:\n",
    "                salary = None\n",
    "            try:\n",
    "                synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "            except:\n",
    "                synopsis = None\n",
    "            df_more = df_more.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis}, ignore_index=True)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:  # Ram helped me build this counter to see how many. You can visibly see Ram's vernacular in the print statements.\n",
    "                print('You have ' + str(i) + ' results. ' + str(df_more.dropna().drop_duplicates().shape[0]) + \" of these aren't rubbish.\")    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_more.to_csv('Indeed_Project_3_df_more_short.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more = pd.read_csv('/Users/aakashtandel/Desktop/Indeed_Project_3_df_more_short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100465, 6)"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7695, 6)"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more[df_more.Salary != 'None'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100460</th>\n",
       "      <td>100460</td>\n",
       "      <td>Manager/Sr. Manager, Diagnostics &amp; Biomarkers</td>\n",
       "      <td>Bothell, WA 98021</td>\n",
       "      <td>Seattle Genetics</td>\n",
       "      <td>None</td>\n",
       "      <td>In collaboration with Bioinformatics, Data Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100461</th>\n",
       "      <td>100461</td>\n",
       "      <td>Postdoctoral Research Scientist, Digital Anthr...</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>Oculus VR</td>\n",
       "      <td>None</td>\n",
       "      <td>3+ years experience with MAXQDA, Noldus Observ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100462</th>\n",
       "      <td>100462</td>\n",
       "      <td>Product Scientist</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>None</td>\n",
       "      <td>Work alongside other data scientists and softw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100463</th>\n",
       "      <td>100463</td>\n",
       "      <td>Data Scientist - Operations</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Redfin</td>\n",
       "      <td>None</td>\n",
       "      <td>As a Data Scientist, focused on our Brokerage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100464</th>\n",
       "      <td>100464</td>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Seattle, WA 98119</td>\n",
       "      <td>Big Fish Games</td>\n",
       "      <td>None</td>\n",
       "      <td>Understand and consume data from dimensional m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                              Title  \\\n",
       "100460      100460      Manager/Sr. Manager, Diagnostics & Biomarkers   \n",
       "100461      100461  Postdoctoral Research Scientist, Digital Anthr...   \n",
       "100462      100462                                  Product Scientist   \n",
       "100463      100463                        Data Scientist - Operations   \n",
       "100464      100464                                  Data Scientist II   \n",
       "\n",
       "                 Location               Company Salary  \\\n",
       "100460  Bothell, WA 98021      Seattle Genetics   None   \n",
       "100461        Redmond, WA             Oculus VR   None   \n",
       "100462        Seattle, WA                Indeed   None   \n",
       "100463        Seattle, WA                Redfin   None   \n",
       "100464  Seattle, WA 98119        Big Fish Games   None   \n",
       "\n",
       "                                                 Synopsis  \n",
       "100460  In collaboration with Bioinformatics, Data Man...  \n",
       "100461  3+ years experience with MAXQDA, Noldus Observ...  \n",
       "100462  Work alongside other data scientists and softw...  \n",
       "100463  As a Data Scientist, focused on our Brokerage ...  \n",
       "100464  Understand and consume data from dimensional m...  "
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.Salary.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Environmental Scientist</td>\n",
       "      <td>Blacksburg, VA</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>None</td>\n",
       "      <td>Environmental Scientist If you are an Environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systems Administrator</td>\n",
       "      <td>Forest, VA</td>\n",
       "      <td>Innerspec Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Manage backup and restore services to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>United States</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>None</td>\n",
       "      <td>Providing case management, data processing, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineering Specialist</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>You will work with a group of energized and fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title           Location  \\\n",
       "0          Environmental Scientist     Blacksburg, VA   \n",
       "1            Systems Administrator         Forest, VA   \n",
       "2                   Senior Manager      United States   \n",
       "3  Software Engineering Specialist  Roanoke, VA 24019   \n",
       "4       Sr Staff Software Engineer  Roanoke, VA 24019   \n",
       "\n",
       "                      Company Salary  \\\n",
       "0                 CyberCoders   None   \n",
       "1      Innerspec Technologies   None   \n",
       "2                    Exponent   None   \n",
       "3            General Electric   None   \n",
       "4            General Electric   None   \n",
       "\n",
       "                                            Synopsis  \n",
       "0  Environmental Scientist If you are an Environm...  \n",
       "1  Manage backup and restore services to ensure t...  \n",
       "2  Providing case management, data processing, an...  \n",
       "3  You will work with a group of energized and fo...  \n",
       "4  Architects, Data Scientists, Businesses & Prod...  "
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.drop_duplicates of                                                     Title  \\\n",
       "0                                 Environmental Scientist   \n",
       "1                                   Systems Administrator   \n",
       "2                                          Senior Manager   \n",
       "3                         Software Engineering Specialist   \n",
       "4                              Sr Staff Software Engineer   \n",
       "5                                 Staff Software Engineer   \n",
       "6       Pharmaceutical Sales Specialist -- Hospital Ca...   \n",
       "7                  Staff Software Engineer - UI Front End   \n",
       "8       Senior Software Engineer - Python (relo required)   \n",
       "9                       Russian Linguist/Research Analyst   \n",
       "10                       Senior Control Engineer, LabVIEW   \n",
       "11      Occupational Medicine Consultant (Relocation t...   \n",
       "12              Marketing Integration & Opportunity (MIO)   \n",
       "13                                  Systems Administrator   \n",
       "14                                         Senior Manager   \n",
       "15                        Software Engineering Specialist   \n",
       "16                             Sr Staff Software Engineer   \n",
       "17                                Staff Software Engineer   \n",
       "18      Pharmaceutical Sales Specialist -- Hospital Ca...   \n",
       "19                 Staff Software Engineer - UI Front End   \n",
       "20                                Environmental Scientist   \n",
       "21                      Russian Linguist/Research Analyst   \n",
       "22      Senior Software Engineer - Python (relo required)   \n",
       "23                       Senior Control Engineer, LabVIEW   \n",
       "24      Occupational Medicine Consultant (Relocation t...   \n",
       "25              Marketing Integration & Opportunity (MIO)   \n",
       "26                                  Systems Administrator   \n",
       "27                                         Senior Manager   \n",
       "28                        Software Engineering Specialist   \n",
       "29                             Sr Staff Software Engineer   \n",
       "...                                                   ...   \n",
       "100435                                  Data Scientist II   \n",
       "100436                           Principal Data Scientist   \n",
       "100437                                  Product Scientist   \n",
       "100438                  Part-time Data Science Instructor   \n",
       "100439         Data Visualization Tools Engineer- Seattle   \n",
       "100440                 Scientific Data Engineer - Level I   \n",
       "100441                           Data Analyst (Marketing)   \n",
       "100442                       SR PRODUCT MARKETING MANAGER   \n",
       "100443                          EPIC CORE SYSTEMS MANAGER   \n",
       "100444                      RS/E 3-FIELD SERVICE ENGINEER   \n",
       "100445  Software Development Engineer III, AWS Machine...   \n",
       "100446                            Data Science Instructor   \n",
       "100447                                  Sr. Data Engineer   \n",
       "100448                                     Data Scientist   \n",
       "100449                        Data Scientist - Operations   \n",
       "100450                                     Data Scientist   \n",
       "100451                           Principal Data Scientist   \n",
       "100452                            Data Science Instructor   \n",
       "100453  Postdoctoral Research Scientist, Perceptual Hu...   \n",
       "100454                Software Engineer: Machine Learning   \n",
       "100455  senior product designer, Digital Products, Sta...   \n",
       "100456                                     Data Scientist   \n",
       "100457                            Data Scientist (Growth)   \n",
       "100458                                  Sr. Data Engineer   \n",
       "100459  Postdoctoral Research Scientist, Perceptual Hu...   \n",
       "100460      Manager/Sr. Manager, Diagnostics & Biomarkers   \n",
       "100461  Postdoctoral Research Scientist, Digital Anthr...   \n",
       "100462                                  Product Scientist   \n",
       "100463                        Data Scientist - Operations   \n",
       "100464                                  Data Scientist II   \n",
       "\n",
       "                                                 Location  \\\n",
       "0                                          Blacksburg, VA   \n",
       "1                                              Forest, VA   \n",
       "2                                           United States   \n",
       "3                                       Roanoke, VA 24019   \n",
       "4                                       Roanoke, VA 24019   \n",
       "5                                       Roanoke, VA 24019   \n",
       "6                                             Roanoke, VA   \n",
       "7                                       Roanoke, VA 24019   \n",
       "8                                           United States   \n",
       "9                                                Virginia   \n",
       "10                                          United States   \n",
       "11                                          United States   \n",
       "12                                          United States   \n",
       "13                                             Forest, VA   \n",
       "14                                          United States   \n",
       "15                                      Roanoke, VA 24019   \n",
       "16                                      Roanoke, VA 24019   \n",
       "17                                      Roanoke, VA 24019   \n",
       "18                                            Roanoke, VA   \n",
       "19                                      Roanoke, VA 24019   \n",
       "20                                         Blacksburg, VA   \n",
       "21                                               Virginia   \n",
       "22                                          United States   \n",
       "23                                          United States   \n",
       "24                                          United States   \n",
       "25                                          United States   \n",
       "26                                             Forest, VA   \n",
       "27                                          United States   \n",
       "28                                      Roanoke, VA 24019   \n",
       "29                                      Roanoke, VA 24019   \n",
       "...                                                   ...   \n",
       "100435                                  Seattle, WA 98119   \n",
       "100436                                  Seattle, WA 98101   \n",
       "100437                                        Seattle, WA   \n",
       "100438                  Seattle, WA 98121 (Belltown area)   \n",
       "100439                                        Seattle, WA   \n",
       "100440  Seattle, WA 98103 (Green Lake - Wallingford area)   \n",
       "100441                                        Seattle, WA   \n",
       "100442                                  Redmond, WA 98052   \n",
       "100443                                        Seattle, WA   \n",
       "100444                                        Seattle, WA   \n",
       "100445                                        Seattle, WA   \n",
       "100446                  Seattle, WA 98121 (Belltown area)   \n",
       "100447                 Bellevue, WA 98004 (Downtown area)   \n",
       "100448                                  Seattle, WA 98104   \n",
       "100449                                        Seattle, WA   \n",
       "100450                                  Seattle, WA 98104   \n",
       "100451                                  Seattle, WA 98101   \n",
       "100452                  Seattle, WA 98121 (Belltown area)   \n",
       "100453                                        Redmond, WA   \n",
       "100454                                       Bellevue, WA   \n",
       "100455       Seattle, WA 98134 (Industrial District area)   \n",
       "100456                                       Bellevue, WA   \n",
       "100457                                       Bellevue, WA   \n",
       "100458                 Bellevue, WA 98004 (Downtown area)   \n",
       "100459                                        Redmond, WA   \n",
       "100460                                  Bothell, WA 98021   \n",
       "100461                                        Redmond, WA   \n",
       "100462                                        Seattle, WA   \n",
       "100463                                        Seattle, WA   \n",
       "100464                                  Seattle, WA 98119   \n",
       "\n",
       "                                            Company Salary  \\\n",
       "0                                       CyberCoders   None   \n",
       "1                            Innerspec Technologies   None   \n",
       "2                                          Exponent   None   \n",
       "3                                  General Electric   None   \n",
       "4                                  General Electric   None   \n",
       "5                                  General Electric   None   \n",
       "6                                       AstraZeneca   None   \n",
       "7                                  General Electric   None   \n",
       "8                             Spoken Communications   None   \n",
       "9                                 Centra Technology   None   \n",
       "10                                 Tri Alpha Energy   None   \n",
       "11                                     Saudi Aramco   None   \n",
       "12                                            Yahoo   None   \n",
       "13                           Innerspec Technologies   None   \n",
       "14                                         Exponent   None   \n",
       "15                                 General Electric   None   \n",
       "16                                 General Electric   None   \n",
       "17                                 General Electric   None   \n",
       "18                                      AstraZeneca   None   \n",
       "19                                 General Electric   None   \n",
       "20                                      CyberCoders   None   \n",
       "21                                Centra Technology   None   \n",
       "22                            Spoken Communications   None   \n",
       "23                                 Tri Alpha Energy   None   \n",
       "24                                     Saudi Aramco   None   \n",
       "25                                            Yahoo   None   \n",
       "26                           Innerspec Technologies   None   \n",
       "27                                         Exponent   None   \n",
       "28                                 General Electric   None   \n",
       "29                                 General Electric   None   \n",
       "...                                             ...    ...   \n",
       "100435                               Big Fish Games   None   \n",
       "100436                                       Zillow   None   \n",
       "100437                                       Indeed   None   \n",
       "100438                             General Assembly   None   \n",
       "100439                                     Zymergen   None   \n",
       "100440                              Allen Institute   None   \n",
       "100441                                      Coupang   None   \n",
       "100442                                    Microsoft   None   \n",
       "100443                     University of Washington   None   \n",
       "100444      University of Washington Medical Center   None   \n",
       "100445                         Amazon Corporate LLC   None   \n",
       "100446                             General Assembly   None   \n",
       "100447                          Vega Consulting LLC   None   \n",
       "100448                                         KPMG   None   \n",
       "100449                                       Redfin   None   \n",
       "100450                                         KPMG   None   \n",
       "100451                                       Zillow   None   \n",
       "100452                             General Assembly   None   \n",
       "100453                                     Facebook   None   \n",
       "100454                                    Postmates   None   \n",
       "100455                                    Starbucks   None   \n",
       "100456                                    Postmates   None   \n",
       "100457                                    Postmates   None   \n",
       "100458                          Vega Consulting LLC   None   \n",
       "100459                                    Oculus VR   None   \n",
       "100460                             Seattle Genetics   None   \n",
       "100461                                    Oculus VR   None   \n",
       "100462                                       Indeed   None   \n",
       "100463                                       Redfin   None   \n",
       "100464                               Big Fish Games   None   \n",
       "\n",
       "                                                 Synopsis  \n",
       "0       Environmental Scientist If you are an Environm...  \n",
       "1       Manage backup and restore services to ensure t...  \n",
       "2       Providing case management, data processing, an...  \n",
       "3       You will work with a group of energized and fo...  \n",
       "4       Architects, Data Scientists, Businesses & Prod...  \n",
       "5       Architects, Data Scientists, Businesses & Prod...  \n",
       "6       Experience working with Medical Information Sc...  \n",
       "7       Architects, Data Scientists, Businesses & Prod...  \n",
       "8       You'll find yourself collaborating with world-...  \n",
       "9       CENTRA Technology, Inc. has an immediate openi...  \n",
       "10      Networking using Ethernet, EtherNet/IP, Data D...  \n",
       "11      Analyze and interpret statistical data for eva...  \n",
       "12      We strive for industry-leading work in a diver...  \n",
       "13      Manage backup and restore services to ensure t...  \n",
       "14      Providing case management, data processing, an...  \n",
       "15      You will work with a group of energized and fo...  \n",
       "16      Architects, Data Scientists, Businesses & Prod...  \n",
       "17      Architects, Data Scientists, Businesses & Prod...  \n",
       "18      Experience working with Medical Information Sc...  \n",
       "19      Architects, Data Scientists, Businesses & Prod...  \n",
       "20      Environmental Scientist If you are an Environm...  \n",
       "21      CENTRA Technology, Inc. has an immediate openi...  \n",
       "22      You'll find yourself collaborating with world-...  \n",
       "23      Networking using Ethernet, EtherNet/IP, Data D...  \n",
       "24      Analyze and interpret statistical data for eva...  \n",
       "25      We strive for industry-leading work in a diver...  \n",
       "26      Manage backup and restore services to ensure t...  \n",
       "27      Providing case management, data processing, an...  \n",
       "28      You will work with a group of energized and fo...  \n",
       "29      Architects, Data Scientists, Businesses & Prod...  \n",
       "...                                                   ...  \n",
       "100435  Understand and consume data from dimensional m...  \n",
       "100436  Experience mentoring/leading other data scient...  \n",
       "100437  Work alongside other data scientists and softw...  \n",
       "100438  Python, Machine Learning, Probability, Statist...  \n",
       "100439  Data Visualization Tools Engineer. You will be...  \n",
       "100440  They will additionally support integration of ...  \n",
       "100441  Dive deep into Coupang’s customer demographic ...  \n",
       "100442  In this highly visible role, you will define a...  \n",
       "100443  Epic User Access and Security, Epic Environmen...  \n",
       "100444  Communications/networking, electromagnetics/re...  \n",
       "100445  Experience with data mining tools and techniqu...  \n",
       "100446  We are looking for a Data Scientist to teach o...  \n",
       "100447  Experience in data modeling and transformation...  \n",
       "100448  Retrieve, process and prepare a rich data vari...  \n",
       "100449  As a Data Scientist, focused on our Brokerage ...  \n",
       "100450  Retrieve, process and prepare a rich data vari...  \n",
       "100451  Experience mentoring/leading other data scient...  \n",
       "100452  We are looking for a Data Scientist to teach o...  \n",
       "100453  As a Post-doctoral Research Scientist, you wil...  \n",
       "100454  You’ll also ensure that data is easy to access...  \n",
       "100455  Work with data scientists and user researchers...  \n",
       "100456  As a Data Scientist, you will help us unlock i...  \n",
       "100457  As a Growth Marketing Data Scientist you will ...  \n",
       "100458  Experience in data modeling and transformation...  \n",
       "100459  As a Post-doctoral Research Scientist, you wil...  \n",
       "100460  In collaboration with Bioinformatics, Data Man...  \n",
       "100461  3+ years experience with MAXQDA, Noldus Observ...  \n",
       "100462  Work alongside other data scientists and softw...  \n",
       "100463  As a Data Scientist, focused on our Brokerage ...  \n",
       "100464  Understand and consume data from dimensional m...  \n",
       "\n",
       "[100465 rows x 5 columns]>"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100465, 5)"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# indeed_frame = pd.DataFrame(columns=[\"title\",\"location\",\"company\",\"salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# title = []\n",
    "# location = []\n",
    "# company = []\n",
    "# salary = []\n",
    "# for each in results:\n",
    "#     title.append(extract_title(each))\n",
    "#     location.append(extract_location(each))\n",
    "#     company.append(extract_company(each))\n",
    "#     salary.append(extract_salary(each))\n",
    "# #dc_eats.loc[len(dc_eats)]=[name, location, compay, bookings]\n",
    "# indeed_frame = {'title':title, 'location':location, 'company':company, 'salary':salary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# indeed_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "# def parser(url):\n",
    "#     for each in url.find_all('div', {'class':'  row  result'}):\n",
    "#         titlee = each.find_all(class_='jobtitle')\n",
    "#         title = titlee.text.replace('\\n', '')\n",
    "#         locationn = result.find_all('span', {'class':\"location\" })\n",
    "#         location = locationn.text\n",
    "#         companyy = result.find_all(class_='company')\n",
    "#         company = companyy.text.replace('\\n', '')\n",
    "#         match = re.findall(r'[\\$][+-]?[0-9]{1,3}(?:,?[0-9]{3})*(?:\\.[0-9]{2})', each.text)\n",
    "#         salary = []\n",
    "#         if match:\n",
    "#             salary.append(match)\n",
    "#         else:\n",
    "#             salary.append(None)\n",
    "#         indeed_frame.loc[len(indeed_frame)]=[name, location, company, salary]\n",
    "#     return indeed_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# url = 'https://www.indeed.com/jobs?q=data+scientist+$20,000&l=New+York&start=10' \n",
    "# html = requests.get(url)\n",
    "# soup = BeautifulSoup(html.text, 'html.parser')\n",
    "# #soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop through each entry\n",
    "#for entry in html.find_all('div', {'class':'result content-section-list-row cf with-times'}):\n",
    "    # grab the name\n",
    "#    name = entry.find('span', {'class': 'rest-row-name-text'}).text\n",
    "    # grab the location\n",
    "#    location = entry.find('span', {'class': 'rest-row-meta--location rest-row-meta-text'}).renderContents()\n",
    "    # grab the price\n",
    "#    price = entry.find('div', {'class': 'rest-row-pricing'}).find('i').renderContents().count('$')\n",
    "    # try to find the number of bookings\n",
    "#    try:\n",
    "#        temp = entry.find('div', {'class':'booking'}).text\n",
    "#        match = re.search(r'\\d+', temp)\n",
    "#        if match:\n",
    "#            bookings = match.group()\n",
    "#    except:\n",
    "#        bookings = 'NA'\n",
    "    # add to df\n",
    "#    dc_eats.loc[len(dc_eats)]=[name, location, price, bookings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "#df.drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_dropped = df[df.Salary.str.contains(\"None\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more = df_more[df_more.Salary.str.contains(\"hour\") == False]\n",
    "df_more = df_more[df_more.Salary.str.contains(\"month\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Senior Software Engineer - Python (relo required)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spoken Communications</td>\n",
       "      <td>None</td>\n",
       "      <td>You'll find yourself collaborating with world-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Senior Control Engineer, LabVIEW</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tri Alpha Energy</td>\n",
       "      <td>None</td>\n",
       "      <td>Networking using Ethernet, EtherNet/IP, Data D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Occupational Medicine Consultant (Relocation t...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Saudi Aramco</td>\n",
       "      <td>None</td>\n",
       "      <td>Analyze and interpret statistical data for eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Marketing Integration &amp; Opportunity (MIO)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>None</td>\n",
       "      <td>We strive for industry-leading work in a diver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Systems Administrator</td>\n",
       "      <td>Forest, VA</td>\n",
       "      <td>Innerspec Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Manage backup and restore services to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>United States</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>None</td>\n",
       "      <td>Providing case management, data processing, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Software Engineering Specialist</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>You will work with a group of energized and fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Sr Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Pharmaceutical Sales Specialist -- Hospital Ca...</td>\n",
       "      <td>Roanoke, VA</td>\n",
       "      <td>AstraZeneca</td>\n",
       "      <td>None</td>\n",
       "      <td>Experience working with Medical Information Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Staff Software Engineer - UI Front End</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Environmental Scientist</td>\n",
       "      <td>Blacksburg, VA</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>None</td>\n",
       "      <td>Environmental Scientist If you are an Environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Russian Linguist/Research Analyst</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Centra Technology</td>\n",
       "      <td>None</td>\n",
       "      <td>CENTRA Technology, Inc. has an immediate openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Senior Software Engineer - Python (relo required)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spoken Communications</td>\n",
       "      <td>None</td>\n",
       "      <td>You'll find yourself collaborating with world-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Senior Control Engineer, LabVIEW</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tri Alpha Energy</td>\n",
       "      <td>None</td>\n",
       "      <td>Networking using Ethernet, EtherNet/IP, Data D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Occupational Medicine Consultant (Relocation t...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Saudi Aramco</td>\n",
       "      <td>None</td>\n",
       "      <td>Analyze and interpret statistical data for eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Marketing Integration &amp; Opportunity (MIO)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>None</td>\n",
       "      <td>We strive for industry-leading work in a diver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Software Engineering Specialist</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>You will work with a group of energized and fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Sr Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Pharmaceutical Sales Specialist -- Hospital Ca...</td>\n",
       "      <td>Roanoke, VA</td>\n",
       "      <td>AstraZeneca</td>\n",
       "      <td>None</td>\n",
       "      <td>Experience working with Medical Information Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Staff Software Engineer - UI Front End</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Systems Administrator</td>\n",
       "      <td>Forest, VA</td>\n",
       "      <td>Innerspec Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Manage backup and restore services to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Environmental Scientist</td>\n",
       "      <td>Blacksburg, VA</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>None</td>\n",
       "      <td>Environmental Scientist If you are an Environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>United States</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>None</td>\n",
       "      <td>Providing case management, data processing, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Russian Linguist/Research Analyst</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Centra Technology</td>\n",
       "      <td>None</td>\n",
       "      <td>CENTRA Technology, Inc. has an immediate openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Senior Software Engineer - Python (relo required)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spoken Communications</td>\n",
       "      <td>None</td>\n",
       "      <td>You'll find yourself collaborating with world-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Senior Control Engineer, LabVIEW</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tri Alpha Energy</td>\n",
       "      <td>None</td>\n",
       "      <td>Networking using Ethernet, EtherNet/IP, Data D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Occupational Medicine Consultant (Relocation t...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Saudi Aramco</td>\n",
       "      <td>None</td>\n",
       "      <td>Analyze and interpret statistical data for eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Software Engineering Specialist</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>You will work with a group of energized and fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Sr Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Pharmaceutical Sales Specialist -- Hospital Ca...</td>\n",
       "      <td>Roanoke, VA</td>\n",
       "      <td>AstraZeneca</td>\n",
       "      <td>None</td>\n",
       "      <td>Experience working with Medical Information Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Staff Software Engineer - UI Front End</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Systems Administrator</td>\n",
       "      <td>Forest, VA</td>\n",
       "      <td>Innerspec Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Manage backup and restore services to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Environmental Scientist</td>\n",
       "      <td>Blacksburg, VA</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>None</td>\n",
       "      <td>Environmental Scientist If you are an Environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>United States</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>None</td>\n",
       "      <td>Providing case management, data processing, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Russian Linguist/Research Analyst</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Centra Technology</td>\n",
       "      <td>None</td>\n",
       "      <td>CENTRA Technology, Inc. has an immediate openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Senior Software Engineer - Python (relo required)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spoken Communications</td>\n",
       "      <td>None</td>\n",
       "      <td>You'll find yourself collaborating with world-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Senior Control Engineer, LabVIEW</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tri Alpha Energy</td>\n",
       "      <td>None</td>\n",
       "      <td>Networking using Ethernet, EtherNet/IP, Data D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Occupational Medicine Consultant (Relocation t...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Saudi Aramco</td>\n",
       "      <td>None</td>\n",
       "      <td>Analyze and interpret statistical data for eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Systems Administrator</td>\n",
       "      <td>Forest, VA</td>\n",
       "      <td>Innerspec Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Manage backup and restore services to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>United States</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>None</td>\n",
       "      <td>Providing case management, data processing, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Environmental Scientist</td>\n",
       "      <td>Blacksburg, VA</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>None</td>\n",
       "      <td>Environmental Scientist If you are an Environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Software Engineering Specialist</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>You will work with a group of energized and fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Sr Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Pharmaceutical Sales Specialist -- Hospital Ca...</td>\n",
       "      <td>Roanoke, VA</td>\n",
       "      <td>AstraZeneca</td>\n",
       "      <td>None</td>\n",
       "      <td>Experience working with Medical Information Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Staff Software Engineer - UI Front End</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Russian Linguist/Research Analyst</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Centra Technology</td>\n",
       "      <td>None</td>\n",
       "      <td>CENTRA Technology, Inc. has an immediate openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Senior Software Engineer - Python (relo required)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spoken Communications</td>\n",
       "      <td>None</td>\n",
       "      <td>You'll find yourself collaborating with world-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Senior Control Engineer, LabVIEW</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tri Alpha Energy</td>\n",
       "      <td>None</td>\n",
       "      <td>Networking using Ethernet, EtherNet/IP, Data D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Occupational Medicine Consultant (Relocation t...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Saudi Aramco</td>\n",
       "      <td>None</td>\n",
       "      <td>Analyze and interpret statistical data for eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Marketing Integration &amp; Opportunity (MIO)</td>\n",
       "      <td>United States</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>None</td>\n",
       "      <td>We strive for industry-leading work in a diver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Systems Administrator</td>\n",
       "      <td>Forest, VA</td>\n",
       "      <td>Innerspec Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Manage backup and restore services to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>United States</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>None</td>\n",
       "      <td>Providing case management, data processing, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Environmental Scientist</td>\n",
       "      <td>Blacksburg, VA</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>None</td>\n",
       "      <td>Environmental Scientist If you are an Environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Software Engineering Specialist</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>You will work with a group of energized and fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Sr Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title           Location  \\\n",
       "60   Senior Software Engineer - Python (relo required)      United States   \n",
       "61                    Senior Control Engineer, LabVIEW      United States   \n",
       "62   Occupational Medicine Consultant (Relocation t...      United States   \n",
       "63           Marketing Integration & Opportunity (MIO)      United States   \n",
       "64                               Systems Administrator         Forest, VA   \n",
       "65                                      Senior Manager      United States   \n",
       "66                     Software Engineering Specialist  Roanoke, VA 24019   \n",
       "67                          Sr Staff Software Engineer  Roanoke, VA 24019   \n",
       "68                             Staff Software Engineer  Roanoke, VA 24019   \n",
       "69   Pharmaceutical Sales Specialist -- Hospital Ca...        Roanoke, VA   \n",
       "70              Staff Software Engineer - UI Front End  Roanoke, VA 24019   \n",
       "71                             Environmental Scientist     Blacksburg, VA   \n",
       "72                   Russian Linguist/Research Analyst           Virginia   \n",
       "73   Senior Software Engineer - Python (relo required)      United States   \n",
       "74                    Senior Control Engineer, LabVIEW      United States   \n",
       "75   Occupational Medicine Consultant (Relocation t...      United States   \n",
       "76           Marketing Integration & Opportunity (MIO)      United States   \n",
       "77                     Software Engineering Specialist  Roanoke, VA 24019   \n",
       "78                          Sr Staff Software Engineer  Roanoke, VA 24019   \n",
       "79                             Staff Software Engineer  Roanoke, VA 24019   \n",
       "80   Pharmaceutical Sales Specialist -- Hospital Ca...        Roanoke, VA   \n",
       "81              Staff Software Engineer - UI Front End  Roanoke, VA 24019   \n",
       "82                               Systems Administrator         Forest, VA   \n",
       "83                             Environmental Scientist     Blacksburg, VA   \n",
       "84                                      Senior Manager      United States   \n",
       "85                   Russian Linguist/Research Analyst           Virginia   \n",
       "86   Senior Software Engineer - Python (relo required)      United States   \n",
       "87                    Senior Control Engineer, LabVIEW      United States   \n",
       "88   Occupational Medicine Consultant (Relocation t...      United States   \n",
       "89                     Software Engineering Specialist  Roanoke, VA 24019   \n",
       "90                          Sr Staff Software Engineer  Roanoke, VA 24019   \n",
       "91                             Staff Software Engineer  Roanoke, VA 24019   \n",
       "92   Pharmaceutical Sales Specialist -- Hospital Ca...        Roanoke, VA   \n",
       "93              Staff Software Engineer - UI Front End  Roanoke, VA 24019   \n",
       "94                               Systems Administrator         Forest, VA   \n",
       "95                             Environmental Scientist     Blacksburg, VA   \n",
       "96                                      Senior Manager      United States   \n",
       "97                   Russian Linguist/Research Analyst           Virginia   \n",
       "98   Senior Software Engineer - Python (relo required)      United States   \n",
       "99                    Senior Control Engineer, LabVIEW      United States   \n",
       "100  Occupational Medicine Consultant (Relocation t...      United States   \n",
       "101                              Systems Administrator         Forest, VA   \n",
       "102                                     Senior Manager      United States   \n",
       "103                            Environmental Scientist     Blacksburg, VA   \n",
       "104                    Software Engineering Specialist  Roanoke, VA 24019   \n",
       "105                         Sr Staff Software Engineer  Roanoke, VA 24019   \n",
       "106                            Staff Software Engineer  Roanoke, VA 24019   \n",
       "107  Pharmaceutical Sales Specialist -- Hospital Ca...        Roanoke, VA   \n",
       "108             Staff Software Engineer - UI Front End  Roanoke, VA 24019   \n",
       "109                  Russian Linguist/Research Analyst           Virginia   \n",
       "110  Senior Software Engineer - Python (relo required)      United States   \n",
       "111                   Senior Control Engineer, LabVIEW      United States   \n",
       "112  Occupational Medicine Consultant (Relocation t...      United States   \n",
       "113          Marketing Integration & Opportunity (MIO)      United States   \n",
       "114                              Systems Administrator         Forest, VA   \n",
       "115                                     Senior Manager      United States   \n",
       "116                            Environmental Scientist     Blacksburg, VA   \n",
       "117                    Software Engineering Specialist  Roanoke, VA 24019   \n",
       "118                         Sr Staff Software Engineer  Roanoke, VA 24019   \n",
       "119                            Staff Software Engineer  Roanoke, VA 24019   \n",
       "\n",
       "                        Company Salary  \\\n",
       "60        Spoken Communications   None   \n",
       "61             Tri Alpha Energy   None   \n",
       "62                 Saudi Aramco   None   \n",
       "63                        Yahoo   None   \n",
       "64       Innerspec Technologies   None   \n",
       "65                     Exponent   None   \n",
       "66             General Electric   None   \n",
       "67             General Electric   None   \n",
       "68             General Electric   None   \n",
       "69                  AstraZeneca   None   \n",
       "70             General Electric   None   \n",
       "71                  CyberCoders   None   \n",
       "72            Centra Technology   None   \n",
       "73        Spoken Communications   None   \n",
       "74             Tri Alpha Energy   None   \n",
       "75                 Saudi Aramco   None   \n",
       "76                        Yahoo   None   \n",
       "77             General Electric   None   \n",
       "78             General Electric   None   \n",
       "79             General Electric   None   \n",
       "80                  AstraZeneca   None   \n",
       "81             General Electric   None   \n",
       "82       Innerspec Technologies   None   \n",
       "83                  CyberCoders   None   \n",
       "84                     Exponent   None   \n",
       "85            Centra Technology   None   \n",
       "86        Spoken Communications   None   \n",
       "87             Tri Alpha Energy   None   \n",
       "88                 Saudi Aramco   None   \n",
       "89             General Electric   None   \n",
       "90             General Electric   None   \n",
       "91             General Electric   None   \n",
       "92                  AstraZeneca   None   \n",
       "93             General Electric   None   \n",
       "94       Innerspec Technologies   None   \n",
       "95                  CyberCoders   None   \n",
       "96                     Exponent   None   \n",
       "97            Centra Technology   None   \n",
       "98        Spoken Communications   None   \n",
       "99             Tri Alpha Energy   None   \n",
       "100                Saudi Aramco   None   \n",
       "101      Innerspec Technologies   None   \n",
       "102                    Exponent   None   \n",
       "103                 CyberCoders   None   \n",
       "104            General Electric   None   \n",
       "105            General Electric   None   \n",
       "106            General Electric   None   \n",
       "107                 AstraZeneca   None   \n",
       "108            General Electric   None   \n",
       "109           Centra Technology   None   \n",
       "110       Spoken Communications   None   \n",
       "111            Tri Alpha Energy   None   \n",
       "112                Saudi Aramco   None   \n",
       "113                       Yahoo   None   \n",
       "114      Innerspec Technologies   None   \n",
       "115                    Exponent   None   \n",
       "116                 CyberCoders   None   \n",
       "117            General Electric   None   \n",
       "118            General Electric   None   \n",
       "119            General Electric   None   \n",
       "\n",
       "                                              Synopsis  \n",
       "60   You'll find yourself collaborating with world-...  \n",
       "61   Networking using Ethernet, EtherNet/IP, Data D...  \n",
       "62   Analyze and interpret statistical data for eva...  \n",
       "63   We strive for industry-leading work in a diver...  \n",
       "64   Manage backup and restore services to ensure t...  \n",
       "65   Providing case management, data processing, an...  \n",
       "66   You will work with a group of energized and fo...  \n",
       "67   Architects, Data Scientists, Businesses & Prod...  \n",
       "68   Architects, Data Scientists, Businesses & Prod...  \n",
       "69   Experience working with Medical Information Sc...  \n",
       "70   Architects, Data Scientists, Businesses & Prod...  \n",
       "71   Environmental Scientist If you are an Environm...  \n",
       "72   CENTRA Technology, Inc. has an immediate openi...  \n",
       "73   You'll find yourself collaborating with world-...  \n",
       "74   Networking using Ethernet, EtherNet/IP, Data D...  \n",
       "75   Analyze and interpret statistical data for eva...  \n",
       "76   We strive for industry-leading work in a diver...  \n",
       "77   You will work with a group of energized and fo...  \n",
       "78   Architects, Data Scientists, Businesses & Prod...  \n",
       "79   Architects, Data Scientists, Businesses & Prod...  \n",
       "80   Experience working with Medical Information Sc...  \n",
       "81   Architects, Data Scientists, Businesses & Prod...  \n",
       "82   Manage backup and restore services to ensure t...  \n",
       "83   Environmental Scientist If you are an Environm...  \n",
       "84   Providing case management, data processing, an...  \n",
       "85   CENTRA Technology, Inc. has an immediate openi...  \n",
       "86   You'll find yourself collaborating with world-...  \n",
       "87   Networking using Ethernet, EtherNet/IP, Data D...  \n",
       "88   Analyze and interpret statistical data for eva...  \n",
       "89   You will work with a group of energized and fo...  \n",
       "90   Architects, Data Scientists, Businesses & Prod...  \n",
       "91   Architects, Data Scientists, Businesses & Prod...  \n",
       "92   Experience working with Medical Information Sc...  \n",
       "93   Architects, Data Scientists, Businesses & Prod...  \n",
       "94   Manage backup and restore services to ensure t...  \n",
       "95   Environmental Scientist If you are an Environm...  \n",
       "96   Providing case management, data processing, an...  \n",
       "97   CENTRA Technology, Inc. has an immediate openi...  \n",
       "98   You'll find yourself collaborating with world-...  \n",
       "99   Networking using Ethernet, EtherNet/IP, Data D...  \n",
       "100  Analyze and interpret statistical data for eva...  \n",
       "101  Manage backup and restore services to ensure t...  \n",
       "102  Providing case management, data processing, an...  \n",
       "103  Environmental Scientist If you are an Environm...  \n",
       "104  You will work with a group of energized and fo...  \n",
       "105  Architects, Data Scientists, Businesses & Prod...  \n",
       "106  Architects, Data Scientists, Businesses & Prod...  \n",
       "107  Experience working with Medical Information Sc...  \n",
       "108  Architects, Data Scientists, Businesses & Prod...  \n",
       "109  CENTRA Technology, Inc. has an immediate openi...  \n",
       "110  You'll find yourself collaborating with world-...  \n",
       "111  Networking using Ethernet, EtherNet/IP, Data D...  \n",
       "112  Analyze and interpret statistical data for eva...  \n",
       "113  We strive for industry-leading work in a diver...  \n",
       "114  Manage backup and restore services to ensure t...  \n",
       "115  Providing case management, data processing, an...  \n",
       "116  Environmental Scientist If you are an Environm...  \n",
       "117  You will work with a group of energized and fo...  \n",
       "118  Architects, Data Scientists, Businesses & Prod...  \n",
       "119  Architects, Data Scientists, Businesses & Prod...  "
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more[60:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_dropped  = df_dropped.drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dropped = df_dropped.reset_index()\n",
    "#df_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_drop  = df_dropped.drop('index',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_dropped.drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_dropped[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more = df_more[df_more.Salary != 'None'].drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 5)"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have 572 unique jobs with salary data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dropped[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_dropped = df_dropped['Salary'].str.strip()\n",
    "# df_dropped = df_dropped['Title'].str.strip()\n",
    "# df_dropped = df_dropped['Location'].str.strip()\n",
    "# df_dropped = df_dropped['Company'].str.strip()\n",
    "# df_dropped = df_dropped['Synopsis'].str.strip()\n",
    "# df_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_drop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-510-bcf5b73dcce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_drop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompany\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_drop' is not defined"
     ]
    }
   ],
   "source": [
    "df_drop.Company.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_no_desc = df_dropped.drop('Synopsis', axis=1)\n",
    "# df_no_desc[60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_no_desc.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_no_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " for each in dataframe:\n",
    "        each = each.strip('a year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395, 5)\n",
      "(395, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>$50,000 - $100,000 a year</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>$55,000 - $60,000 a year</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>$80,000 - $130,000 a year</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>$140,000 a year</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>$130,000 a year</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                         Salary  \\\n",
       "1263  $50,000 - $100,000 a year   \n",
       "4001   $55,000 - $60,000 a year   \n",
       "4176  $80,000 - $130,000 a year   \n",
       "4177            $140,000 a year   \n",
       "4184            $130,000 a year   \n",
       "\n",
       "                                               Synopsis  \n",
       "1263  We are seeking a mid-level Environmental Scien...  \n",
       "4001  Produce analyses of crime trends and provide d...  \n",
       "4176  Requirements of the Data Scientist:. Prominent...  \n",
       "4177  A major healthcare corporation located right i...  \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...  "
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (df_more.shape)\n",
    "df_more = df_more[df_more.Salary.str.contains(\"hour\") == False]\n",
    "df_more = df_more[df_more.Salary.str.contains(\"month\") == False]\n",
    "print (df_more.shape)\n",
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_stripper(dataframe, column):\n",
    "    dataframe[str(column)] = dataframe[str(column)].replace({'\\$':''}, regex = True)\n",
    "    dataframe[str(column)].replace(regex=True,inplace=True,to_replace=r'\\D',value=r' ')\n",
    "    dataframe[str(column)] = dataframe[str(column)].str.replace(' ',',')\n",
    "    dataframe = dataframe.join(dataframe[str(column)].str.split(',,,', 1, expand=True).rename(columns={0:'Low', 1:'High'}))\n",
    "    dataframe['Low'] = dataframe['Low'].str.replace(',','')\n",
    "    dataframe['Low'] = dataframe['Low'].astype('float64')\n",
    "    dataframe.drop(str(column), axis=1, inplace=True)\n",
    "    dataframe['High'] = dataframe['High'].str.replace(',','')\n",
    "    dataframe['High'] = dataframe['High'].apply(pd.to_numeric)\n",
    "    dataframe['Average'] = dataframe[['Low', 'High']].mean(axis=1)\n",
    "    return dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>75000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                                               Synopsis       Low      High  \\\n",
       "1263  We are seeking a mid-level Environmental Scien...   50000.0  100000.0   \n",
       "4001  Produce analyses of crime trends and provide d...   55000.0   60000.0   \n",
       "4176  Requirements of the Data Scientist:. Prominent...   80000.0  130000.0   \n",
       "4177  A major healthcare corporation located right i...  140000.0       NaN   \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...  130000.0       NaN   \n",
       "\n",
       "       Average  \n",
       "1263   75000.0  \n",
       "4001   57500.0  \n",
       "4176  105000.0  \n",
       "4177  140000.0  \n",
       "4184  130000.0  "
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_stripper(df_more, 'Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more['Salary'] = df_more['Salary'].replace({'\\$':''}, regex = True)\n",
    "df_more['Salary'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r' ')\n",
    "df_more['Salary'] = df_more['Salary'].str.replace(' ',',')\n",
    "df_more = df_more.join(df_more['Salary'].str.split(',,,', 1, expand=True).rename(columns={0:'Salary Low', 1:'Salary High'}))\n",
    "df_more['Salary Low'] = df_more['Salary Low'].str.replace(',','')\n",
    "df_more['Salary High'] = df_more['Salary High'].str.replace(',','')\n",
    "df_more['Salary Low'] = df_more['Salary Low'].astype('float64')\n",
    "df_more.drop('Salary', axis=1, inplace=True)\n",
    "df_more['Salary High'] = df_more['Salary High'].apply(pd.to_numeric)\n",
    "df_more['Average'] = df_more[['Salary Low', 'Salary High']].mean(axis=1)\n",
    "#df_more.drop('Salary High', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Salary Low</th>\n",
       "      <th>Salary High</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>75000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                                               Synopsis  Salary Low  \\\n",
       "1263  We are seeking a mid-level Environmental Scien...     50000.0   \n",
       "4001  Produce analyses of crime trends and provide d...     55000.0   \n",
       "4176  Requirements of the Data Scientist:. Prominent...     80000.0   \n",
       "4177  A major healthcare corporation located right i...    140000.0   \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...    130000.0   \n",
       "\n",
       "      Salary High   Average  \n",
       "1263     100000.0   75000.0  \n",
       "4001      60000.0   57500.0  \n",
       "4176     130000.0  105000.0  \n",
       "4177          NaN  140000.0  \n",
       "4184          NaN  130000.0  "
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for each in df_more['Salary High']:\n",
    "    if each == '':\n",
    "        each = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more['Salary High'] = df_more['Salary High'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Salary Low</th>\n",
       "      <th>Salary High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                                               Synopsis  Salary Low  \\\n",
       "1263  We are seeking a mid-level Environmental Scien...     50000.0   \n",
       "4001  Produce analyses of crime trends and provide d...     55000.0   \n",
       "4176  Requirements of the Data Scientist:. Prominent...     80000.0   \n",
       "4177  A major healthcare corporation located right i...    140000.0   \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...    130000.0   \n",
       "\n",
       "      Salary High  \n",
       "1263     100000.0  \n",
       "4001      60000.0  \n",
       "4176     130000.0  \n",
       "4177          NaN  \n",
       "4184          NaN  "
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more['Average'] = df_more[['Salary Low', 'Salary High']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Salary Low</th>\n",
       "      <th>Salary High</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>75000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                                               Synopsis  Salary Low  \\\n",
       "1263  We are seeking a mid-level Environmental Scien...     50000.0   \n",
       "4001  Produce analyses of crime trends and provide d...     55000.0   \n",
       "4176  Requirements of the Data Scientist:. Prominent...     80000.0   \n",
       "4177  A major healthcare corporation located right i...    140000.0   \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...    130000.0   \n",
       "\n",
       "      Salary High       avg  \n",
       "1263     100000.0   75000.0  \n",
       "4001      60000.0   57500.0  \n",
       "4176     130000.0  105000.0  \n",
       "4177          NaN  140000.0  \n",
       "4184          NaN  130000.0  "
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "must specify a fill method or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-801-b748d93be66c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_more\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_more\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   2752\u001b[0m                      \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2753\u001b[0m                                   \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2754\u001b[0;31m                                   downcast=downcast, **kwargs)\n\u001b[0m\u001b[1;32m   2755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shift'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   3581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3582\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3583\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'must specify a fill method or value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3584\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3585\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: must specify a fill method or value"
     ]
    }
   ],
   "source": [
    "df_more.fillna()\n",
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Salary Low</th>\n",
       "      <th>Salary High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                                               Synopsis  Salary Low  \\\n",
       "1263  We are seeking a mid-level Environmental Scien...     50000.0   \n",
       "4001  Produce analyses of crime trends and provide d...     55000.0   \n",
       "4176  Requirements of the Data Scientist:. Prominent...     80000.0   \n",
       "4177  A major healthcare corporation located right i...    140000.0   \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...    130000.0   \n",
       "\n",
       "     Salary High  \n",
       "1263      100000  \n",
       "4001       60000  \n",
       "4176      130000  \n",
       "4177              \n",
       "4184              "
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more.drop('Salary', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Salary Low</th>\n",
       "      <th>Salary High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                                               Synopsis  Salary Low  \\\n",
       "1263  We are seeking a mid-level Environmental Scien...     50000.0   \n",
       "4001  Produce analyses of crime trends and provide d...     55000.0   \n",
       "4176  Requirements of the Data Scientist:. Prominent...     80000.0   \n",
       "4177  A major healthcare corporation located right i...    140000.0   \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...    130000.0   \n",
       "\n",
       "     Salary High  \n",
       "1263      100000  \n",
       "4001       60000  \n",
       "4176      130000  \n",
       "4177              \n",
       "4184              "
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more['Salary'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r' ')\n",
    "df_more['Salary'] = df_more['Salary'].str.replace(' ',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more['Salary'] = df_more['Salary'].str.replace(' ',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>50,000,,,100,000,,,,,,,</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>55,000,,,60,000,,,,,,,</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>80,000,,,130,000,,,,,,,</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>140,000,,,,,,,</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>130,000,,,,,,,</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                       Salary  \\\n",
       "1263  50,000,,,100,000,,,,,,,   \n",
       "4001   55,000,,,60,000,,,,,,,   \n",
       "4176  80,000,,,130,000,,,,,,,   \n",
       "4177           140,000,,,,,,,   \n",
       "4184           130,000,,,,,,,   \n",
       "\n",
       "                                               Synopsis  \n",
       "1263  We are seeking a mid-level Environmental Scien...  \n",
       "4001  Produce analyses of crime trends and provide d...  \n",
       "4176  Requirements of the Data Scientist:. Prominent...  \n",
       "4177  A major healthcare corporation located right i...  \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...  "
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>000   100 000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>000   60 000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>000   130 000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first                   row\n",
       "0    50  000   100 000       \n",
       "1    55   000   60 000       \n",
       "2    80  000   130 000       \n",
       "3   140            000       \n",
       "4   130            000       "
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Salary Low</th>\n",
       "      <th>Salary High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>50,000,,,100,000,,,,,,,</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50,000</td>\n",
       "      <td>100,000,,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>55,000,,,60,000,,,,,,,</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55,000</td>\n",
       "      <td>60,000,,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>80,000,,,130,000,,,,,,,</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "      <td>80,000</td>\n",
       "      <td>130,000,,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>140,000,,,,,,,</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "      <td>140,000</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>130,000,,,,,,,</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "      <td>130,000</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                       Salary  \\\n",
       "1263  50,000,,,100,000,,,,,,,   \n",
       "4001   55,000,,,60,000,,,,,,,   \n",
       "4176  80,000,,,130,000,,,,,,,   \n",
       "4177           140,000,,,,,,,   \n",
       "4184           130,000,,,,,,,   \n",
       "\n",
       "                                               Synopsis Salary Low  \\\n",
       "1263  We are seeking a mid-level Environmental Scien...     50,000   \n",
       "4001  Produce analyses of crime trends and provide d...     55,000   \n",
       "4176  Requirements of the Data Scientist:. Prominent...     80,000   \n",
       "4177  A major healthcare corporation located right i...    140,000   \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...    130,000   \n",
       "\n",
       "         Salary High  \n",
       "1263  100,000,,,,,,,  \n",
       "4001   60,000,,,,,,,  \n",
       "4176  130,000,,,,,,,  \n",
       "4177            ,,,,  \n",
       "4184            ,,,,  "
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_more['Salary_low', 'Salary_high'] = df_more['Salary'].str.split(',,,')\n",
    "df_more = df_more.join(df_more['Salary'].str.split(',,,', 1, expand=True).rename(columns={0:'Salary Low', 1:'Salary High'}))\n",
    "#df.join(df['AB'].str.split('-', 1, expand=True).rename(columns={0:'A', 1:'B'}))\n",
    "#df['AB_split'] = df['AB'].str.split('-')\n",
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_more['Salary Low'] = df_more['Salary Low'].str.replace(',','')\n",
    "df_more['Salary High'] = df_more['Salary High'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Salary Low</th>\n",
       "      <th>Salary High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>50,000,,,100,000,,,,,,,</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>55,000,,,60,000,,,,,,,</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>80,000,,,130,000,,,,,,,</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "      <td>80000</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>140,000,,,,,,,</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "      <td>140000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>130,000,,,,,,,</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "      <td>130000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                       Salary  \\\n",
       "1263  50,000,,,100,000,,,,,,,   \n",
       "4001   55,000,,,60,000,,,,,,,   \n",
       "4176  80,000,,,130,000,,,,,,,   \n",
       "4177           140,000,,,,,,,   \n",
       "4184           130,000,,,,,,,   \n",
       "\n",
       "                                               Synopsis Salary Low Salary High  \n",
       "1263  We are seeking a mid-level Environmental Scien...      50000      100000  \n",
       "4001  Produce analyses of crime trends and provide d...      55000       60000  \n",
       "4176  Requirements of the Data Scientist:. Prominent...      80000      130000  \n",
       "4177  A major healthcare corporation located right i...     140000              \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...     130000              "
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more['Salary Low'] = df_more['Salary Low'].astype('float64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-713-3e3cd88b2eae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_more\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Salary High'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_more\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Salary High'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/util/_decorators.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m         new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 3410\u001b[0;31m                                      **kwargs)\n\u001b[0m\u001b[1;32m   3411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3090\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3091\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3092\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 471\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/dtypes/cast.pyc\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "df_more['Salary High'] = df_more['Salary High'].astype('float64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Salary Low</th>\n",
       "      <th>Salary High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>50,000,,,100,000,,,,,,,</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>55,000,,,60,000,,,,,,,</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>80,000,,,130,000,,,,,,,</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>140,000,,,,,,,</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>130,000,,,,,,,</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                       Salary  \\\n",
       "1263  50,000,,,100,000,,,,,,,   \n",
       "4001   55,000,,,60,000,,,,,,,   \n",
       "4176  80,000,,,130,000,,,,,,,   \n",
       "4177           140,000,,,,,,,   \n",
       "4184           130,000,,,,,,,   \n",
       "\n",
       "                                               Synopsis  Salary Low  \\\n",
       "1263  We are seeking a mid-level Environmental Scien...     50000.0   \n",
       "4001  Produce analyses of crime trends and provide d...     55000.0   \n",
       "4176  Requirements of the Data Scientist:. Prominent...     80000.0   \n",
       "4177  A major healthcare corporation located right i...    140000.0   \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...    130000.0   \n",
       "\n",
       "     Salary High  \n",
       "1263      100000  \n",
       "4001       60000  \n",
       "4176      130000  \n",
       "4177              \n",
       "4184              "
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more.Salary = [x.strip().replace(' ', ',') for x in df_more.Salary]\n",
    "#list2 = [x for ind, x in enumerate(list1) if 4 > ind > 0]\n",
    "#formatted.columns = [x.strip().replace(' ', '_') for x in formatted.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Salary Low'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-612-6c3d7135bd44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_more\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Salary Low'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_more\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Salary Low'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aakashtandel/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Salary Low'"
     ]
    }
   ],
   "source": [
    "df_more['Salary Low']  = [x.strip().replace(',', '') for x in df_more['Salary Low']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>50,000,,,100,000,,,,,,,</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Auth...</td>\n",
       "      <td>55,000,,,60,000,,,,,,,</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>80,000,,,130,000,,,,,,,</td>\n",
       "      <td>Requirements of the Data Scientist:. Prominent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>140,000,,,,,,,</td>\n",
       "      <td>A major healthcare corporation located right i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>Lead Data Scientist (Tableau, RShiny, D3)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>130,000,,,,,,,</td>\n",
       "      <td>Hiring for a Senior-Lead Data Scientist for a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title             Location  \\\n",
       "1263                   Environmental Consultant  Nashville, TN 37220   \n",
       "4001                           Research Analyst          Chicago, IL   \n",
       "4176                             Data Scientist          Chicago, IL   \n",
       "4177                        Lead Data Scientist          Chicago, IL   \n",
       "4184  Lead Data Scientist (Tableau, RShiny, D3)          Chicago, IL   \n",
       "\n",
       "                                                Company  \\\n",
       "1263                                   LP Environmental   \n",
       "4001      Illinois Criminal Justice Information Auth...   \n",
       "4176                            Smith Hanley Associates   \n",
       "4177                              Workbridge Associates   \n",
       "4184                              Workbridge Associates   \n",
       "\n",
       "                       Salary  \\\n",
       "1263  50,000,,,100,000,,,,,,,   \n",
       "4001   55,000,,,60,000,,,,,,,   \n",
       "4176  80,000,,,130,000,,,,,,,   \n",
       "4177           140,000,,,,,,,   \n",
       "4184           130,000,,,,,,,   \n",
       "\n",
       "                                               Synopsis  \n",
       "1263  We are seeking a mid-level Environmental Scien...  \n",
       "4001  Produce analyses of crime trends and provide d...  \n",
       "4176  Requirements of the Data Scientist:. Prominent...  \n",
       "4177  A major healthcare corporation located right i...  \n",
       "4184  Hiring for a Senior-Lead Data Scientist for a ...  "
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#salary_stripper(df_more, 'Salary')\n",
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more = pd.read_csv('/Users/aakashtandel/Desktop/Indeed_Project_3_df_more.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Systems Administrator</td>\n",
       "      <td>Forest, VA</td>\n",
       "      <td>Innerspec Technologies</td>\n",
       "      <td>None</td>\n",
       "      <td>Manage backup and restore services to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Environmental Scientist</td>\n",
       "      <td>Blacksburg, VA</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>None</td>\n",
       "      <td>Environmental Scientist If you are an Environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>United States</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>None</td>\n",
       "      <td>Providing case management, data processing, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineering Specialist</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>You will work with a group of energized and fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title           Location  \\\n",
       "0            Systems Administrator         Forest, VA   \n",
       "1          Environmental Scientist     Blacksburg, VA   \n",
       "2                   Senior Manager      United States   \n",
       "3  Software Engineering Specialist  Roanoke, VA 24019   \n",
       "4          Staff Software Engineer  Roanoke, VA 24019   \n",
       "\n",
       "                      Company Salary  \\\n",
       "0      Innerspec Technologies   None   \n",
       "1                 CyberCoders   None   \n",
       "2                    Exponent   None   \n",
       "3            General Electric   None   \n",
       "4            General Electric   None   \n",
       "\n",
       "                                            Synopsis  \n",
       "0  Manage backup and restore services to ensure t...  \n",
       "1  Environmental Scientist If you are an Environm...  \n",
       "2  Providing case management, data processing, an...  \n",
       "3  You will work with a group of energized and fo...  \n",
       "4  Architects, Data Scientists, Businesses & Prod...  "
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4769</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13843</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13887</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13891</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13938</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14012</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14042</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14075</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14081</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14085</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14087</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14098</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14112</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14221</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14233</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14234</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14266</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14294</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14308</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14309</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14370</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14386</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14398</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14428</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14436</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14446</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14447</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14456</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179872</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179879</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179888</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179902</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179907</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179916</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179921</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179930</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179935</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179944</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179949</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179956</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179963</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179971</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179977</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184853</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184855</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184858</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184914</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190106</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190126</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190141</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190157</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190172</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190186</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190201</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190216</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190232</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190246</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6182 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Title  Location  Company  Salary  Synopsis\n",
       "4769    False     False    False   False     False\n",
       "13843   False     False    False   False     False\n",
       "13887   False     False    False   False     False\n",
       "13891   False     False    False   False     False\n",
       "13938   False     False    False   False     False\n",
       "14012   False     False    False   False     False\n",
       "14037   False     False    False   False     False\n",
       "14042   False     False    False   False     False\n",
       "14075   False     False    False   False     False\n",
       "14081   False     False    False   False     False\n",
       "14085   False     False    False   False     False\n",
       "14087   False     False    False   False     False\n",
       "14098   False     False    False   False     False\n",
       "14112   False     False    False   False     False\n",
       "14126   False     False    False   False     False\n",
       "14221   False     False    False   False     False\n",
       "14233   False     False    False   False     False\n",
       "14234   False     False    False   False     False\n",
       "14266   False     False    False   False     False\n",
       "14294   False     False    False   False     False\n",
       "14308   False     False    False   False     False\n",
       "14309   False     False    False   False     False\n",
       "14370   False     False    False   False     False\n",
       "14386   False     False    False   False     False\n",
       "14398   False     False    False   False     False\n",
       "14428   False     False    False   False     False\n",
       "14436   False     False    False   False     False\n",
       "14446   False     False    False   False     False\n",
       "14447   False     False    False   False     False\n",
       "14456   False     False    False   False     False\n",
       "...       ...       ...      ...     ...       ...\n",
       "179872  False     False    False   False     False\n",
       "179879  False     False    False   False     False\n",
       "179888  False     False    False   False     False\n",
       "179893  False     False    False   False     False\n",
       "179902  False     False    False   False     False\n",
       "179907  False     False    False   False     False\n",
       "179916  False     False    False   False     False\n",
       "179921  False     False    False   False     False\n",
       "179930  False     False    False   False     False\n",
       "179935  False     False    False   False     False\n",
       "179944  False     False    False   False     False\n",
       "179949  False     False    False   False     False\n",
       "179956  False     False    False   False     False\n",
       "179963  False     False    False   False     False\n",
       "179971  False     False    False   False     False\n",
       "179977  False     False    False   False     False\n",
       "184853  False     False    False   False     False\n",
       "184855  False     False    False   False     False\n",
       "184858  False     False    False   False     False\n",
       "184914  False     False    False   False     False\n",
       "190106  False     False    False   False     False\n",
       "190126  False     False    False   False     False\n",
       "190141  False     False    False   False     False\n",
       "190157  False     False    False   False     False\n",
       "190172  False     False    False   False     False\n",
       "190186  False     False    False   False     False\n",
       "190201  False     False    False   False     False\n",
       "190216  False     False    False   False     False\n",
       "190232  False     False    False   False     False\n",
       "190246  False     False    False   False     False\n",
       "\n",
       "[6182 rows x 5 columns]"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.shape[0] == df_more[df_more.Salary.str.contains('year')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "# Export to csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary using Sklearn. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title or whether 'Manager' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value?\n",
    "- After creating these variables, use count-vectorizer to create features based on the words in the job titles.\n",
    "- Build a new random forest model with location and these new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process with a non-tree-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the job descriptions. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
