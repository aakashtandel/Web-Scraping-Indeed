{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title, and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use a random forest classifier, as well as another classifier of your choice; either logistic regression, SVM, or KNN. \n",
    "\n",
    "- **Question**: Why would we want this to be a classification problem?\n",
    "- **Answer**: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "The URL here has many query parameters\n",
    "- q for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- l for a location\n",
    "- start for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one result more closely. A single result looks like\n",
    "```JSON\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&campaignid=serp-linkcompanyname&fromjk=2480d203f7e97210&jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a nobr element inside of a td element with class='snip.\n",
    "- The title of a job is in a link with class set to jobtitle and a data-tn-element=\"jobTitle.\n",
    "- The location is set in a span with class='location'.\n",
    "- The company is set in a span with class='company'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write 4 functions to extract these items (one function for each): location, company, job title, and salary.¶\n",
    "Example\n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "##### - Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    ">- Remember to check if a field is empty or None for attempting to call methods on it\n",
    ">- Remember to use try/except if you anticipate errors.\n",
    "\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Rithika suggested I merge all of the find_alls into one large function, so the code below was created with her assistance. \n",
    "\n",
    "def parse(url):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "    df = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "    for each in soup.find_all(class_= \"result\" ):\n",
    "        try: \n",
    "            title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "        except:\n",
    "            title = 'None'\n",
    "        try:\n",
    "            location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "        except:\n",
    "            location = 'None'\n",
    "        try: \n",
    "            company = each.find(class_='company').text.replace('\\n', '')\n",
    "        except:\n",
    "            company = 'None'\n",
    "        try:\n",
    "            salary = each.find('span', {'class':'no-wrap'}).text\n",
    "        except:\n",
    "            salary = 'None'\n",
    "        synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "        df = df.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Big Data &amp; Analytics</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>None</td>\n",
       "      <td>KPMG is currently seeking a Data Scientist - B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Healthcare &amp; Life Sciences - Data Scientist</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>None</td>\n",
       "      <td>KPMG is currently seeking a Healthcare &amp; Life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entry Level – Research Analyst/Editor/Content ...</td>\n",
       "      <td>New York, NY 10017 (Midtown area)</td>\n",
       "      <td>XG Consultants Group, Inc.</td>\n",
       "      <td>$15 an hour</td>\n",
       "      <td>Job Overview: XG Consultants Group is looking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>UBS</td>\n",
       "      <td>None</td>\n",
       "      <td>Proficient using C++, VBA, R, SAS, SQL, Oracle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Intern - Fall 2017</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>FactSet</td>\n",
       "      <td>None</td>\n",
       "      <td>Scientist and engineer. Extract, transform, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Intern - Fall 2017</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>FactSet Research Systems</td>\n",
       "      <td>None</td>\n",
       "      <td>Just the right kind of work for a passionate d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Specialist, Advanced Insights - McKinsey Solut...</td>\n",
       "      <td>New York, NY 10022 (Midtown area)</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>None</td>\n",
       "      <td>As one of the fastest-growing parts of our fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Indellient</td>\n",
       "      <td>None</td>\n",
       "      <td>Big data and analytics, digital content delive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning Engineer - KYC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>None</td>\n",
       "      <td>Experience with Big data technologies such as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quantitative Research Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Morningstar</td>\n",
       "      <td>None</td>\n",
       "      <td>Perform ad-hoc data cleaning and statistical a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Specialist - Operations Performance, Energy In...</td>\n",
       "      <td>New York, NY 10022 (Midtown area)</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>None</td>\n",
       "      <td>As one of the fastest-growing parts of our fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Analyst - Energy Insights</td>\n",
       "      <td>New York, NY 10022 (Midtown area)</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>None</td>\n",
       "      <td>As one of the fastest-growing parts of our fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist | NYC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Avanade</td>\n",
       "      <td>None</td>\n",
       "      <td>Design, implement and deploy ETL to load data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY 10154</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>None</td>\n",
       "      <td>KPMG is currently seeking a Data Scientist to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist - Worldwide Advanced Analytics ...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>IBM</td>\n",
       "      <td>None</td>\n",
       "      <td>The Worldwide Advanced Analytics Center of Com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0               Data Scientist - Big Data & Analytics   \n",
       "1         Healthcare & Life Sciences - Data Scientist   \n",
       "2   Entry Level – Research Analyst/Editor/Content ...   \n",
       "3                                Quantitative Analyst   \n",
       "4                     Data Science Intern - Fall 2017   \n",
       "5                     Data Science Intern - Fall 2017   \n",
       "6   Specialist, Advanced Insights - McKinsey Solut...   \n",
       "7                           Machine Learning Engineer   \n",
       "8                     Machine Learning Engineer - KYC   \n",
       "9                       Quantitative Research Analyst   \n",
       "10  Specialist - Operations Performance, Energy In...   \n",
       "11                          Analyst - Energy Insights   \n",
       "12                               Data Scientist | NYC   \n",
       "13                                     Data Scientist   \n",
       "14  Data Scientist - Worldwide Advanced Analytics ...   \n",
       "\n",
       "                              Location                     Company  \\\n",
       "0                   New York, NY 10154                        KPMG   \n",
       "1                   New York, NY 10154                        KPMG   \n",
       "2    New York, NY 10017 (Midtown area)  XG Consultants Group, Inc.   \n",
       "3                         New York, NY                         UBS   \n",
       "4   New York, NY 10016 (Gramercy area)                     FactSet   \n",
       "5   New York, NY 10016 (Gramercy area)    FactSet Research Systems   \n",
       "6    New York, NY 10022 (Midtown area)          McKinsey & Company   \n",
       "7                         New York, NY                  Indellient   \n",
       "8                         New York, NY                   Bloomberg   \n",
       "9                         New York, NY                 Morningstar   \n",
       "10   New York, NY 10022 (Midtown area)          McKinsey & Company   \n",
       "11   New York, NY 10022 (Midtown area)          McKinsey & Company   \n",
       "12                        New York, NY                     Avanade   \n",
       "13                  New York, NY 10154                        KPMG   \n",
       "14                        New York, NY                         IBM   \n",
       "\n",
       "         Salary                                           Synopsis  \n",
       "0          None  KPMG is currently seeking a Data Scientist - B...  \n",
       "1          None  KPMG is currently seeking a Healthcare & Life ...  \n",
       "2   $15 an hour  Job Overview: XG Consultants Group is looking ...  \n",
       "3          None  Proficient using C++, VBA, R, SAS, SQL, Oracle...  \n",
       "4          None  Scientist and engineer. Extract, transform, an...  \n",
       "5          None  Just the right kind of work for a passionate d...  \n",
       "6          None  As one of the fastest-growing parts of our fir...  \n",
       "7          None  Big data and analytics, digital content delive...  \n",
       "8          None  Experience with Big data technologies such as ...  \n",
       "9          None  Perform ad-hoc data cleaning and statistical a...  \n",
       "10         None  As one of the fastest-growing parts of our fir...  \n",
       "11         None  As one of the fastest-growing parts of our fir...  \n",
       "12         None  Design, implement and deploy ETL to load data ...  \n",
       "13         None  KPMG is currently seeking a Data Scientist to ...  \n",
       "14         None  The Worldwide Advanced Analytics Center of Com...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the l=New+York and the start=10. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list).\n",
    "##### Complete the following code to collect results from multiple cities and starting points.\n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = 'Washington%2C+DC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1000 results. 0 of these aren't rubbish.\n",
      "You have 2000 results. 0 of these aren't rubbish.\n",
      "You have 3000 results. 2 of these aren't rubbish.\n",
      "You have 4000 results. 2 of these aren't rubbish.\n",
      "You have 5000 results. 2 of these aren't rubbish.\n",
      "You have 6000 results. 2 of these aren't rubbish.\n",
      "You have 7000 results. 2 of these aren't rubbish.\n",
      "You have 8000 results. 4 of these aren't rubbish.\n",
      "You have 9000 results. 41 of these aren't rubbish.\n",
      "You have 10000 results. 41 of these aren't rubbish.\n",
      "You have 11000 results. 45 of these aren't rubbish.\n",
      "You have 12000 results. 52 of these aren't rubbish.\n",
      "You have 13000 results. 58 of these aren't rubbish.\n",
      "You have 14000 results. 61 of these aren't rubbish.\n",
      "You have 15000 results. 69 of these aren't rubbish.\n",
      "You have 16000 results. 69 of these aren't rubbish.\n",
      "You have 17000 results. 73 of these aren't rubbish.\n",
      "You have 18000 results. 94 of these aren't rubbish.\n",
      "You have 19000 results. 94 of these aren't rubbish.\n",
      "You have 20000 results. 94 of these aren't rubbish.\n",
      "You have 21000 results. 98 of these aren't rubbish.\n",
      "You have 22000 results. 98 of these aren't rubbish.\n",
      "You have 23000 results. 105 of these aren't rubbish.\n",
      "You have 24000 results. 105 of these aren't rubbish.\n",
      "You have 25000 results. 105 of these aren't rubbish.\n",
      "You have 26000 results. 107 of these aren't rubbish.\n",
      "You have 27000 results. 107 of these aren't rubbish.\n",
      "You have 28000 results. 107 of these aren't rubbish.\n",
      "You have 29000 results. 111 of these aren't rubbish.\n",
      "You have 30000 results. 111 of these aren't rubbish.\n",
      "You have 31000 results. 114 of these aren't rubbish.\n",
      "You have 32000 results. 114 of these aren't rubbish.\n",
      "You have 33000 results. 114 of these aren't rubbish.\n",
      "You have 34000 results. 123 of these aren't rubbish.\n",
      "You have 35000 results. 123 of these aren't rubbish.\n",
      "You have 36000 results. 123 of these aren't rubbish.\n",
      "You have 37000 results. 129 of these aren't rubbish.\n",
      "You have 38000 results. 129 of these aren't rubbish.\n",
      "You have 39000 results. 129 of these aren't rubbish.\n",
      "You have 40000 results. 133 of these aren't rubbish.\n",
      "You have 41000 results. 133 of these aren't rubbish.\n",
      "You have 42000 results. 133 of these aren't rubbish.\n",
      "You have 43000 results. 133 of these aren't rubbish.\n",
      "You have 44000 results. 133 of these aren't rubbish.\n",
      "You have 45000 results. 145 of these aren't rubbish.\n",
      "You have 46000 results. 145 of these aren't rubbish.\n",
      "You have 47000 results. 145 of these aren't rubbish.\n",
      "You have 48000 results. 154 of these aren't rubbish.\n",
      "You have 49000 results. 168 of these aren't rubbish.\n",
      "You have 50000 results. 168 of these aren't rubbish.\n",
      "You have 51000 results. 173 of these aren't rubbish.\n",
      "You have 52000 results. 173 of these aren't rubbish.\n",
      "You have 53000 results. 173 of these aren't rubbish.\n",
      "You have 54000 results. 195 of these aren't rubbish.\n",
      "You have 55000 results. 195 of these aren't rubbish.\n",
      "You have 56000 results. 195 of these aren't rubbish.\n",
      "You have 57000 results. 198 of these aren't rubbish.\n",
      "You have 58000 results. 198 of these aren't rubbish.\n",
      "You have 59000 results. 198 of these aren't rubbish.\n",
      "You have 60000 results. 199 of these aren't rubbish.\n",
      "You have 61000 results. 199 of these aren't rubbish.\n",
      "You have 62000 results. 199 of these aren't rubbish.\n",
      "You have 63000 results. 204 of these aren't rubbish.\n",
      "You have 64000 results. 204 of these aren't rubbish.\n",
      "You have 65000 results. 204 of these aren't rubbish.\n",
      "You have 66000 results. 205 of these aren't rubbish.\n",
      "You have 67000 results. 205 of these aren't rubbish.\n",
      "You have 68000 results. 208 of these aren't rubbish.\n",
      "You have 69000 results. 208 of these aren't rubbish.\n",
      "You have 70000 results. 208 of these aren't rubbish.\n",
      "You have 71000 results. 209 of these aren't rubbish.\n",
      "You have 72000 results. 209 of these aren't rubbish.\n",
      "You have 73000 results. 230 of these aren't rubbish.\n",
      "You have 74000 results. 234 of these aren't rubbish.\n",
      "You have 75000 results. 234 of these aren't rubbish.\n",
      "You have 76000 results. 235 of these aren't rubbish.\n",
      "You have 77000 results. 235 of these aren't rubbish.\n",
      "You have 78000 results. 236 of these aren't rubbish.\n",
      "You have 79000 results. 236 of these aren't rubbish.\n",
      "You have 80000 results. 236 of these aren't rubbish.\n",
      "You have 81000 results. 239 of these aren't rubbish.\n",
      "You have 82000 results. 251 of these aren't rubbish.\n",
      "You have 83000 results. 252 of these aren't rubbish.\n",
      "You have 84000 results. 258 of these aren't rubbish.\n",
      "You have 85000 results. 258 of these aren't rubbish.\n",
      "You have 86000 results. 258 of these aren't rubbish.\n",
      "You have 87000 results. 260 of these aren't rubbish.\n",
      "You have 88000 results. 260 of these aren't rubbish.\n",
      "You have 89000 results. 264 of these aren't rubbish.\n",
      "You have 90000 results. 264 of these aren't rubbish.\n",
      "You have 91000 results. 266 of these aren't rubbish.\n",
      "You have 92000 results. 266 of these aren't rubbish.\n",
      "You have 93000 results. 266 of these aren't rubbish.\n",
      "You have 94000 results. 277 of these aren't rubbish.\n",
      "You have 95000 results. 277 of these aren't rubbish.\n",
      "You have 96000 results. 277 of these aren't rubbish.\n",
      "You have 97000 results. 292 of these aren't rubbish.\n",
      "You have 98000 results. 292 of these aren't rubbish.\n",
      "You have 99000 results. 292 of these aren't rubbish.\n",
      "You have 100000 results. 295 of these aren't rubbish.\n",
      "You have 101000 results. 295 of these aren't rubbish.\n",
      "You have 102000 results. 295 of these aren't rubbish.\n",
      "You have 103000 results. 295 of these aren't rubbish.\n",
      "You have 104000 results. 300 of these aren't rubbish.\n",
      "You have 105000 results. 300 of these aren't rubbish.\n",
      "You have 106000 results. 300 of these aren't rubbish.\n",
      "You have 107000 results. 301 of these aren't rubbish.\n",
      "You have 108000 results. 301 of these aren't rubbish.\n",
      "You have 109000 results. 301 of these aren't rubbish.\n",
      "You have 110000 results. 303 of these aren't rubbish.\n",
      "You have 111000 results. 303 of these aren't rubbish.\n",
      "You have 112000 results. 303 of these aren't rubbish.\n",
      "You have 113000 results. 307 of these aren't rubbish.\n",
      "You have 114000 results. 307 of these aren't rubbish.\n",
      "You have 115000 results. 307 of these aren't rubbish.\n",
      "You have 116000 results. 331 of these aren't rubbish.\n",
      "You have 117000 results. 331 of these aren't rubbish.\n",
      "You have 118000 results. 331 of these aren't rubbish.\n",
      "You have 119000 results. 352 of these aren't rubbish.\n",
      "You have 120000 results. 352 of these aren't rubbish.\n",
      "You have 121000 results. 352 of these aren't rubbish.\n",
      "You have 122000 results. 352 of these aren't rubbish.\n",
      "You have 123000 results. 354 of these aren't rubbish.\n",
      "You have 124000 results. 354 of these aren't rubbish.\n",
      "You have 125000 results. 373 of these aren't rubbish.\n",
      "You have 126000 results. 373 of these aren't rubbish.\n",
      "You have 127000 results. 373 of these aren't rubbish.\n",
      "You have 128000 results. 382 of these aren't rubbish.\n",
      "You have 129000 results. 382 of these aren't rubbish.\n",
      "You have 130000 results. 382 of these aren't rubbish.\n",
      "You have 131000 results. 382 of these aren't rubbish.\n",
      "You have 132000 results. 382 of these aren't rubbish.\n",
      "You have 133000 results. 382 of these aren't rubbish.\n",
      "You have 134000 results. 382 of these aren't rubbish.\n",
      "You have 135000 results. 382 of these aren't rubbish.\n",
      "You have 136000 results. 382 of these aren't rubbish.\n",
      "You have 137000 results. 408 of these aren't rubbish.\n",
      "You have 138000 results. 429 of these aren't rubbish.\n",
      "You have 139000 results. 429 of these aren't rubbish.\n",
      "You have 140000 results. 429 of these aren't rubbish.\n",
      "You have 141000 results. 429 of these aren't rubbish.\n",
      "You have 142000 results. 429 of these aren't rubbish.\n",
      "You have 143000 results. 446 of these aren't rubbish.\n",
      "You have 144000 results. 446 of these aren't rubbish.\n",
      "You have 145000 results. 446 of these aren't rubbish.\n",
      "You have 146000 results. 469 of these aren't rubbish.\n",
      "You have 147000 results. 469 of these aren't rubbish.\n",
      "You have 148000 results. 469 of these aren't rubbish.\n",
      "You have 149000 results. 470 of these aren't rubbish.\n",
      "You have 150000 results. 471 of these aren't rubbish.\n",
      "You have 151000 results. 471 of these aren't rubbish.\n",
      "You have 152000 results. 475 of these aren't rubbish.\n",
      "You have 153000 results. 475 of these aren't rubbish.\n",
      "You have 154000 results. 475 of these aren't rubbish.\n",
      "You have 155000 results. 475 of these aren't rubbish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 156000 results. 475 of these aren't rubbish.\n",
      "You have 157000 results. 476 of these aren't rubbish.\n",
      "You have 158000 results. 476 of these aren't rubbish.\n",
      "You have 159000 results. 476 of these aren't rubbish.\n",
      "You have 160000 results. 476 of these aren't rubbish.\n",
      "You have 161000 results. 476 of these aren't rubbish.\n",
      "You have 162000 results. 476 of these aren't rubbish.\n",
      "You have 163000 results. 476 of these aren't rubbish.\n",
      "You have 164000 results. 477 of these aren't rubbish.\n",
      "You have 165000 results. 488 of these aren't rubbish.\n",
      "You have 166000 results. 497 of these aren't rubbish.\n",
      "You have 167000 results. 501 of these aren't rubbish.\n",
      "You have 168000 results. 501 of these aren't rubbish.\n",
      "You have 169000 results. 501 of these aren't rubbish.\n",
      "You have 170000 results. 504 of these aren't rubbish.\n",
      "You have 171000 results. 506 of these aren't rubbish.\n",
      "You have 172000 results. 506 of these aren't rubbish.\n",
      "You have 173000 results. 506 of these aren't rubbish.\n",
      "You have 174000 results. 506 of these aren't rubbish.\n",
      "You have 175000 results. 506 of these aren't rubbish.\n",
      "You have 176000 results. 509 of these aren't rubbish.\n",
      "You have 177000 results. 516 of these aren't rubbish.\n",
      "You have 178000 results. 516 of these aren't rubbish.\n",
      "You have 179000 results. 516 of these aren't rubbish.\n",
      "You have 180000 results. 516 of these aren't rubbish.\n",
      "You have 181000 results. 516 of these aren't rubbish.\n",
      "You have 182000 results. 521 of these aren't rubbish.\n",
      "You have 183000 results. 521 of these aren't rubbish.\n",
      "You have 184000 results. 521 of these aren't rubbish.\n",
      "You have 185000 results. 532 of these aren't rubbish.\n",
      "You have 186000 results. 532 of these aren't rubbish.\n",
      "You have 187000 results. 532 of these aren't rubbish.\n",
      "You have 188000 results. 533 of these aren't rubbish.\n",
      "You have 189000 results. 533 of these aren't rubbish.\n",
      "You have 190000 results. 533 of these aren't rubbish.\n",
      "You have 191000 results. 534 of these aren't rubbish.\n",
      "You have 192000 results. 534 of these aren't rubbish.\n",
      "You have 193000 results. 534 of these aren't rubbish.\n",
      "You have 194000 results. 547 of these aren't rubbish.\n",
      "You have 195000 results. 547 of these aren't rubbish.\n",
      "You have 196000 results. 547 of these aren't rubbish.\n",
      "You have 197000 results. 581 of these aren't rubbish.\n",
      "You have 198000 results. 581 of these aren't rubbish.\n",
      "You have 199000 results. 581 of these aren't rubbish.\n"
     ]
    }
   ],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 2000 # Set this to a high-value (5000) to generate more results. \n",
    "# Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "i = 0\n",
    "results = []\n",
    "df_more = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Synopsis\"])\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY, \n",
    "    'Charlottesville', 'Richmond', 'Baltimore', 'Harrisonburg', 'San+Antonio', 'San+Diego', 'San+Jose'\n",
    "    'Austin', 'Jacksonville', 'Indianapolis', 'Columbus', 'Fort+Worth', 'Charlotte', 'Detroit', 'El+Paso', \n",
    "    'Memphis', 'Boston', 'Nashville', 'Louisville', 'Milwaukee', 'Las+Vegas', 'Albuquerque', 'Tucson', \n",
    "    'Fresno', 'Sacramento', 'Long+Beach', 'Mesa', 'Virginia+Beach', 'Norfolk', 'Atlanta', 'Colorado+Springs',\n",
    "    'Raleigh', 'Omaha', 'Oakland', 'Tulsa', 'Minneapolis', 'Cleveland', 'Wichita', 'Arlington', 'New+Orleans', \n",
    "    'Bakersfield', 'Tampa', 'Honolulu', 'Anaheim', 'Aurora', 'Santa+Ana', 'Riverside', 'Corpus+Christi', 'Pittsburgh', \n",
    "    'Lexington', 'Anchorage', 'Cincinnati', 'Baton+Rouge', 'Chesapeake', 'Alexandria', 'Fairfax', 'Herndon',\n",
    "    'Reston', 'Roanoke']):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        url = url_template.format(city, start)\n",
    "        # Append to the full set of results\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        for each in soup.find_all(class_= \"result\" ):\n",
    "            try: \n",
    "                title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "            except:\n",
    "                title = None\n",
    "            try:\n",
    "                location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "            except:\n",
    "                location = None\n",
    "            try: \n",
    "                company = each.find(class_='company').text.replace('\\n', '')\n",
    "            except:\n",
    "                company = None\n",
    "            try:\n",
    "                salary = each.find('span', {'class':'no-wrap'}).text\n",
    "            except:\n",
    "                salary = None\n",
    "            try:\n",
    "                synopsis = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "            except:\n",
    "                synopsis = None\n",
    "            df_more = df_more.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Synopsis':synopsis}, ignore_index=True)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:  # Ram helped me build this counter to see how many. You can visibly see Ram's vernacular in the print statements.\n",
    "                print('You have ' + str(i) + ' results. ' + str(df_more.dropna().drop_duplicates().shape[0]) + \" of these aren't rubbish.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more.to_csv('Indeed_Project_3_df_more_long_not_cleaned.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more = pd.read_csv('/Users/aakashtandel/Desktop/Indeed_Project_3_df_more_long_not_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Systems Administrator</td>\n",
       "      <td>Forest, VA</td>\n",
       "      <td>Innerspec Technologies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manage backup and restore services to ensure t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Environmental Scientist</td>\n",
       "      <td>Blacksburg, VA</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Environmental Scientist If you are an Environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>United States</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Providing case management, data processing, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineering Specialist</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You will work with a group of energized and fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Staff Software Engineer</td>\n",
       "      <td>Roanoke, VA 24019</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Architects, Data Scientists, Businesses &amp; Prod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title           Location                 Company  \\\n",
       "0            Systems Administrator         Forest, VA  Innerspec Technologies   \n",
       "1          Environmental Scientist     Blacksburg, VA             CyberCoders   \n",
       "2                   Senior Manager      United States                Exponent   \n",
       "3  Software Engineering Specialist  Roanoke, VA 24019        General Electric   \n",
       "4       Sr Staff Software Engineer  Roanoke, VA 24019        General Electric   \n",
       "\n",
       "  Salary                                           Synopsis  \n",
       "0    NaN  Manage backup and restore services to ensure t...  \n",
       "1    NaN  Environmental Scientist If you are an Environm...  \n",
       "2    NaN  Providing case management, data processing, an...  \n",
       "3    NaN  You will work with a group of energized and fo...  \n",
       "4    NaN  Architects, Data Scientists, Businesses & Prod...  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Title           Location                 Company  \\\n",
      "0            Systems Administrator         Forest, VA  Innerspec Technologies   \n",
      "1          Environmental Scientist     Blacksburg, VA             CyberCoders   \n",
      "2                   Senior Manager      United States                Exponent   \n",
      "3  Software Engineering Specialist  Roanoke, VA 24019        General Electric   \n",
      "4       Sr Staff Software Engineer  Roanoke, VA 24019        General Electric   \n",
      "\n",
      "  Salary                                           Synopsis  \n",
      "0    NaN  Manage backup and restore services to ensure t...  \n",
      "1    NaN  Environmental Scientist If you are an Environm...  \n",
      "2    NaN  Providing case management, data processing, an...  \n",
      "3    NaN  You will work with a group of energized and fo...  \n",
      "4    NaN  Architects, Data Scientists, Businesses & Prod...  \n",
      "(199055, 5)\n",
      "(199055, 5)\n",
      "(581, 5)\n"
     ]
    }
   ],
   "source": [
    "print (df_more.head())\n",
    "print (df_more.shape)\n",
    "print (df_more[df_more.Salary != 'None'].shape)\n",
    "df_more = df_more[df_more.Salary != 'None'].drop_duplicates().dropna()\n",
    "print (df_more.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>$50,000 - $100,000 a year</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>Data Scientist – Marketing Analytics</td>\n",
       "      <td>Chicago, IL 60601 (Loop area)</td>\n",
       "      <td>Enterprise Select</td>\n",
       "      <td>$125,000 a year</td>\n",
       "      <td>We are currently looking for an experienced Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Authority</td>\n",
       "      <td>$55,000 - $60,000 a year</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8197</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL 60606 (Loop area)</td>\n",
       "      <td>ICJIA</td>\n",
       "      <td>$55,000 - $60,000 a year</td>\n",
       "      <td>(3) analyzing qualitative and quantitative dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>Data Scientist (Python, R, AWS, Azure)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>$85,000 - $125,000 a year</td>\n",
       "      <td>Our startup client working on risk and fraud d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title                       Location  \\\n",
       "2724                Environmental Consultant            Nashville, TN 37220   \n",
       "8054    Data Scientist – Marketing Analytics  Chicago, IL 60601 (Loop area)   \n",
       "8194                        Research Analyst                    Chicago, IL   \n",
       "8197                        Research Analyst  Chicago, IL 60606 (Loop area)   \n",
       "8234  Data Scientist (Python, R, AWS, Azure)                    Chicago, IL   \n",
       "\n",
       "                                              Company  \\\n",
       "2724                                 LP Environmental   \n",
       "8054                                Enterprise Select   \n",
       "8194  Illinois Criminal Justice Information Authority   \n",
       "8197                                            ICJIA   \n",
       "8234                            Workbridge Associates   \n",
       "\n",
       "                         Salary  \\\n",
       "2724  $50,000 - $100,000 a year   \n",
       "8054            $125,000 a year   \n",
       "8194   $55,000 - $60,000 a year   \n",
       "8197   $55,000 - $60,000 a year   \n",
       "8234  $85,000 - $125,000 a year   \n",
       "\n",
       "                                               Synopsis  \n",
       "2724  We are seeking a mid-level Environmental Scien...  \n",
       "8054  We are currently looking for an experienced Da...  \n",
       "8194  Produce analyses of crime trends and provide d...  \n",
       "8197  (3) analyzing qualitative and quantitative dat...  \n",
       "8234  Our startup client working on risk and fraud d...  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more = df_more[df_more.Salary.str.contains(\"hour\") == False]\n",
    "df_more = df_more[df_more.Salary.str.contains(\"month\") == False]\n",
    "print (df_more.shape)\n",
    "df_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "def salary_stripper(dataframe, column):\n",
    "    dataframe[str(column)] = dataframe[str(column)].replace({'\\$':''}, regex = True)\n",
    "    dataframe[str(column)].replace(regex=True,inplace=True,to_replace=r'\\D',value=r' ')\n",
    "    dataframe[str(column)] = dataframe[str(column)].str.replace(' ',',')\n",
    "    dataframe = dataframe.join(dataframe[str(column)].str.split(',,,', 1, expand=True).rename(columns={0:'Low', 1:'High'}))\n",
    "    dataframe['Low'] = dataframe['Low'].str.replace(',','')\n",
    "    dataframe['Low'] = dataframe['Low'].astype('float64')\n",
    "    dataframe.drop(str(column), axis=1, inplace=True)\n",
    "    dataframe['High'] = dataframe['High'].str.replace(',','')\n",
    "    dataframe['High'] = dataframe['High'].apply(pd.to_numeric)\n",
    "    dataframe['Average'] = dataframe[['Low', 'High']].mean(axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_more = salary_stripper(df_more, 'Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17086</th>\n",
       "      <td>Senior Data Scientist Healthcare</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>Senior Data Scientist - Healthcare. Reporting ...</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17252</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Data Scientist Qualifications:. Data Scientist...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17287</th>\n",
       "      <td>Predictive Analytics (Machine Learning)</td>\n",
       "      <td>Wilmington, DE</td>\n",
       "      <td>Kennedy Unlimited Inc, Professional Staffing</td>\n",
       "      <td>Salary 130K to 140K We are assisting our Clien...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>Data Scientist/Machine Learning Specialist</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>A leading healthcare analytical team, one of t...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17406</th>\n",
       "      <td>NMR Spectroscopist</td>\n",
       "      <td>West Point, PA</td>\n",
       "      <td>EPM Scientific</td>\n",
       "      <td>Scientist | Structure Elucidation*. Excellent ...</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17421</th>\n",
       "      <td>Data Scientist/Optimization Engineer</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>In this role you will be extracting power plan...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>112500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17451</th>\n",
       "      <td>Research Scientist (Gene Therapy, Molecular Cl...</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Apex Life Sciences</td>\n",
       "      <td>Analyze and interpret the results including st...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17459</th>\n",
       "      <td>Machine Learning Researcher</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Experience with Data Mining. This agency, spec...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>115000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17467</th>\n",
       "      <td>Quant Research Analyst</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>3coast</td>\n",
       "      <td>Experience in data and time series analysis st...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17481</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Winston Fox</td>\n",
       "      <td>In this role, you will examine global markets,...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title          Location  \\\n",
       "17086                   Senior Data Scientist Healthcare  Philadelphia, PA   \n",
       "17252                                     Data Scientist  Philadelphia, PA   \n",
       "17287            Predictive Analytics (Machine Learning)    Wilmington, DE   \n",
       "17376         Data Scientist/Machine Learning Specialist  Philadelphia, PA   \n",
       "17406                                 NMR Spectroscopist    West Point, PA   \n",
       "17421               Data Scientist/Optimization Engineer  Philadelphia, PA   \n",
       "17451  Research Scientist (Gene Therapy, Molecular Cl...  Philadelphia, PA   \n",
       "17459                        Machine Learning Researcher  Philadelphia, PA   \n",
       "17467                             Quant Research Analyst  Philadelphia, PA   \n",
       "17481                               Quantitative Analyst  Philadelphia, PA   \n",
       "\n",
       "                                            Company  \\\n",
       "17086                                       Harnham   \n",
       "17252                       Smith Hanley Associates   \n",
       "17287  Kennedy Unlimited Inc, Professional Staffing   \n",
       "17376                            Jobspring Partners   \n",
       "17406                                EPM Scientific   \n",
       "17421                            Jobspring Partners   \n",
       "17451                            Apex Life Sciences   \n",
       "17459                            Jobspring Partners   \n",
       "17467                                        3coast   \n",
       "17481                                   Winston Fox   \n",
       "\n",
       "                                                Synopsis       Low      High  \\\n",
       "17086  Senior Data Scientist - Healthcare. Reporting ...  170000.0       NaN   \n",
       "17252  Data Scientist Qualifications:. Data Scientist...  120000.0  140000.0   \n",
       "17287  Salary 130K to 140K We are assisting our Clien...  130000.0  140000.0   \n",
       "17376  A leading healthcare analytical team, one of t...  100000.0  160000.0   \n",
       "17406  Scientist | Structure Elucidation*. Excellent ...  115000.0  145000.0   \n",
       "17421  In this role you will be extracting power plan...  100000.0  125000.0   \n",
       "17451  Analyze and interpret the results including st...   50000.0       NaN   \n",
       "17459  Experience with Data Mining. This agency, spec...  100000.0  130000.0   \n",
       "17467  Experience in data and time series analysis st...  150000.0  250000.0   \n",
       "17481  In this role, you will examine global markets,...  100000.0  110000.0   \n",
       "\n",
       "        Average  \n",
       "17086  170000.0  \n",
       "17252  130000.0  \n",
       "17287  135000.0  \n",
       "17376  130000.0  \n",
       "17406  130000.0  \n",
       "17421  112500.0  \n",
       "17451   50000.0  \n",
       "17459  115000.0  \n",
       "17467  200000.0  \n",
       "17481  105000.0  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_more = df_more.join(df_more['Location'].str.split(',', 1, expand=True).rename(columns={0:'City', 1:'State'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN 37220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>Data Scientist – Marketing Analytics</td>\n",
       "      <td>Chicago, IL 60601 (Loop area)</td>\n",
       "      <td>Enterprise Select</td>\n",
       "      <td>We are currently looking for an experienced Da...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60601 (Loop area)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Authority</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8197</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL 60606 (Loop area)</td>\n",
       "      <td>ICJIA</td>\n",
       "      <td>(3) analyzing qualitative and quantitative dat...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60606 (Loop area)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>Data Scientist (Python, R, AWS, Azure)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Our startup client working on risk and fraud d...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title                       Location  \\\n",
       "2724                Environmental Consultant            Nashville, TN 37220   \n",
       "8054    Data Scientist – Marketing Analytics  Chicago, IL 60601 (Loop area)   \n",
       "8194                        Research Analyst                    Chicago, IL   \n",
       "8197                        Research Analyst  Chicago, IL 60606 (Loop area)   \n",
       "8234  Data Scientist (Python, R, AWS, Azure)                    Chicago, IL   \n",
       "\n",
       "                                              Company  \\\n",
       "2724                                 LP Environmental   \n",
       "8054                                Enterprise Select   \n",
       "8194  Illinois Criminal Justice Information Authority   \n",
       "8197                                            ICJIA   \n",
       "8234                            Workbridge Associates   \n",
       "\n",
       "                                               Synopsis       Low      High  \\\n",
       "2724  We are seeking a mid-level Environmental Scien...   50000.0  100000.0   \n",
       "8054  We are currently looking for an experienced Da...  125000.0       NaN   \n",
       "8194  Produce analyses of crime trends and provide d...   55000.0   60000.0   \n",
       "8197  (3) analyzing qualitative and quantitative dat...   55000.0   60000.0   \n",
       "8234  Our startup client working on risk and fraud d...   85000.0  125000.0   \n",
       "\n",
       "       Average       City                  State  \n",
       "2724   75000.0  Nashville               TN 37220  \n",
       "8054  125000.0    Chicago   IL 60601 (Loop area)  \n",
       "8194   57500.0    Chicago                     IL  \n",
       "8197   57500.0    Chicago   IL 60606 (Loop area)  \n",
       "8234  105000.0    Chicago                     IL  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>State Initials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN 37220</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>Data Scientist – Marketing Analytics</td>\n",
       "      <td>Chicago, IL 60601 (Loop area)</td>\n",
       "      <td>Enterprise Select</td>\n",
       "      <td>We are currently looking for an experienced Da...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60601 (Loop area)</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Authority</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8197</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL 60606 (Loop area)</td>\n",
       "      <td>ICJIA</td>\n",
       "      <td>(3) analyzing qualitative and quantitative dat...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60606 (Loop area)</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>Data Scientist (Python, R, AWS, Azure)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Our startup client working on risk and fraud d...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title                       Location  \\\n",
       "2724                Environmental Consultant            Nashville, TN 37220   \n",
       "8054    Data Scientist – Marketing Analytics  Chicago, IL 60601 (Loop area)   \n",
       "8194                        Research Analyst                    Chicago, IL   \n",
       "8197                        Research Analyst  Chicago, IL 60606 (Loop area)   \n",
       "8234  Data Scientist (Python, R, AWS, Azure)                    Chicago, IL   \n",
       "\n",
       "                                              Company  \\\n",
       "2724                                 LP Environmental   \n",
       "8054                                Enterprise Select   \n",
       "8194  Illinois Criminal Justice Information Authority   \n",
       "8197                                            ICJIA   \n",
       "8234                            Workbridge Associates   \n",
       "\n",
       "                                               Synopsis       Low      High  \\\n",
       "2724  We are seeking a mid-level Environmental Scien...   50000.0  100000.0   \n",
       "8054  We are currently looking for an experienced Da...  125000.0       NaN   \n",
       "8194  Produce analyses of crime trends and provide d...   55000.0   60000.0   \n",
       "8197  (3) analyzing qualitative and quantitative dat...   55000.0   60000.0   \n",
       "8234  Our startup client working on risk and fraud d...   85000.0  125000.0   \n",
       "\n",
       "       Average       City                  State State Initials  \n",
       "2724   75000.0  Nashville               TN 37220             TN  \n",
       "8054  125000.0    Chicago   IL 60601 (Loop area)             IL  \n",
       "8194   57500.0    Chicago                     IL             IL  \n",
       "8197   57500.0    Chicago   IL 60606 (Loop area)             IL  \n",
       "8234  105000.0    Chicago                     IL             IL  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strip_state(x):\n",
    "    if x != None:\n",
    "        return x[0:3]\n",
    "    else:\n",
    "        None\n",
    "df_more['State Initials'] = df_more['State'].apply(strip_state)\n",
    "df_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "df_more.to_csv('Indeed_Project_3_df_cleaned.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>State Initials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN 37220</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist – Marketing Analytics</td>\n",
       "      <td>Chicago, IL 60601 (Loop area)</td>\n",
       "      <td>Enterprise Select</td>\n",
       "      <td>We are currently looking for an experienced Da...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60601 (Loop area)</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Authority</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL 60606 (Loop area)</td>\n",
       "      <td>ICJIA</td>\n",
       "      <td>(3) analyzing qualitative and quantitative dat...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60606 (Loop area)</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (Python, R, AWS, Azure)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Our startup client working on risk and fraud d...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Title                       Location  \\\n",
       "0                Environmental Consultant            Nashville, TN 37220   \n",
       "1    Data Scientist – Marketing Analytics  Chicago, IL 60601 (Loop area)   \n",
       "2                        Research Analyst                    Chicago, IL   \n",
       "3                        Research Analyst  Chicago, IL 60606 (Loop area)   \n",
       "4  Data Scientist (Python, R, AWS, Azure)                    Chicago, IL   \n",
       "\n",
       "                                           Company  \\\n",
       "0                                 LP Environmental   \n",
       "1                                Enterprise Select   \n",
       "2  Illinois Criminal Justice Information Authority   \n",
       "3                                            ICJIA   \n",
       "4                            Workbridge Associates   \n",
       "\n",
       "                                            Synopsis       Low      High  \\\n",
       "0  We are seeking a mid-level Environmental Scien...   50000.0  100000.0   \n",
       "1  We are currently looking for an experienced Da...  125000.0       NaN   \n",
       "2  Produce analyses of crime trends and provide d...   55000.0   60000.0   \n",
       "3  (3) analyzing qualitative and quantitative dat...   55000.0   60000.0   \n",
       "4  Our startup client working on risk and fraud d...   85000.0  125000.0   \n",
       "\n",
       "    Average       City                  State State Initials  \n",
       "0   75000.0  Nashville               TN 37220             TN  \n",
       "1  125000.0    Chicago   IL 60601 (Loop area)             IL  \n",
       "2   57500.0    Chicago                     IL             IL  \n",
       "3   57500.0    Chicago   IL 60606 (Loop area)             IL  \n",
       "4  105000.0    Chicago                     IL             IL  "
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more = pd.read_csv('/Users/aakashtandel/Desktop/Indeed_Project_3_df_cleaned.csv', index_col=0)\n",
    "df_more = df_more.reset_index(drop=True)\n",
    "df_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median salary for our data set is $86711.0\n"
     ]
    }
   ],
   "source": [
    "median = df_more['Average'].median()\n",
    "print ('The median salary for our data set is $' + str(median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>State Initials</th>\n",
       "      <th>Above Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Environmental Consultant</td>\n",
       "      <td>Nashville, TN 37220</td>\n",
       "      <td>LP Environmental</td>\n",
       "      <td>We are seeking a mid-level Environmental Scien...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN 37220</td>\n",
       "      <td>TN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist – Marketing Analytics</td>\n",
       "      <td>Chicago, IL 60601 (Loop area)</td>\n",
       "      <td>Enterprise Select</td>\n",
       "      <td>We are currently looking for an experienced Da...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60601 (Loop area)</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Illinois Criminal Justice Information Authority</td>\n",
       "      <td>Produce analyses of crime trends and provide d...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Chicago, IL 60606 (Loop area)</td>\n",
       "      <td>ICJIA</td>\n",
       "      <td>(3) analyzing qualitative and quantitative dat...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL 60606 (Loop area)</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (Python, R, AWS, Azure)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Our startup client working on risk and fraud d...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Title                       Location  \\\n",
       "0                Environmental Consultant            Nashville, TN 37220   \n",
       "1    Data Scientist – Marketing Analytics  Chicago, IL 60601 (Loop area)   \n",
       "2                        Research Analyst                    Chicago, IL   \n",
       "3                        Research Analyst  Chicago, IL 60606 (Loop area)   \n",
       "4  Data Scientist (Python, R, AWS, Azure)                    Chicago, IL   \n",
       "\n",
       "                                           Company  \\\n",
       "0                                 LP Environmental   \n",
       "1                                Enterprise Select   \n",
       "2  Illinois Criminal Justice Information Authority   \n",
       "3                                            ICJIA   \n",
       "4                            Workbridge Associates   \n",
       "\n",
       "                                            Synopsis       Low      High  \\\n",
       "0  We are seeking a mid-level Environmental Scien...   50000.0  100000.0   \n",
       "1  We are currently looking for an experienced Da...  125000.0       NaN   \n",
       "2  Produce analyses of crime trends and provide d...   55000.0   60000.0   \n",
       "3  (3) analyzing qualitative and quantitative dat...   55000.0   60000.0   \n",
       "4  Our startup client working on risk and fraud d...   85000.0  125000.0   \n",
       "\n",
       "    Average       City                  State State Initials  Above Median  \n",
       "0   75000.0  Nashville               TN 37220             TN             0  \n",
       "1  125000.0    Chicago   IL 60601 (Loop area)             IL             1  \n",
       "2   57500.0    Chicago                     IL             IL             0  \n",
       "3   57500.0    Chicago   IL 60606 (Loop area)             IL             0  \n",
       "4  105000.0    Chicago                     IL             IL             1  "
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def above_median(x):\n",
    "    if x > median:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Above Median'] = df_more['Average'].apply(above_median)\n",
    "df_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    205\n",
       "1    204\n",
       "Name: Above Median, dtype: int64"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more['Above Median'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline accuracy for our model would be about 50/50 because if we flipped a coin to determine whether or not a value is above or below the median, we have a 50/50 chance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary using Sklearn. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Albemarle County</th>\n",
       "      <th>Albuquerque</th>\n",
       "      <th>Anchorage</th>\n",
       "      <th>Arlington</th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Auburn</th>\n",
       "      <th>Aurora</th>\n",
       "      <th>Austin</th>\n",
       "      <th>Bakersfield</th>\n",
       "      <th>Baltimore</th>\n",
       "      <th>...</th>\n",
       "      <th>Tampa</th>\n",
       "      <th>Tampa Bay</th>\n",
       "      <th>Tempe</th>\n",
       "      <th>Tripler Army Medical Center</th>\n",
       "      <th>Tucson</th>\n",
       "      <th>Washington</th>\n",
       "      <th>West Point</th>\n",
       "      <th>Wichita</th>\n",
       "      <th>Wilmington</th>\n",
       "      <th>Woodlawn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Albemarle County  Albuquerque  Anchorage  Arlington  Atlanta  Auburn  \\\n",
       "0                 0            0          0          0        0       0   \n",
       "1                 0            0          0          0        0       0   \n",
       "2                 0            0          0          0        0       0   \n",
       "3                 0            0          0          0        0       0   \n",
       "4                 0            0          0          0        0       0   \n",
       "\n",
       "   Aurora  Austin  Bakersfield  Baltimore    ...     Tampa  Tampa Bay  Tempe  \\\n",
       "0       0       0            0          0    ...         0          0      0   \n",
       "1       0       0            0          0    ...         0          0      0   \n",
       "2       0       0            0          0    ...         0          0      0   \n",
       "3       0       0            0          0    ...         0          0      0   \n",
       "4       0       0            0          0    ...         0          0      0   \n",
       "\n",
       "   Tripler Army Medical Center  Tucson  Washington  West Point  Wichita  \\\n",
       "0                            0       0           0           0        0   \n",
       "1                            0       0           0           0        0   \n",
       "2                            0       0           0           0        0   \n",
       "3                            0       0           0           0        0   \n",
       "4                            0       0           0           0        0   \n",
       "\n",
       "   Wilmington  Woodlawn  \n",
       "0           0         0  \n",
       "1           0         0  \n",
       "2           0         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city_dummy = pd.get_dummies(df_more['City'])\n",
    "df_city_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AK</th>\n",
       "      <th>AZ</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>DC</th>\n",
       "      <th>DE</th>\n",
       "      <th>FL</th>\n",
       "      <th>GA</th>\n",
       "      <th>HI</th>\n",
       "      <th>IL</th>\n",
       "      <th>...</th>\n",
       "      <th>NV</th>\n",
       "      <th>NY</th>\n",
       "      <th>OH</th>\n",
       "      <th>OR</th>\n",
       "      <th>PA</th>\n",
       "      <th>TN</th>\n",
       "      <th>TX</th>\n",
       "      <th>VA</th>\n",
       "      <th>WA</th>\n",
       "      <th>WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AK   AZ   CA   CO   DC   DE   FL   GA   HI   IL ...    NV   NY   OH   OR  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    1 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    1 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    1 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    1 ...     0    0    0    0   \n",
       "\n",
       "    PA   TN   TX   VA   WA   WI  \n",
       "0    0    1    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state_dummy = pd.get_dummies(df_more['State Initials'])\n",
    "df_state_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.50724638  0.38235294  0.33823529  0.55882353  0.58823529  0.51470588]\n",
      "Average score: 0.481599886331\n",
      "Standard deviation of score: 0.0908219073371\n",
      "0.655256723716\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "X = df_city_dummy\n",
    "y = df_more['Above Median']\n",
    "cv_model = cross_val_score(model, X, y, cv=6)\n",
    "print 'Cross-validated scores:', cv_model\n",
    "print 'Average score:', cv_model.mean()\n",
    "print 'Standard deviation of score:', cv_model.std()\n",
    "model.fit(X, y)\n",
    "print (model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the city locations are slightly better than our baseline accuracy of 50/50. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title or whether 'Manager' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value?\n",
    "- After creating these variables, use count-vectorizer to create features based on the words in the job titles.\n",
    "- Build a new random forest model with location and these new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def senior(x):\n",
    "    if 'Senior' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Senior'] = df_more['Title'].apply(senior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>State Initials</th>\n",
       "      <th>Above Median</th>\n",
       "      <th>Senior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Senior Data Scientist / Machine Learning Engineer</td>\n",
       "      <td>Northbrook, IL</td>\n",
       "      <td>Request Technology</td>\n",
       "      <td>Seeking a Senior Data Scientist / Machine Lear...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Go2Group</td>\n",
       "      <td>Seeking a Data Scientist (Consultant to Archit...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>You will be building out new predictive models...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Senior Data Scientist - Modeling</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>TS Kandilit</td>\n",
       "      <td>Sr Data Scientist – Modeling. Candidates with ...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Full stack data scientists looking to grow wit...</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>122500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Senior Data Engineer (AWS RedShift, MySQL, Pyt...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Our client's Data Scientists and Engineers are...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>San Francisco, CA 94102 (Downtown area)</td>\n",
       "      <td>Aquila</td>\n",
       "      <td>Identify and own data latency and data quality...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA 94102 (Downtown area)</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Senior Data Scientist Healthcare</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>Senior Data Scientist - Healthcare. Reporting ...</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Senior Statistician/Data Scientist-PHARMA</td>\n",
       "      <td>Horsham, PA</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Statistician/Data Scientist Responsibilities. ...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Horsham</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Senior Front-End Engineer</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>One will be a web-based application used by da...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Senior Software Architect for Cybersecurity In...</td>\n",
       "      <td>Boulder, CO 80303 (Southeast Boulder area)</td>\n",
       "      <td>Technical Integrity</td>\n",
       "      <td>Designing and building large-scale and perform...</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO 80303 (Southeast Boulder area)</td>\n",
       "      <td>CO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Laboratory Quality Assurance Officer (Senior S...</td>\n",
       "      <td>Richmond, VA</td>\n",
       "      <td>Dept of General Services</td>\n",
       "      <td>This position will provide consultation and gu...</td>\n",
       "      <td>48681.0</td>\n",
       "      <td>60617.0</td>\n",
       "      <td>54649.0</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>VA</td>\n",
       "      <td>VA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Senior Analyst, Modeling</td>\n",
       "      <td>Richmond, VA</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Data Scientist Position Description:. 3+ years...</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>VA</td>\n",
       "      <td>VA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Data Scientist Senior</td>\n",
       "      <td>Albemarle County, VA</td>\n",
       "      <td>University of Virginia Health System</td>\n",
       "      <td>Provides guidance to less experienced data ana...</td>\n",
       "      <td>89523.0</td>\n",
       "      <td>143229.0</td>\n",
       "      <td>116376.0</td>\n",
       "      <td>Albemarle County</td>\n",
       "      <td>VA</td>\n",
       "      <td>VA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Senior Research Statistician</td>\n",
       "      <td>Columbus, OH 43212</td>\n",
       "      <td>Ohio State University Medical Center</td>\n",
       "      <td>Identifies or develops new statistical, analyt...</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>86000.0</td>\n",
       "      <td>78500.0</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>OH 43212</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Collaborate with a team of other data engineer...</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>Reston</td>\n",
       "      <td>VA 20190</td>\n",
       "      <td>VA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Responsibilities for the Lead Data Scientist i...</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>Reston</td>\n",
       "      <td>VA 20190</td>\n",
       "      <td>VA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Senior Product Manager</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Catalist</td>\n",
       "      <td>Conversant understanding of relational data an...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>DC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Senior Statistician</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Experience with data mining, discovery, classi...</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>75500.0</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Senior Research Scientist (Principal Investiga...</td>\n",
       "      <td>Austin, TX 78746</td>\n",
       "      <td>Gibson - An Education Consulting &amp; Research Group</td>\n",
       "      <td>Provide statistical consulting to clients rega...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX 78746</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin Fraser</td>\n",
       "      <td>SENIOR DATA ENGINEER (Lead). Austin, TX – Seni...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Senior Consultant, Advanced Analytics</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Logos Infotech Inc</td>\n",
       "      <td>The Senior consultant will collaboratively wor...</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Senior Market Research Analyst</td>\n",
       "      <td>San Antonio, TX 78258</td>\n",
       "      <td>Z&amp;A Recruiting</td>\n",
       "      <td>Data discovery, validation, analysis (i.e. Res...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX 78258</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Accounting Policy, Research and Special Projec...</td>\n",
       "      <td>Duluth, GA</td>\n",
       "      <td>JSP Recruitment Services</td>\n",
       "      <td>Accounting Policy, Research and Special Projec...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>GA</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Senior Statistical Consultant</td>\n",
       "      <td>Roswell, GA</td>\n",
       "      <td>Principle Solutions Group</td>\n",
       "      <td>Knowledge of credit bureau and alternative dat...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Roswell</td>\n",
       "      <td>GA</td>\n",
       "      <td>GA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Senior Laboratory Analyst</td>\n",
       "      <td>Farmington Hills, MI</td>\n",
       "      <td>Labs-Mart Inc.</td>\n",
       "      <td>Managing and interpreting analytical data. The...</td>\n",
       "      <td>50400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50400.0</td>\n",
       "      <td>Farmington Hills</td>\n",
       "      <td>MI</td>\n",
       "      <td>MI</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Senior Statistical Modeler</td>\n",
       "      <td>Dearborn, MI</td>\n",
       "      <td>JSP Recruitment Services</td>\n",
       "      <td>Verifying data for rate indications, rate revi...</td>\n",
       "      <td>87400.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>99700.0</td>\n",
       "      <td>Dearborn</td>\n",
       "      <td>MI</td>\n",
       "      <td>MI</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Senior Statistician - Credit Cards</td>\n",
       "      <td>Los Angeles, CA 90048</td>\n",
       "      <td>Seek Business Capital</td>\n",
       "      <td>Strong statistics and data analytics academic ...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA 90048</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Senior iOS Developer</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>LT</td>\n",
       "      <td>There is currently three Data Scientists. Data...</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Senior Statistician</td>\n",
       "      <td>Calabasas, CA</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Data Scientist Responsibilities:. Use programm...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Calabasas</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Research Nurse, Senior</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Knowledge of data management techniques. Compl...</td>\n",
       "      <td>46329.0</td>\n",
       "      <td>70715.0</td>\n",
       "      <td>58522.0</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Clinical Research Coordinator, Senior (Multipl...</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Create case report forms (CRFs) in consultatio...</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>53750.0</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Accountant, Senior (Phoenix, AZ)</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Adjusts to changing needs of university operat...</td>\n",
       "      <td>38200.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>45600.0</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Senior Data Scientist – Machine Learning</td>\n",
       "      <td>Morrisville, NC</td>\n",
       "      <td>Strivector</td>\n",
       "      <td>Senior Data Scientist – Machine Learning*. Men...</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Morrisville</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>HEAD DATA SCIENTIST. The Head Data Scientist i...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Senior Research Analyst, Bureau of Maternal In...</td>\n",
       "      <td>Queens, NY</td>\n",
       "      <td>DEPT OF HEALTH/MENTAL HYGIENE</td>\n",
       "      <td>Perform data analyses for routine reports, dat...</td>\n",
       "      <td>78630.0</td>\n",
       "      <td>102600.0</td>\n",
       "      <td>90615.0</td>\n",
       "      <td>Queens</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Senior Policy Analyst, Bureau of Children, You...</td>\n",
       "      <td>Queens, NY</td>\n",
       "      <td>DEPT OF HEALTH/MENTAL HYGIENE</td>\n",
       "      <td>Two years as a City Research Scientist Level I...</td>\n",
       "      <td>70286.0</td>\n",
       "      <td>80829.0</td>\n",
       "      <td>75557.5</td>\n",
       "      <td>Queens</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Senior Modeler</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>DEPARTMENT OF FINANCE</td>\n",
       "      <td>Construct mathematical models that predict the...</td>\n",
       "      <td>70286.0</td>\n",
       "      <td>80829.0</td>\n",
       "      <td>75557.5</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Senior Project Manager</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>HRA/DEPT OF SOCIAL SERVICES</td>\n",
       "      <td>Provide technical assistance on available data...</td>\n",
       "      <td>78630.0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>86565.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Senior Research Assistant - Neurosurgery Research</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>MD Anderson Cancer Center</td>\n",
       "      <td>Research scientists to design experiments invo...</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Senior Alcohol Beverage Applications Scientist</td>\n",
       "      <td>Florence, KY</td>\n",
       "      <td>Branford Search Consultants</td>\n",
       "      <td>Top Specialty Chemical Company seeks an Applic...</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>97500.0</td>\n",
       "      <td>Florence</td>\n",
       "      <td>KY</td>\n",
       "      <td>KY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Senior Data Science Analyst, Customer Advocacy...</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Liberty Mutual</td>\n",
       "      <td>Metrics &amp; Insights team in CAO is looking for ...</td>\n",
       "      <td>90301.0</td>\n",
       "      <td>114900.0</td>\n",
       "      <td>102600.5</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>MA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>NDEx Senior Developer</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>In-depth knowledge of bioinformatics methods, ...</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>93500.0</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Senior Software Engineer - Java</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>Sharpedge Solutions Inc.</td>\n",
       "      <td>_ data pipelines at scale, and real-time proce...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Analyst/Senior Analyst, Product Research</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Liberty Mutual</td>\n",
       "      <td>Analyst of Renewal Business Experience is resp...</td>\n",
       "      <td>73300.0</td>\n",
       "      <td>114900.0</td>\n",
       "      <td>94100.0</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Experience in complex data cleansing, data val...</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>212500.0</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Senior Data Scientist. Senior Data Scientist R...</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "19   Senior Data Scientist / Machine Learning Engineer   \n",
       "20                               Senior Data Scientist   \n",
       "24                               Senior Data Scientist   \n",
       "25                    Senior Data Scientist - Modeling   \n",
       "29                                Senior Data Engineer   \n",
       "31   Senior Data Engineer (AWS RedShift, MySQL, Pyt...   \n",
       "38                               Senior Data Scientist   \n",
       "50                    Senior Data Scientist Healthcare   \n",
       "65           Senior Statistician/Data Scientist-PHARMA   \n",
       "66                           Senior Front-End Engineer   \n",
       "72   Senior Software Architect for Cybersecurity In...   \n",
       "76   Laboratory Quality Assurance Officer (Senior S...   \n",
       "77                            Senior Analyst, Modeling   \n",
       "81                               Data Scientist Senior   \n",
       "96                        Senior Research Statistician   \n",
       "110                               Senior Data Engineer   \n",
       "114                              Senior Data Scientist   \n",
       "125                             Senior Product Manager   \n",
       "132                                Senior Statistician   \n",
       "135  Senior Research Scientist (Principal Investiga...   \n",
       "137                               Senior Data Engineer   \n",
       "145              Senior Consultant, Advanced Analytics   \n",
       "147                     Senior Market Research Analyst   \n",
       "156  Accounting Policy, Research and Special Projec...   \n",
       "169                      Senior Statistical Consultant   \n",
       "223                          Senior Laboratory Analyst   \n",
       "224                         Senior Statistical Modeler   \n",
       "232                 Senior Statistician - Credit Cards   \n",
       "237                               Senior iOS Developer   \n",
       "239                                Senior Statistician   \n",
       "247                             Research Nurse, Senior   \n",
       "252  Clinical Research Coordinator, Senior (Multipl...   \n",
       "253                   Accountant, Senior (Phoenix, AZ)   \n",
       "265           Senior Data Scientist – Machine Learning   \n",
       "273                              Senior Data Scientist   \n",
       "284  Senior Research Analyst, Bureau of Maternal In...   \n",
       "292  Senior Policy Analyst, Bureau of Children, You...   \n",
       "301                                     Senior Modeler   \n",
       "306                             Senior Project Manager   \n",
       "342  Senior Research Assistant - Neurosurgery Research   \n",
       "352     Senior Alcohol Beverage Applications Scientist   \n",
       "364  Senior Data Science Analyst, Customer Advocacy...   \n",
       "370                              NDEx Senior Developer   \n",
       "374                    Senior Software Engineer - Java   \n",
       "397           Analyst/Senior Analyst, Product Research   \n",
       "403                              Senior Data Scientist   \n",
       "405                              Senior Data Scientist   \n",
       "\n",
       "                                       Location  \\\n",
       "19                               Northbrook, IL   \n",
       "20                                  Chicago, IL   \n",
       "24                                  Chicago, IL   \n",
       "25                                  Chicago, IL   \n",
       "29                                  Chicago, IL   \n",
       "31                                  Chicago, IL   \n",
       "38      San Francisco, CA 94102 (Downtown area)   \n",
       "50                             Philadelphia, PA   \n",
       "65                                  Horsham, PA   \n",
       "66                             Philadelphia, PA   \n",
       "72   Boulder, CO 80303 (Southeast Boulder area)   \n",
       "76                                 Richmond, VA   \n",
       "77                                 Richmond, VA   \n",
       "81                         Albemarle County, VA   \n",
       "96                           Columbus, OH 43212   \n",
       "110                            Reston, VA 20190   \n",
       "114                            Reston, VA 20190   \n",
       "125                              Washington, DC   \n",
       "132                              Pittsburgh, PA   \n",
       "135                            Austin, TX 78746   \n",
       "137                                  Austin, TX   \n",
       "145                             San Antonio, TX   \n",
       "147                       San Antonio, TX 78258   \n",
       "156                                  Duluth, GA   \n",
       "169                                 Roswell, GA   \n",
       "223                        Farmington Hills, MI   \n",
       "224                                Dearborn, MI   \n",
       "232                       Los Angeles, CA 90048   \n",
       "237                             Los Angeles, CA   \n",
       "239                               Calabasas, CA   \n",
       "247                                  Tucson, AZ   \n",
       "252                                  Tucson, AZ   \n",
       "253                                  Tucson, AZ   \n",
       "265                             Morrisville, NC   \n",
       "273                             Los Angeles, CA   \n",
       "284                                  Queens, NY   \n",
       "292                                  Queens, NY   \n",
       "301                               Manhattan, NY   \n",
       "306                               Manhattan, NY   \n",
       "342                                 Houston, TX   \n",
       "352                                Florence, KY   \n",
       "364                                  Boston, MA   \n",
       "370                               San Diego, CA   \n",
       "374                               San Diego, CA   \n",
       "397                                 Seattle, WA   \n",
       "403                                 Seattle, WA   \n",
       "405                                 Seattle, WA   \n",
       "\n",
       "                                               Company  \\\n",
       "19                                  Request Technology   \n",
       "20                                            Go2Group   \n",
       "24                               Workbridge Associates   \n",
       "25                                         TS Kandilit   \n",
       "29                                  Jobspring Partners   \n",
       "31                               Workbridge Associates   \n",
       "38                                              Aquila   \n",
       "50                                             Harnham   \n",
       "65                             Smith Hanley Associates   \n",
       "66                                  Jobspring Partners   \n",
       "72                                 Technical Integrity   \n",
       "76                            Dept of General Services   \n",
       "77                             Smith Hanley Associates   \n",
       "81                University of Virginia Health System   \n",
       "96                Ohio State University Medical Center   \n",
       "110                                    Piper Companies   \n",
       "114                                    Piper Companies   \n",
       "125                                           Catalist   \n",
       "132                                   All-In Analytics   \n",
       "135  Gibson - An Education Consulting & Research Group   \n",
       "137                                      Austin Fraser   \n",
       "145                                 Logos Infotech Inc   \n",
       "147                                     Z&A Recruiting   \n",
       "156                           JSP Recruitment Services   \n",
       "169                          Principle Solutions Group   \n",
       "223                                     Labs-Mart Inc.   \n",
       "224                           JSP Recruitment Services   \n",
       "232                              Seek Business Capital   \n",
       "237                                                 LT   \n",
       "239                            Smith Hanley Associates   \n",
       "247                              University of Arizona   \n",
       "252                              University of Arizona   \n",
       "253                              University of Arizona   \n",
       "265                                         Strivector   \n",
       "273                                   All-In Analytics   \n",
       "284                      DEPT OF HEALTH/MENTAL HYGIENE   \n",
       "292                      DEPT OF HEALTH/MENTAL HYGIENE   \n",
       "301                              DEPARTMENT OF FINANCE   \n",
       "306                        HRA/DEPT OF SOCIAL SERVICES   \n",
       "342                          MD Anderson Cancer Center   \n",
       "352                        Branford Search Consultants   \n",
       "364                                     Liberty Mutual   \n",
       "370                                       UC San Diego   \n",
       "374                           Sharpedge Solutions Inc.   \n",
       "397                                     Liberty Mutual   \n",
       "403                                   All-In Analytics   \n",
       "405                            Smith Hanley Associates   \n",
       "\n",
       "                                              Synopsis       Low      High  \\\n",
       "19   Seeking a Senior Data Scientist / Machine Lear...  130000.0  135000.0   \n",
       "20   Seeking a Data Scientist (Consultant to Archit...  130000.0  190000.0   \n",
       "24   You will be building out new predictive models...  130000.0       NaN   \n",
       "25   Sr Data Scientist – Modeling. Candidates with ...  100000.0  125000.0   \n",
       "29   Full stack data scientists looking to grow wit...  115000.0  130000.0   \n",
       "31   Our client's Data Scientists and Engineers are...   80000.0  110000.0   \n",
       "38   Identify and own data latency and data quality...  100000.0  150000.0   \n",
       "50   Senior Data Scientist - Healthcare. Reporting ...  170000.0       NaN   \n",
       "65   Statistician/Data Scientist Responsibilities. ...  120000.0       NaN   \n",
       "66   One will be a web-based application used by da...  135000.0  155000.0   \n",
       "72   Designing and building large-scale and perform...  160000.0  180000.0   \n",
       "76   This position will provide consultation and gu...   48681.0   60617.0   \n",
       "77   Data Scientist Position Description:. 3+ years...   75000.0   90000.0   \n",
       "81   Provides guidance to less experienced data ana...   89523.0  143229.0   \n",
       "96   Identifies or develops new statistical, analyt...   71000.0   86000.0   \n",
       "110  Collaborate with a team of other data engineer...  190000.0  200000.0   \n",
       "114  Responsibilities for the Lead Data Scientist i...  200000.0  220000.0   \n",
       "125  Conversant understanding of relational data an...   70000.0  100000.0   \n",
       "132  Experience with data mining, discovery, classi...   53000.0   98000.0   \n",
       "135  Provide statistical consulting to clients rega...  110000.0  150000.0   \n",
       "137  SENIOR DATA ENGINEER (Lead). Austin, TX – Seni...  120000.0  150000.0   \n",
       "145  The Senior consultant will collaboratively wor...  117000.0       NaN   \n",
       "147  Data discovery, validation, analysis (i.e. Res...   80000.0   90000.0   \n",
       "156  Accounting Policy, Research and Special Projec...   70000.0   80000.0   \n",
       "169  Knowledge of credit bureau and alternative dat...  120000.0       NaN   \n",
       "223  Managing and interpreting analytical data. The...   50400.0       NaN   \n",
       "224  Verifying data for rate indications, rate revi...   87400.0  112000.0   \n",
       "232  Strong statistics and data analytics academic ...   65000.0   75000.0   \n",
       "237  There is currently three Data Scientists. Data...  170000.0       NaN   \n",
       "239  Data Scientist Responsibilities:. Use programm...  100000.0  140000.0   \n",
       "247  Knowledge of data management techniques. Compl...   46329.0   70715.0   \n",
       "252  Create case report forms (CRFs) in consultatio...   47500.0   60000.0   \n",
       "253  Adjusts to changing needs of university operat...   38200.0   53000.0   \n",
       "265  Senior Data Scientist – Machine Learning*. Men...  170000.0       NaN   \n",
       "273  HEAD DATA SCIENTIST. The Head Data Scientist i...  150000.0  180000.0   \n",
       "284  Perform data analyses for routine reports, dat...   78630.0  102600.0   \n",
       "292  Two years as a City Research Scientist Level I...   70286.0   80829.0   \n",
       "301  Construct mathematical models that predict the...   70286.0   80829.0   \n",
       "306  Provide technical assistance on available data...   78630.0   94500.0   \n",
       "342  Research scientists to design experiments invo...   38000.0   57000.0   \n",
       "352  Top Specialty Chemical Company seeks an Applic...   90000.0  105000.0   \n",
       "364  Metrics & Insights team in CAO is looking for ...   90301.0  114900.0   \n",
       "370  In-depth knowledge of bioinformatics methods, ...   75000.0  112000.0   \n",
       "374  _ data pipelines at scale, and real-time proce...  100000.0       NaN   \n",
       "397  Analyst of Renewal Business Experience is resp...   73300.0  114900.0   \n",
       "403  Experience in complex data cleansing, data val...  150000.0  275000.0   \n",
       "405  Senior Data Scientist. Senior Data Scientist R...  160000.0  180000.0   \n",
       "\n",
       "      Average              City                               State  \\\n",
       "19   132500.0        Northbrook                                  IL   \n",
       "20   160000.0           Chicago                                  IL   \n",
       "24   130000.0           Chicago                                  IL   \n",
       "25   112500.0           Chicago                                  IL   \n",
       "29   122500.0           Chicago                                  IL   \n",
       "31    95000.0           Chicago                                  IL   \n",
       "38   125000.0     San Francisco            CA 94102 (Downtown area)   \n",
       "50   170000.0      Philadelphia                                  PA   \n",
       "65   120000.0           Horsham                                  PA   \n",
       "66   145000.0      Philadelphia                                  PA   \n",
       "72   170000.0           Boulder   CO 80303 (Southeast Boulder area)   \n",
       "76    54649.0          Richmond                                  VA   \n",
       "77    82500.0          Richmond                                  VA   \n",
       "81   116376.0  Albemarle County                                  VA   \n",
       "96    78500.0          Columbus                            OH 43212   \n",
       "110  195000.0            Reston                            VA 20190   \n",
       "114  210000.0            Reston                            VA 20190   \n",
       "125   85000.0        Washington                                  DC   \n",
       "132   75500.0        Pittsburgh                                  PA   \n",
       "135  130000.0            Austin                            TX 78746   \n",
       "137  135000.0            Austin                                  TX   \n",
       "145  117000.0       San Antonio                                  TX   \n",
       "147   85000.0       San Antonio                            TX 78258   \n",
       "156   75000.0            Duluth                                  GA   \n",
       "169  120000.0           Roswell                                  GA   \n",
       "223   50400.0  Farmington Hills                                  MI   \n",
       "224   99700.0          Dearborn                                  MI   \n",
       "232   70000.0       Los Angeles                            CA 90048   \n",
       "237  170000.0       Los Angeles                                  CA   \n",
       "239  120000.0         Calabasas                                  CA   \n",
       "247   58522.0            Tucson                                  AZ   \n",
       "252   53750.0            Tucson                                  AZ   \n",
       "253   45600.0            Tucson                                  AZ   \n",
       "265  170000.0       Morrisville                                  NC   \n",
       "273  165000.0       Los Angeles                                  CA   \n",
       "284   90615.0            Queens                                  NY   \n",
       "292   75557.5            Queens                                  NY   \n",
       "301   75557.5         Manhattan                                  NY   \n",
       "306   86565.0         Manhattan                                  NY   \n",
       "342   47500.0           Houston                                  TX   \n",
       "352   97500.0          Florence                                  KY   \n",
       "364  102600.5            Boston                                  MA   \n",
       "370   93500.0         San Diego                                  CA   \n",
       "374  100000.0         San Diego                                  CA   \n",
       "397   94100.0           Seattle                                  WA   \n",
       "403  212500.0           Seattle                                  WA   \n",
       "405  170000.0           Seattle                                  WA   \n",
       "\n",
       "    State Initials  Above Median  Senior  \n",
       "19              IL             1       1  \n",
       "20              IL             1       1  \n",
       "24              IL             1       1  \n",
       "25              IL             1       1  \n",
       "29              IL             1       1  \n",
       "31              IL             1       1  \n",
       "38              CA             1       1  \n",
       "50              PA             1       1  \n",
       "65              PA             1       1  \n",
       "66              PA             1       1  \n",
       "72              CO             1       1  \n",
       "76              VA             0       1  \n",
       "77              VA             0       1  \n",
       "81              VA             1       1  \n",
       "96              OH             0       1  \n",
       "110             VA             1       1  \n",
       "114             VA             1       1  \n",
       "125             DC             0       1  \n",
       "132             PA             0       1  \n",
       "135             TX             1       1  \n",
       "137             TX             1       1  \n",
       "145             TX             1       1  \n",
       "147             TX             0       1  \n",
       "156             GA             0       1  \n",
       "169             GA             1       1  \n",
       "223             MI             0       1  \n",
       "224             MI             1       1  \n",
       "232             CA             0       1  \n",
       "237             CA             1       1  \n",
       "239             CA             1       1  \n",
       "247             AZ             0       1  \n",
       "252             AZ             0       1  \n",
       "253             AZ             0       1  \n",
       "265             NC             1       1  \n",
       "273             CA             1       1  \n",
       "284             NY             1       1  \n",
       "292             NY             0       1  \n",
       "301             NY             0       1  \n",
       "306             NY             0       1  \n",
       "342             TX             0       1  \n",
       "352             KY             1       1  \n",
       "364             MA             1       1  \n",
       "370             CA             1       1  \n",
       "374             CA             1       1  \n",
       "397             WA             1       1  \n",
       "403             WA             1       1  \n",
       "405             WA             1       1  "
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more[df_more.Senior != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manager(x):\n",
    "    if 'Manager' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Manager'] = df_more['Title'].apply(manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>State Initials</th>\n",
       "      <th>Above Median</th>\n",
       "      <th>Senior</th>\n",
       "      <th>Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>District Sales Manager</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>Anchor Point Technology Resources</td>\n",
       "      <td>Ability to handle technical processes, data ga...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Laboratory Manager, IRL Blood Bank</td>\n",
       "      <td>Central, IN</td>\n",
       "      <td>Lighthouse Recruiting</td>\n",
       "      <td>Join the New Medical Laboratory Scientists Gro...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>78500.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Computational Image Data Analysis Manager</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>Medical Science &amp; Computing</td>\n",
       "      <td>Analysis of biopsy and resection samples from ...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Bethesda</td>\n",
       "      <td>MD</td>\n",
       "      <td>MD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Senior Product Manager</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Catalist</td>\n",
       "      <td>Conversant understanding of relational data an...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "      <td>DC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2017-07-10 IT Program Manager Earning $$213,000</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>EMF Industries</td>\n",
       "      <td>Our talented group of Data Scientists, Develop...</td>\n",
       "      <td>213000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213000.0</td>\n",
       "      <td>McLean</td>\n",
       "      <td>VA</td>\n",
       "      <td>VA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Account Manager</td>\n",
       "      <td>Charlotte, NC 28204 (Elizabeth area)</td>\n",
       "      <td>The Creative Group</td>\n",
       "      <td>You're fascinated by data analytics:. You may ...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC 28204 (Elizabeth area)</td>\n",
       "      <td>NC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Analytics Manager (Machine Learning)</td>\n",
       "      <td>Charlotte, NC</td>\n",
       "      <td>Kennedy Unlimited Inc, Professional Staffing</td>\n",
       "      <td>8 Plus years of modeling experience in Big Dat...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>District Sales Manager</td>\n",
       "      <td>Wichita, KS</td>\n",
       "      <td>Anchor Point Technology Resources</td>\n",
       "      <td>Ability to handle technical processes, data ga...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>KS</td>\n",
       "      <td>KS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Laboratory Manager, Pulmonary and Endothelial ...</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Carry out laboratory processing of samples, in...</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Accounting Manager (Phoenix, Arizona)</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Interprets various accounting data, analyzes r...</td>\n",
       "      <td>48645.0</td>\n",
       "      <td>74251.0</td>\n",
       "      <td>61448.0</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>AZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Data Manager/Statistician</td>\n",
       "      <td>Stony Brook, NY</td>\n",
       "      <td>Stony Brook University</td>\n",
       "      <td>Compliant data analysis. Biostatistics and dat...</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>Stony Brook</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Office Manager</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>AiCure</td>\n",
       "      <td>Learn how we combine machine learning, compute...</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Senior Project Manager</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>HRA/DEPT OF SOCIAL SERVICES</td>\n",
       "      <td>Provide technical assistance on available data...</td>\n",
       "      <td>78630.0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>86565.0</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Sr. Technical Laboratory Manager</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>This individual will also work closely with mu...</td>\n",
       "      <td>59159.0</td>\n",
       "      <td>81406.0</td>\n",
       "      <td>70282.5</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>MD</td>\n",
       "      <td>MD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Public Health Laboratory Manager</td>\n",
       "      <td>El Paso, TX</td>\n",
       "      <td>City of El Paso</td>\n",
       "      <td>Medical Technologist (MT), Medical Laboratory ...</td>\n",
       "      <td>55634.0</td>\n",
       "      <td>77748.0</td>\n",
       "      <td>66691.0</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Manager / Director of Storage</td>\n",
       "      <td>Cambridge, MA 02138 (West Cambridge area)</td>\n",
       "      <td>WinterWyman</td>\n",
       "      <td>Strong familiarity with Enterprise Storage and...</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>MA 02138 (West Cambridge area)</td>\n",
       "      <td>MA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Regulatory Project Manager (Interdisciplinary)</td>\n",
       "      <td>Sacramento, CA</td>\n",
       "      <td>Department of the Army</td>\n",
       "      <td>Physical Scientist (1301). Applicant's claimin...</td>\n",
       "      <td>43895.0</td>\n",
       "      <td>57067.0</td>\n",
       "      <td>50481.0</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Industry Relations Manager</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>University of Portland</td>\n",
       "      <td>Compile, analyze, and report relevant data. Ex...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>Portland</td>\n",
       "      <td>OR</td>\n",
       "      <td>OR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Project Program Manager III</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>King County</td>\n",
       "      <td>Analyze complex data, policy, practices, syste...</td>\n",
       "      <td>80413.0</td>\n",
       "      <td>101920.0</td>\n",
       "      <td>91166.5</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Capital Projects Delivery Program Manager</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>King County</td>\n",
       "      <td>Accumulate historical data, such as performanc...</td>\n",
       "      <td>84302.0</td>\n",
       "      <td>101920.0</td>\n",
       "      <td>93111.0</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>District Sales Manager</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Anchor Point Technology Resources</td>\n",
       "      <td>Ability to handle technical processes, data ga...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "43                              District Sales Manager   \n",
       "79                  Laboratory Manager, IRL Blood Bank   \n",
       "112          Computational Image Data Analysis Manager   \n",
       "125                             Senior Product Manager   \n",
       "183    2017-07-10 IT Program Manager Earning $$213,000   \n",
       "199                                    Account Manager   \n",
       "203               Analytics Manager (Machine Learning)   \n",
       "221                             District Sales Manager   \n",
       "241  Laboratory Manager, Pulmonary and Endothelial ...   \n",
       "254              Accounting Manager (Phoenix, Arizona)   \n",
       "275                          Data Manager/Statistician   \n",
       "294                                     Office Manager   \n",
       "306                             Senior Project Manager   \n",
       "316                   Sr. Technical Laboratory Manager   \n",
       "353                   Public Health Laboratory Manager   \n",
       "363                      Manager / Director of Storage   \n",
       "382     Regulatory Project Manager (Interdisciplinary)   \n",
       "387                         Industry Relations Manager   \n",
       "394                        Project Program Manager III   \n",
       "395          Capital Projects Delivery Program Manager   \n",
       "404                             District Sales Manager   \n",
       "\n",
       "                                      Location  \\\n",
       "43                                  Dallas, TX   \n",
       "79                                 Central, IN   \n",
       "112                               Bethesda, MD   \n",
       "125                             Washington, DC   \n",
       "183                                 McLean, VA   \n",
       "199       Charlotte, NC 28204 (Elizabeth area)   \n",
       "203                              Charlotte, NC   \n",
       "221                                Wichita, KS   \n",
       "241                                 Tucson, AZ   \n",
       "254                                 Tucson, AZ   \n",
       "275                            Stony Brook, NY   \n",
       "294                               New York, NY   \n",
       "306                              Manhattan, NY   \n",
       "316                              Baltimore, MD   \n",
       "353                                El Paso, TX   \n",
       "363  Cambridge, MA 02138 (West Cambridge area)   \n",
       "382                             Sacramento, CA   \n",
       "387                               Portland, OR   \n",
       "394                                Seattle, WA   \n",
       "395                                Seattle, WA   \n",
       "404                                Seattle, WA   \n",
       "\n",
       "                                          Company  \\\n",
       "43              Anchor Point Technology Resources   \n",
       "79                          Lighthouse Recruiting   \n",
       "112                   Medical Science & Computing   \n",
       "125                                      Catalist   \n",
       "183                                EMF Industries   \n",
       "199                            The Creative Group   \n",
       "203  Kennedy Unlimited Inc, Professional Staffing   \n",
       "221             Anchor Point Technology Resources   \n",
       "241                         University of Arizona   \n",
       "254                         University of Arizona   \n",
       "275                        Stony Brook University   \n",
       "294                                        AiCure   \n",
       "306                   HRA/DEPT OF SOCIAL SERVICES   \n",
       "316                      Johns Hopkins University   \n",
       "353                               City of El Paso   \n",
       "363                                   WinterWyman   \n",
       "382                        Department of the Army   \n",
       "387                        University of Portland   \n",
       "394                                   King County   \n",
       "395                                   King County   \n",
       "404             Anchor Point Technology Resources   \n",
       "\n",
       "                                              Synopsis       Low      High  \\\n",
       "43   Ability to handle technical processes, data ga...  100000.0       NaN   \n",
       "79   Join the New Medical Laboratory Scientists Gro...   70000.0   87000.0   \n",
       "112  Analysis of biopsy and resection samples from ...  100000.0       NaN   \n",
       "125  Conversant understanding of relational data an...   70000.0  100000.0   \n",
       "183  Our talented group of Data Scientists, Develop...  213000.0       NaN   \n",
       "199  You're fascinated by data analytics:. You may ...   50000.0   60000.0   \n",
       "203  8 Plus years of modeling experience in Big Dat...  120000.0  150000.0   \n",
       "221  Ability to handle technical processes, data ga...  100000.0       NaN   \n",
       "241  Carry out laboratory processing of samples, in...   60000.0   80000.0   \n",
       "254  Interprets various accounting data, analyzes r...   48645.0   74251.0   \n",
       "275  Compliant data analysis. Biostatistics and dat...   52000.0   62000.0   \n",
       "294  Learn how we combine machine learning, compute...   40000.0   50000.0   \n",
       "306  Provide technical assistance on available data...   78630.0   94500.0   \n",
       "316  This individual will also work closely with mu...   59159.0   81406.0   \n",
       "353  Medical Technologist (MT), Medical Laboratory ...   55634.0   77748.0   \n",
       "363  Strong familiarity with Enterprise Storage and...  160000.0       NaN   \n",
       "382  Physical Scientist (1301). Applicant's claimin...   43895.0   57067.0   \n",
       "387  Compile, analyze, and report relevant data. Ex...   55000.0   65000.0   \n",
       "394  Analyze complex data, policy, practices, syste...   80413.0  101920.0   \n",
       "395  Accumulate historical data, such as performanc...   84302.0  101920.0   \n",
       "404  Ability to handle technical processes, data ga...  100000.0       NaN   \n",
       "\n",
       "      Average         City                            State State Initials  \\\n",
       "43   100000.0       Dallas                               TX             TX   \n",
       "79    78500.0      Central                               IN             IN   \n",
       "112  100000.0     Bethesda                               MD             MD   \n",
       "125   85000.0   Washington                               DC             DC   \n",
       "183  213000.0       McLean                               VA             VA   \n",
       "199   55000.0    Charlotte        NC 28204 (Elizabeth area)             NC   \n",
       "203  135000.0    Charlotte                               NC             NC   \n",
       "221  100000.0      Wichita                               KS             KS   \n",
       "241   70000.0       Tucson                               AZ             AZ   \n",
       "254   61448.0       Tucson                               AZ             AZ   \n",
       "275   57000.0  Stony Brook                               NY             NY   \n",
       "294   45000.0     New York                               NY             NY   \n",
       "306   86565.0    Manhattan                               NY             NY   \n",
       "316   70282.5    Baltimore                               MD             MD   \n",
       "353   66691.0      El Paso                               TX             TX   \n",
       "363  160000.0    Cambridge   MA 02138 (West Cambridge area)             MA   \n",
       "382   50481.0   Sacramento                               CA             CA   \n",
       "387   60000.0     Portland                               OR             OR   \n",
       "394   91166.5      Seattle                               WA             WA   \n",
       "395   93111.0      Seattle                               WA             WA   \n",
       "404  100000.0      Seattle                               WA             WA   \n",
       "\n",
       "     Above Median  Senior  Manager  \n",
       "43              1       0        1  \n",
       "79              0       0        1  \n",
       "112             1       0        1  \n",
       "125             0       1        1  \n",
       "183             1       0        1  \n",
       "199             0       0        1  \n",
       "203             1       0        1  \n",
       "221             1       0        1  \n",
       "241             0       0        1  \n",
       "254             0       0        1  \n",
       "275             0       0        1  \n",
       "294             0       0        1  \n",
       "306             0       1        1  \n",
       "316             0       0        1  \n",
       "353             0       0        1  \n",
       "363             1       0        1  \n",
       "382             0       0        1  \n",
       "387             0       0        1  \n",
       "394             1       0        1  \n",
       "395             1       0        1  \n",
       "404             1       0        1  "
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more[df_more.Manager != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def engineer(x):\n",
    "    if 'Engineer' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Engineer'] = df_more['Title'].apply(engineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Average</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>State Initials</th>\n",
       "      <th>Above Median</th>\n",
       "      <th>Senior</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Engineer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist/Engineer</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>They would ideally have a STEM/Quantitative de...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Senior Data Scientist / Machine Learning Engineer</td>\n",
       "      <td>Northbrook, IL</td>\n",
       "      <td>Request Technology</td>\n",
       "      <td>Seeking a Senior Data Scientist / Machine Lear...</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>Northbrook</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Engineer/Scientist</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Big Data experience with Hadoop, Spark, Pig. A...</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Machine Learning Engineer (Ruby)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Experience working with electronic medical rec...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Software Engineer (Python)</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Brand new product that is used globally by the...</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Full stack data scientists looking to grow wit...</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>122500.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Civil/ Environmental Engineer</td>\n",
       "      <td>Lombard, IL 60148</td>\n",
       "      <td>Andrews Engineering, Inc.</td>\n",
       "      <td>Analyzing Data or Information. Collaborate wit...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Lombard</td>\n",
       "      <td>IL 60148</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Senior Data Engineer (AWS RedShift, MySQL, Pyt...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Our client's Data Scientists and Engineers are...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sales Engineer</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Pentaho a Hitachi Company</td>\n",
       "      <td>ETL, data warehousing and data engineering. Co...</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>CEI</td>\n",
       "      <td>Data Analytics Engineer*. An experienced data ...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Data Scientist/Optimization Engineer</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>In this role you will be extracting power plan...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>They are looking for a Data Scientist, special...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Philadelphia, PA 19107 (City Center East area)</td>\n",
       "      <td>Juno Search Partners</td>\n",
       "      <td>Their academic platform helps answer questions...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA 19107 (City Center East area)</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Senior Front-End Engineer</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>One will be a web-based application used by da...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Interdisciplinary (General Engineer, Electroni...</td>\n",
       "      <td>Charlottesville, VA</td>\n",
       "      <td>Department of the Army</td>\n",
       "      <td>And/or Knowledge of organization(s) for and me...</td>\n",
       "      <td>40684.0</td>\n",
       "      <td>52893.0</td>\n",
       "      <td>46788.5</td>\n",
       "      <td>Charlottesville</td>\n",
       "      <td>VA</td>\n",
       "      <td>VA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Reston, VA 20190</td>\n",
       "      <td>Piper Companies</td>\n",
       "      <td>Collaborate with a team of other data engineer...</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>Reston</td>\n",
       "      <td>VA 20190</td>\n",
       "      <td>VA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Embedded Engineer Intern</td>\n",
       "      <td>Herndon, VA</td>\n",
       "      <td>digiBlitz Inc</td>\n",
       "      <td>Implementation and integration of heterogeneou...</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>Herndon</td>\n",
       "      <td>VA</td>\n",
       "      <td>VA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Engineering Scientist - R and D Algorithm and ...</td>\n",
       "      <td>Austin, TX 78758 (North Austin area)</td>\n",
       "      <td>Applied Research Laboratories, The University ...</td>\n",
       "      <td>Knowledge of digital signal processing, image ...</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX 78758 (North Austin area)</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>CareerMonks</td>\n",
       "      <td>Experience with integration of data from multi...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin Fraser</td>\n",
       "      <td>SENIOR DATA ENGINEER (Lead). Austin, TX – Seni...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Computer Scientist/Software Engineer</td>\n",
       "      <td>Austin, TX 78759 (Arboretum area)</td>\n",
       "      <td>Signature Science, LLC</td>\n",
       "      <td>Computer Science support to the research, deve...</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX 78759 (Arboretum area)</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Software Development Engineers (Core Java)</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Winston Fox</td>\n",
       "      <td>In this role you will be working across the SD...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Python Full Stack Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>HireIQ Solutions, Inc.</td>\n",
       "      <td>Work with our data scientist on our cutting ed...</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>GA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Sr. Biochemical Automation Workflow Engineer - RT</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Absolute Opportunities</td>\n",
       "      <td>Fine-tuning sample preparation applications in...</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>GA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Systems Software Engineer</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Emory University</td>\n",
       "      <td>Strong willingness to adhere to the security r...</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Civil Engineer (Structural)</td>\n",
       "      <td>Memphis, TN</td>\n",
       "      <td>Department of the Army</td>\n",
       "      <td>This is a Career Program (CP)-18, Engineers &amp; ...</td>\n",
       "      <td>60210.0</td>\n",
       "      <td>93821.0</td>\n",
       "      <td>77015.5</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>TN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Software Engineer - Entry/Mid-Level</td>\n",
       "      <td>Fort Meade, MD</td>\n",
       "      <td>National Security Agency</td>\n",
       "      <td>As a Computer Scientist, you may be part of a ...</td>\n",
       "      <td>68586.0</td>\n",
       "      <td>85464.0</td>\n",
       "      <td>77025.0</td>\n",
       "      <td>Fort Meade</td>\n",
       "      <td>MD</td>\n",
       "      <td>MD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Research Computer Engineer, AST, Data Systems</td>\n",
       "      <td>Hampton, VA</td>\n",
       "      <td>National Aeronautics and Space Administration</td>\n",
       "      <td>For Data Analysis, Modeling and Theoretical Si...</td>\n",
       "      <td>72168.0</td>\n",
       "      <td>111560.0</td>\n",
       "      <td>91864.0</td>\n",
       "      <td>Hampton</td>\n",
       "      <td>VA</td>\n",
       "      <td>VA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Environmental Scientist/Engineer</td>\n",
       "      <td>Cleveland, OH</td>\n",
       "      <td>Pacific Western Technologies, Ltd.</td>\n",
       "      <td>Consulting Oportunities for Environmental scie...</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Software Engineer/Data Scientist, C/C++, Pytho...</td>\n",
       "      <td>Pasadena, CA</td>\n",
       "      <td>ANRE Technologies Inc.</td>\n",
       "      <td>Scikit-learn, SciPy, Apache Big Data Suite, op...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>This engineer will work alongside data scienti...</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Scientist, Bureau of Environmental Sciences an...</td>\n",
       "      <td>Queens, NY</td>\n",
       "      <td>DEPT OF HEALTH/MENTAL HYGIENE</td>\n",
       "      <td>-Supporting the development and implementation...</td>\n",
       "      <td>59708.0</td>\n",
       "      <td>65678.0</td>\n",
       "      <td>62693.0</td>\n",
       "      <td>Queens</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Client Facing Python Engineers for A.I data co...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Birch &amp; James Associates Limited</td>\n",
       "      <td>An interest in machine learning and/or data sc...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Full-Stack Engineer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>605</td>\n",
       "      <td>Our team of data scientists pioneered the fiel...</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Data Scientist- Engineer</td>\n",
       "      <td>New York State</td>\n",
       "      <td>The Talent Solution</td>\n",
       "      <td>A rapidly growing media and online content dis...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>New York State</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Sr. Data Engineer / Developer for Machine Lear...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Averity</td>\n",
       "      <td>Data Engineer, you will be responsible for hel...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Principal Environmental Engineer</td>\n",
       "      <td>Laurel, MD 20707</td>\n",
       "      <td>WSSC</td>\n",
       "      <td>Ability to plan and oversee the work of profes...</td>\n",
       "      <td>75515.0</td>\n",
       "      <td>115278.0</td>\n",
       "      <td>95396.5</td>\n",
       "      <td>Laurel</td>\n",
       "      <td>MD 20707</td>\n",
       "      <td>MD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Head of Engineering - Accounting Platform</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Oscar Technology</td>\n",
       "      <td>They are a leading investment data analysis fi...</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Industrial Engineering Technician</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>Department of the Navy</td>\n",
       "      <td>Incorporation of technical data changes. Analy...</td>\n",
       "      <td>44899.0</td>\n",
       "      <td>86378.0</td>\n",
       "      <td>65638.5</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Senior Software Engineer - Java</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>Sharpedge Solutions Inc.</td>\n",
       "      <td>_ data pipelines at scale, and real-time proce...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>University of South Florida</td>\n",
       "      <td>As a part of the Data Engineering team, the Da...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Sr. Data Engineer</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>University of South Florida</td>\n",
       "      <td>Data Engineer’s efforts will span the data lif...</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Software Engineer - Machine Learning</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>NxT Level</td>\n",
       "      <td>We are looking for a passionate Data Scientist...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>117500.0</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "14                             Data Scientist/Engineer   \n",
       "19   Senior Data Scientist / Machine Learning Engineer   \n",
       "21                             Data Engineer/Scientist   \n",
       "22                    Machine Learning Engineer (Ruby)   \n",
       "26                          Software Engineer (Python)   \n",
       "29                                Senior Data Engineer   \n",
       "30                       Civil/ Environmental Engineer   \n",
       "31   Senior Data Engineer (AWS RedShift, MySQL, Pyt...   \n",
       "39                                      Sales Engineer   \n",
       "49                             Data Analytics Engineer   \n",
       "55                Data Scientist/Optimization Engineer   \n",
       "60                           Machine Learning Engineer   \n",
       "64                                     DevOps Engineer   \n",
       "66                           Senior Front-End Engineer   \n",
       "83   Interdisciplinary (General Engineer, Electroni...   \n",
       "110                               Senior Data Engineer   \n",
       "120                           Embedded Engineer Intern   \n",
       "133  Engineering Scientist - R and D Algorithm and ...   \n",
       "134                                  Big Data Engineer   \n",
       "137                               Senior Data Engineer   \n",
       "138               Computer Scientist/Software Engineer   \n",
       "139         Software Development Engineers (Core Java)   \n",
       "149                         Python Full Stack Engineer   \n",
       "166  Sr. Biochemical Automation Workflow Engineer - RT   \n",
       "167                          Systems Software Engineer   \n",
       "173                        Civil Engineer (Structural)   \n",
       "177                Software Engineer - Entry/Mid-Level   \n",
       "195      Research Computer Engineer, AST, Data Systems   \n",
       "218                   Environmental Scientist/Engineer   \n",
       "228  Software Engineer/Data Scientist, C/C++, Pytho...   \n",
       "234                                  Big Data Engineer   \n",
       "274  Scientist, Bureau of Environmental Sciences an...   \n",
       "279  Client Facing Python Engineers for A.I data co...   \n",
       "291                                Full-Stack Engineer   \n",
       "296                           Data Scientist- Engineer   \n",
       "309  Sr. Data Engineer / Developer for Machine Lear...   \n",
       "322                   Principal Environmental Engineer   \n",
       "348          Head of Engineering - Accounting Platform   \n",
       "372                  Industrial Engineering Technician   \n",
       "374                    Senior Software Engineer - Java   \n",
       "378                                      Data Engineer   \n",
       "379                                  Sr. Data Engineer   \n",
       "401               Software Engineer - Machine Learning   \n",
       "\n",
       "                                           Location  \\\n",
       "14                                      Chicago, IL   \n",
       "19                                   Northbrook, IL   \n",
       "21                                      Chicago, IL   \n",
       "22                                      Chicago, IL   \n",
       "26                                      Chicago, IL   \n",
       "29                                      Chicago, IL   \n",
       "30                                Lombard, IL 60148   \n",
       "31                                      Chicago, IL   \n",
       "39                                San Francisco, CA   \n",
       "49                                 Philadelphia, PA   \n",
       "55                                 Philadelphia, PA   \n",
       "60                                 Philadelphia, PA   \n",
       "64   Philadelphia, PA 19107 (City Center East area)   \n",
       "66                                 Philadelphia, PA   \n",
       "83                              Charlottesville, VA   \n",
       "110                                Reston, VA 20190   \n",
       "120                                     Herndon, VA   \n",
       "133            Austin, TX 78758 (North Austin area)   \n",
       "134                                      Austin, TX   \n",
       "137                                      Austin, TX   \n",
       "138               Austin, TX 78759 (Arboretum area)   \n",
       "139                                      Austin, TX   \n",
       "149                                     Atlanta, GA   \n",
       "166                                     Atlanta, GA   \n",
       "167                                     Atlanta, GA   \n",
       "173                                     Memphis, TN   \n",
       "177                                  Fort Meade, MD   \n",
       "195                                     Hampton, VA   \n",
       "218                                   Cleveland, OH   \n",
       "228                                    Pasadena, CA   \n",
       "234                                 Los Angeles, CA   \n",
       "274                                      Queens, NY   \n",
       "279                                    New York, NY   \n",
       "291                                    New York, NY   \n",
       "296                                  New York State   \n",
       "309                                    New York, NY   \n",
       "322                                Laurel, MD 20707   \n",
       "348                                     Houston, TX   \n",
       "372                                   San Diego, CA   \n",
       "374                                   San Diego, CA   \n",
       "378                                       Tampa, FL   \n",
       "379                                       Tampa, FL   \n",
       "401                                     Seattle, WA   \n",
       "\n",
       "                                               Company  \\\n",
       "14                                  Jobspring Partners   \n",
       "19                                  Request Technology   \n",
       "21                               Workbridge Associates   \n",
       "22                                  Jobspring Partners   \n",
       "26                                  Jobspring Partners   \n",
       "29                                  Jobspring Partners   \n",
       "30                           Andrews Engineering, Inc.   \n",
       "31                               Workbridge Associates   \n",
       "39                           Pentaho a Hitachi Company   \n",
       "49                                                 CEI   \n",
       "55                                  Jobspring Partners   \n",
       "60                                  Jobspring Partners   \n",
       "64                                Juno Search Partners   \n",
       "66                                  Jobspring Partners   \n",
       "83                              Department of the Army   \n",
       "110                                    Piper Companies   \n",
       "120                                      digiBlitz Inc   \n",
       "133  Applied Research Laboratories, The University ...   \n",
       "134                                        CareerMonks   \n",
       "137                                      Austin Fraser   \n",
       "138                             Signature Science, LLC   \n",
       "139                                        Winston Fox   \n",
       "149                             HireIQ Solutions, Inc.   \n",
       "166                             Absolute Opportunities   \n",
       "167                                   Emory University   \n",
       "173                             Department of the Army   \n",
       "177                           National Security Agency   \n",
       "195      National Aeronautics and Space Administration   \n",
       "218                 Pacific Western Technologies, Ltd.   \n",
       "228                             ANRE Technologies Inc.   \n",
       "234                                 Jobspring Partners   \n",
       "274                      DEPT OF HEALTH/MENTAL HYGIENE   \n",
       "279                   Birch & James Associates Limited   \n",
       "291                                                605   \n",
       "296                                The Talent Solution   \n",
       "309                                            Averity   \n",
       "322                                               WSSC   \n",
       "348                                   Oscar Technology   \n",
       "372                             Department of the Navy   \n",
       "374                           Sharpedge Solutions Inc.   \n",
       "378                        University of South Florida   \n",
       "379                        University of South Florida   \n",
       "401                                          NxT Level   \n",
       "\n",
       "                                              Synopsis       Low      High  \\\n",
       "14   They would ideally have a STEM/Quantitative de...   70000.0   80000.0   \n",
       "19   Seeking a Senior Data Scientist / Machine Lear...  130000.0  135000.0   \n",
       "21   Big Data experience with Hadoop, Spark, Pig. A...   90000.0  125000.0   \n",
       "22   Experience working with electronic medical rec...  110000.0  130000.0   \n",
       "26   Brand new product that is used globally by the...   75000.0  110000.0   \n",
       "29   Full stack data scientists looking to grow wit...  115000.0  130000.0   \n",
       "30   Analyzing Data or Information. Collaborate wit...   50000.0   65000.0   \n",
       "31   Our client's Data Scientists and Engineers are...   80000.0  110000.0   \n",
       "39   ETL, data warehousing and data engineering. Co...  190000.0  200000.0   \n",
       "49   Data Analytics Engineer*. An experienced data ...   85000.0       NaN   \n",
       "55   In this role you will be extracting power plan...  100000.0  125000.0   \n",
       "60   They are looking for a Data Scientist, special...  110000.0  160000.0   \n",
       "64   Their academic platform helps answer questions...  100000.0  120000.0   \n",
       "66   One will be a web-based application used by da...  135000.0  155000.0   \n",
       "83   And/or Knowledge of organization(s) for and me...   40684.0   52893.0   \n",
       "110  Collaborate with a team of other data engineer...  190000.0  200000.0   \n",
       "120  Implementation and integration of heterogeneou...   35000.0   50000.0   \n",
       "133  Knowledge of digital signal processing, image ...   75000.0  130000.0   \n",
       "134  Experience with integration of data from multi...  100000.0  130000.0   \n",
       "137  SENIOR DATA ENGINEER (Lead). Austin, TX – Seni...  120000.0  150000.0   \n",
       "138  Computer Science support to the research, deve...   79000.0       NaN   \n",
       "139  In this role you will be working across the SD...  120000.0  200000.0   \n",
       "149  Work with our data scientist on our cutting ed...   75000.0  115000.0   \n",
       "166  Fine-tuning sample preparation applications in...   95000.0  125000.0   \n",
       "167  Strong willingness to adhere to the security r...   86400.0       NaN   \n",
       "173  This is a Career Program (CP)-18, Engineers & ...   60210.0   93821.0   \n",
       "177  As a Computer Scientist, you may be part of a ...   68586.0   85464.0   \n",
       "195  For Data Analysis, Modeling and Theoretical Si...   72168.0  111560.0   \n",
       "218  Consulting Oportunities for Environmental scie...   40000.0   50000.0   \n",
       "228  Scikit-learn, SciPy, Apache Big Data Suite, op...   80000.0  160000.0   \n",
       "234  This engineer will work alongside data scienti...  140000.0  180000.0   \n",
       "274  -Supporting the development and implementation...   59708.0   65678.0   \n",
       "279  An interest in machine learning and/or data sc...   70000.0  110000.0   \n",
       "291  Our team of data scientists pioneered the fiel...   95000.0  130000.0   \n",
       "296  A rapidly growing media and online content dis...     140.0       NaN   \n",
       "309  Data Engineer, you will be responsible for hel...  125000.0  185000.0   \n",
       "322  Ability to plan and oversee the work of profes...   75515.0  115278.0   \n",
       "348  They are a leading investment data analysis fi...  200000.0  300000.0   \n",
       "372  Incorporation of technical data changes. Analy...   44899.0   86378.0   \n",
       "374  _ data pipelines at scale, and real-time proce...  100000.0       NaN   \n",
       "378  As a part of the Data Engineering team, the Da...   65000.0       NaN   \n",
       "379  Data Engineer’s efforts will span the data lif...   85000.0       NaN   \n",
       "401  We are looking for a passionate Data Scientist...  100000.0  135000.0   \n",
       "\n",
       "      Average             City                              State  \\\n",
       "14    75000.0          Chicago                                 IL   \n",
       "19   132500.0       Northbrook                                 IL   \n",
       "21   107500.0          Chicago                                 IL   \n",
       "22   120000.0          Chicago                                 IL   \n",
       "26    92500.0          Chicago                                 IL   \n",
       "29   122500.0          Chicago                                 IL   \n",
       "30    57500.0          Lombard                           IL 60148   \n",
       "31    95000.0          Chicago                                 IL   \n",
       "39   195000.0    San Francisco                                 CA   \n",
       "49    85000.0     Philadelphia                                 PA   \n",
       "55   112500.0     Philadelphia                                 PA   \n",
       "60   135000.0     Philadelphia                                 PA   \n",
       "64   110000.0     Philadelphia   PA 19107 (City Center East area)   \n",
       "66   145000.0     Philadelphia                                 PA   \n",
       "83    46788.5  Charlottesville                                 VA   \n",
       "110  195000.0           Reston                           VA 20190   \n",
       "120   42500.0          Herndon                                 VA   \n",
       "133  102500.0           Austin       TX 78758 (North Austin area)   \n",
       "134  115000.0           Austin                                 TX   \n",
       "137  135000.0           Austin                                 TX   \n",
       "138   79000.0           Austin          TX 78759 (Arboretum area)   \n",
       "139  160000.0           Austin                                 TX   \n",
       "149   95000.0          Atlanta                                 GA   \n",
       "166  110000.0          Atlanta                                 GA   \n",
       "167   86400.0          Atlanta                                 GA   \n",
       "173   77015.5          Memphis                                 TN   \n",
       "177   77025.0       Fort Meade                                 MD   \n",
       "195   91864.0          Hampton                                 VA   \n",
       "218   45000.0        Cleveland                                 OH   \n",
       "228  120000.0         Pasadena                                 CA   \n",
       "234  160000.0      Los Angeles                                 CA   \n",
       "274   62693.0           Queens                                 NY   \n",
       "279   90000.0         New York                                 NY   \n",
       "291  112500.0         New York                                 NY   \n",
       "296     140.0   New York State                                NaN   \n",
       "309  155000.0         New York                                 NY   \n",
       "322   95396.5           Laurel                           MD 20707   \n",
       "348  250000.0          Houston                                 TX   \n",
       "372   65638.5        San Diego                                 CA   \n",
       "374  100000.0        San Diego                                 CA   \n",
       "378   65000.0            Tampa                                 FL   \n",
       "379   85000.0            Tampa                                 FL   \n",
       "401  117500.0          Seattle                                 WA   \n",
       "\n",
       "    State Initials  Above Median  Senior  Manager  Engineer  \n",
       "14              IL             0       0        0         1  \n",
       "19              IL             1       1        0         1  \n",
       "21              IL             1       0        0         1  \n",
       "22              IL             1       0        0         1  \n",
       "26              IL             1       0        0         1  \n",
       "29              IL             1       1        0         1  \n",
       "30              IL             0       0        0         1  \n",
       "31              IL             1       1        0         1  \n",
       "39              CA             1       0        0         1  \n",
       "49              PA             0       0        0         1  \n",
       "55              PA             1       0        0         1  \n",
       "60              PA             1       0        0         1  \n",
       "64              PA             1       0        0         1  \n",
       "66              PA             1       1        0         1  \n",
       "83              VA             0       0        0         1  \n",
       "110             VA             1       1        0         1  \n",
       "120             VA             0       0        0         1  \n",
       "133             TX             1       0        0         1  \n",
       "134             TX             1       0        0         1  \n",
       "137             TX             1       1        0         1  \n",
       "138             TX             0       0        0         1  \n",
       "139             TX             1       0        0         1  \n",
       "149             GA             1       0        0         1  \n",
       "166             GA             1       0        0         1  \n",
       "167             GA             0       0        0         1  \n",
       "173             TN             0       0        0         1  \n",
       "177             MD             0       0        0         1  \n",
       "195             VA             1       0        0         1  \n",
       "218             OH             0       0        0         1  \n",
       "228             CA             1       0        0         1  \n",
       "234             CA             1       0        0         1  \n",
       "274             NY             0       0        0         1  \n",
       "279             NY             1       0        0         1  \n",
       "291             NY             1       0        0         1  \n",
       "296            NaN             0       0        0         1  \n",
       "309             NY             1       0        0         1  \n",
       "322             MD             1       0        0         1  \n",
       "348             TX             1       0        0         1  \n",
       "372             CA             0       0        0         1  \n",
       "374             CA             1       1        0         1  \n",
       "378             FL             0       0        0         1  \n",
       "379             FL             0       0        0         1  \n",
       "401             WA             1       0        0         1  "
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_more[df_more.Engineer != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_scientist(x):\n",
    "    if 'Data Scientist' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Data Scientist'] = df_more['Title'].apply(data_scientist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyst(x):\n",
    "    if 'Analyst' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Analyst'] = df_more['Title'].apply(analyst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assistant(x):\n",
    "    if 'Assistant' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Assistant'] = df_more['Title'].apply(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def internship(x):\n",
    "    if 'Intern' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Intern'] = df_more['Title'].apply(internship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def developer(x):\n",
    "    if 'Developer' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Developer'] = df_more['Title'].apply(developer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def machine_learning(x):\n",
    "    if 'Machine Learning' in x:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df_more['Machine Learning'] = df_more['Title'].apply(machine_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Senior</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Engineer</th>\n",
       "      <th>Data Scientist</th>\n",
       "      <th>Analyst</th>\n",
       "      <th>Assistant</th>\n",
       "      <th>Intern</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Machine Learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Senior  Manager  Engineer  Data Scientist  Analyst  Assistant  Intern  \\\n",
       "0       0        0         0               0        0          0       0   \n",
       "1       0        0         0               1        0          0       0   \n",
       "2       0        0         0               0        1          0       0   \n",
       "3       0        0         0               0        1          0       0   \n",
       "4       0        0         0               1        0          0       0   \n",
       "\n",
       "   Developer  Machine Learning  \n",
       "0          0                 0  \n",
       "1          0                 0  \n",
       "2          0                 0  \n",
       "3          0                 0  \n",
       "4          0                 0  "
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = df_more.copy(deep=True)\n",
    "feature_matrix.drop(['Title', 'Location', 'Company', 'Synopsis', 'Low', 'High', 'Average', 'City', 'State', 'Above Median', 'State Initials'], axis=1, inplace=True)\n",
    "print (feature_matrix.shape)\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.71014493  0.61764706  0.52941176  0.76470588  0.61764706  0.61764706]\n",
      "Average score: 0.642867291844\n",
      "Standard deviation of score: 0.0754445265306\n",
      "0.728606356968\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "X_features = pd.concat([df_city_dummy, feature_matrix, df_state_dummy], axis=1)\n",
    "y = df_more['Above Median']\n",
    "cv_model = cross_val_score(model, X_features, y, cv=6)\n",
    "print 'Cross-validated scores:', cv_model\n",
    "print 'Average score:', cv_model.mean()\n",
    "print 'Standard deviation of score:', cv_model.std()\n",
    "model.fit(X_features, y)\n",
    "print (model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in the key words ('Senior', 'Manager', 'Data Scientist', 'Analyst', 'Assistant', 'Intern', and 'Developer) brought the accuracy up from  50% to around 63%. Let's attempt to increase this by using a CountVectorizer on the title column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytics</th>\n",
       "      <th>assistant</th>\n",
       "      <th>associate</th>\n",
       "      <th>bureau</th>\n",
       "      <th>clinical</th>\n",
       "      <th>data</th>\n",
       "      <th>director</th>\n",
       "      <th>engineer</th>\n",
       "      <th>environmental</th>\n",
       "      <th>...</th>\n",
       "      <th>python</th>\n",
       "      <th>research</th>\n",
       "      <th>science</th>\n",
       "      <th>scientist</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>specialist</th>\n",
       "      <th>sr</th>\n",
       "      <th>statistical</th>\n",
       "      <th>statistician</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analyst  analytics  assistant  associate  bureau  clinical  data  director  \\\n",
       "0        0          0          0          0       0         0     0         0   \n",
       "1        0          1          0          0       0         0     1         0   \n",
       "2        1          0          0          0       0         0     0         0   \n",
       "3        1          0          0          0       0         0     0         0   \n",
       "4        0          0          0          0       0         0     1         0   \n",
       "\n",
       "   engineer  environmental      ...       python  research  science  \\\n",
       "0         0              1      ...            0         0        0   \n",
       "1         0              0      ...            0         0        0   \n",
       "2         0              0      ...            0         1        0   \n",
       "3         0              0      ...            0         1        0   \n",
       "4         0              0      ...            1         0        0   \n",
       "\n",
       "   scientist  senior  software  specialist  sr  statistical  statistician  \n",
       "0          0       0         0           0   0            0             0  \n",
       "1          1       0         0           0   0            0             0  \n",
       "2          0       0         0           0   0            0             0  \n",
       "3          0       0         0           0   0            0             0  \n",
       "4          1       0         0           0   0            0             0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(stop_words='english', max_features=30)\n",
    "vectorizers = cvec.fit_transform(df_more['Title']).toarray()\n",
    "\n",
    "df_vec  = pd.DataFrame(vectorizers, columns=cvec.get_feature_names())\n",
    "print (df_vec.shape)\n",
    "df_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytics</th>\n",
       "      <th>assistant</th>\n",
       "      <th>associate</th>\n",
       "      <th>bureau</th>\n",
       "      <th>clinical</th>\n",
       "      <th>data</th>\n",
       "      <th>director</th>\n",
       "      <th>engineer</th>\n",
       "      <th>environmental</th>\n",
       "      <th>...</th>\n",
       "      <th>NV</th>\n",
       "      <th>NY</th>\n",
       "      <th>OH</th>\n",
       "      <th>OR</th>\n",
       "      <th>PA</th>\n",
       "      <th>TN</th>\n",
       "      <th>TX</th>\n",
       "      <th>VA</th>\n",
       "      <th>WA</th>\n",
       "      <th>WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analyst  analytics  assistant  associate  bureau  clinical  data  director  \\\n",
       "0        0          0          0          0       0         0     0         0   \n",
       "1        0          1          0          0       0         0     1         0   \n",
       "2        1          0          0          0       0         0     0         0   \n",
       "3        1          0          0          0       0         0     0         0   \n",
       "4        0          0          0          0       0         0     1         0   \n",
       "\n",
       "   engineer  environmental ...    NV   NY   OH   OR   PA   TN   TX   VA   WA  \\\n",
       "0         0              1 ...     0    0    0    0    0    1    0    0    0   \n",
       "1         0              0 ...     0    0    0    0    0    0    0    0    0   \n",
       "2         0              0 ...     0    0    0    0    0    0    0    0    0   \n",
       "3         0              0 ...     0    0    0    0    0    0    0    0    0   \n",
       "4         0              0 ...     0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "    WI  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cvec = pd.concat([df_vec, df_city_dummy, df_state_dummy], axis=1)\n",
    "X_cvec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.73913043  0.67647059  0.64705882  0.77941176  0.58823529  0.57352941]\n",
      "Average score: 0.667306052856\n",
      "Standard deviation of score: 0.0744609682702\n",
      "0.738386308068\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.081306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.064954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>0.048287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst</th>\n",
       "      <td>0.042719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>0.020502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior</th>\n",
       "      <td>0.018584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>0.017347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>0.016853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sr</th>\n",
       "      <td>0.016421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>0.016151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           importance\n",
       "data         0.081306\n",
       "research     0.064954\n",
       "scientist    0.048287\n",
       "analyst      0.042719\n",
       "engineer     0.020502\n",
       "senior       0.018584\n",
       " AZ          0.017347\n",
       " CA          0.016853\n",
       "sr           0.016421\n",
       "learning     0.016151"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "y = df_more['Above Median']\n",
    "cv_model = cross_val_score(model, X_cvec, y, cv=6)\n",
    "print 'Cross-validated scores:', cv_model\n",
    "print 'Average score:', cv_model.mean()\n",
    "print 'Standard deviation of score:', cv_model.std()\n",
    "model.fit(X_cvec, y)\n",
    "print (model.oob_score_)\n",
    "importance_dataframe = pd.DataFrame(model.feature_importances_, index = X_cvec.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "importance_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the count vectorizer (and a max of 30 new word features) has increased our accuracy to around 67%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "source": [
    "The code above contains cross-validated accuracy scores for each model. The Random Forest Classifier with the description words Count Vectorized and the location dummies has an average accuracy score of 67%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process with a non-tree-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.71014493  0.64705882  0.52941176  0.79411765  0.61764706  0.63235294]\n",
      "Average score: 0.655122193805\n",
      "Standard deviation of score: 0.0817905778845\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "scores_log = cross_val_score(log_reg, X_cvec, y, cv=6)\n",
    "print 'Cross-validated scores:', scores_log\n",
    "print 'Average score:', scores_log.mean()\n",
    "print 'Standard deviation of score:', scores_log.std()\n",
    "log_model = log_reg.fit(X_cvec, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression gets an average accuracy score of 65%, which isn't that much worse than our Random Forest Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.76811594  0.64705882  0.55882353  0.77941176  0.73529412  0.64705882]\n",
      "Average score: 0.689293833475\n",
      "Standard deviation of score: 0.0785708648744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svmrbf = SVC(kernel='rbf')\n",
    "scores_svm = cross_val_score(model_svmrbf, X_cvec, y, cv=6)\n",
    "print 'Cross-validated scores:', scores_svm\n",
    "print 'Average score:', scores_svm.mean()\n",
    "print 'Standard deviation of score:', scores_svm.std()\n",
    "svm_model = model_svmrbf.fit(X_cvec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.69565217  0.55882353  0.42647059  0.75        0.61764706  0.66176471]\n",
      "Average score: 0.618393009378\n",
      "Standard deviation of score: 0.104525736596\n"
     ]
    }
   ],
   "source": [
    "model_svmlm = SVC(kernel='linear')\n",
    "scores_svmlm = cross_val_score(model_svmlm, X_cvec, y, cv=6)\n",
    "print 'Cross-validated scores:', scores_svmlm\n",
    "print 'Average score:', scores_svmlm.mean()\n",
    "print 'Standard deviation of score:', scores_svmlm.std()\n",
    "svm_model = model_svmlm.fit(X_cvec, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The radial basis kernel support vector machine performs better than the linear kernel support vector machine. The RBF SVM gets an accuracy score of 69%. This is higher than our Random Forest Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68948655256723712"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-3, hidden_layer_sizes=(100,), random_state=1, activation='relu')\n",
    "clf.fit(feature_matrix, y)\n",
    "clf.score(feature_matrix, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.73913043  0.58823529  0.47058824  0.73529412  0.67647059  0.64705882]\n",
      "Average score: 0.642796248934\n",
      "Standard deviation of score: 0.0927548377008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_cvec, y)\n",
    "cv_model = cross_val_score(clf, X_cvec, y, cv=6)\n",
    "print 'Cross-validated scores:', cv_model\n",
    "print 'Average score:', cv_model.mean()\n",
    "print 'Standard deviation of score:', cv_model.std()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.76811594  0.75        0.63235294  0.77941176  0.61764706  0.63235294]\n",
      "Average score: 0.696646774652\n",
      "Standard deviation of score: 0.069896114897\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(booster='gbtree')\n",
    "cv_model = cross_val_score(model, X_cvec, y, cv=6)\n",
    "print 'Cross-validated scores:', cv_model\n",
    "print 'Average score:', cv_model.mean()\n",
    "print 'Standard deviation of score:', cv_model.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the job descriptions. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>analysis</th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytics</th>\n",
       "      <th>analyze</th>\n",
       "      <th>analyzing</th>\n",
       "      <th>big</th>\n",
       "      <th>client</th>\n",
       "      <th>clinical</th>\n",
       "      <th>collection</th>\n",
       "      <th>...</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>statistical</th>\n",
       "      <th>team</th>\n",
       "      <th>technical</th>\n",
       "      <th>use</th>\n",
       "      <th>using</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  analysis  analyst  analytics  analyze  analyzing  big  client  \\\n",
       "0        0         0        0          0        0          0    0       0   \n",
       "1        0         0        0          1        0          0    0       0   \n",
       "2        0         0        0          0        0          0    0       0   \n",
       "3        1         0        0          0        1          1    0       0   \n",
       "4        0         0        0          0        0          0    0       1   \n",
       "\n",
       "   clinical  collection  ...    senior  software  statistical  team  \\\n",
       "0         0           0  ...         0         0            0     0   \n",
       "1         0           0  ...         0         0            0     1   \n",
       "2         0           0  ...         0         0            0     0   \n",
       "3         0           0  ...         0         1            1     0   \n",
       "4         0           0  ...         0         1            0     0   \n",
       "\n",
       "   technical  use  using  work  working  years  \n",
       "0          0    0      0     0        0      1  \n",
       "1          0    0      0     0        0      0  \n",
       "2          0    0      0     0        0      0  \n",
       "3          0    0      2     0        0      0  \n",
       "4          0    0      0     0        1      0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_synos = CountVectorizer(stop_words='english', max_features=50)\n",
    "vectorizers_synos = cvec_synos.fit_transform(df_more['Synopsis']).toarray()\n",
    "df_vec_synos  = pd.DataFrame(vectorizers_synos, columns=cvec_synos.get_feature_names())\n",
    "print (df_vec_synos.shape)\n",
    "df_vec_synos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytics</th>\n",
       "      <th>assistant</th>\n",
       "      <th>associate</th>\n",
       "      <th>bureau</th>\n",
       "      <th>clinical</th>\n",
       "      <th>data</th>\n",
       "      <th>director</th>\n",
       "      <th>engineer</th>\n",
       "      <th>environmental</th>\n",
       "      <th>...</th>\n",
       "      <th>senior</th>\n",
       "      <th>software</th>\n",
       "      <th>statistical</th>\n",
       "      <th>team</th>\n",
       "      <th>technical</th>\n",
       "      <th>use</th>\n",
       "      <th>using</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analyst  analytics  assistant  associate  bureau  clinical  data  director  \\\n",
       "0        0          0          0          0       0         0     0         0   \n",
       "1        0          1          0          0       0         0     1         0   \n",
       "2        1          0          0          0       0         0     0         0   \n",
       "3        1          0          0          0       0         0     0         0   \n",
       "4        0          0          0          0       0         0     1         0   \n",
       "\n",
       "   engineer  environmental  ...    senior  software  statistical  team  \\\n",
       "0         0              1  ...         0         0            0     0   \n",
       "1         0              0  ...         0         0            0     1   \n",
       "2         0              0  ...         0         0            0     0   \n",
       "3         0              0  ...         0         1            1     0   \n",
       "4         0              0  ...         0         1            0     0   \n",
       "\n",
       "   technical  use  using  work  working  years  \n",
       "0          0    0      0     0        0      1  \n",
       "1          0    0      0     0        0      0  \n",
       "2          0    0      0     0        0      0  \n",
       "3          0    0      2     0        0      0  \n",
       "4          0    0      0     0        1      0  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cvec_synos = pd.concat([df_vec, df_city_dummy, df_state_dummy, df_vec_synos], axis=1)\n",
    "X_cvec_synos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 236)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cvec_synos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753056234719\n",
      "Cross-validated scores: [ 0.76811594  0.70588235  0.63235294  0.80882353  0.69117647  0.72058824]\n",
      "Average score: 0.721156578573\n",
      "Standard deviation of score: 0.0561385101897\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.049201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.043424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.035142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>0.028058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst</th>\n",
       "      <td>0.024330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>0.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientists</th>\n",
       "      <td>0.020927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking</th>\n",
       "      <td>0.018494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis</th>\n",
       "      <td>0.015077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>0.014487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analytics</th>\n",
       "      <td>0.013385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>0.012766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>0.012581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0.011967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>0.010912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.010146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <td>0.010076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>0.010047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development</th>\n",
       "      <td>0.009973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0.009848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             importance\n",
       "research       0.049201\n",
       "data           0.043424\n",
       "data           0.035142\n",
       "scientist      0.028058\n",
       "analyst        0.024330\n",
       "scientist      0.023333\n",
       "scientists     0.020927\n",
       "looking        0.018494\n",
       "analysis       0.015077\n",
       " DC            0.014487\n",
       "analytics      0.013385\n",
       "learning       0.012766\n",
       " CA            0.012581\n",
       "science        0.011967\n",
       "learning       0.010912\n",
       "research       0.010146\n",
       "machine        0.010076\n",
       "engineer       0.010047\n",
       "development    0.009973\n",
       "work           0.009848"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "y = df_more['Above Median']\n",
    "model.fit(X_cvec_synos, y)\n",
    "print (model.oob_score_)\n",
    "cv_model = cross_val_score(model, X_cvec_synos, y, cv=6)\n",
    "print 'Cross-validated scores:', cv_model\n",
    "print 'Average score:', cv_model.mean()\n",
    "print 'Standard deviation of score:', cv_model.std()\n",
    "importance_dataframe_big = pd.DataFrame(model.feature_importances_, index = X_cvec_synos.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "importance_dataframe_big.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the countvectorizer on the description, the accuracy of the model has increased from 70% to about 72%. That isn't a huge gain in accuracy and it is evident that the small sample size of 409 observations is hurting the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.75362319  0.67647059  0.54411765  0.75        0.66176471  0.64705882]\n",
      "Average score: 0.672172492185\n",
      "Standard deviation of score: 0.0705299844588\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "log_model = log_reg.fit(X_cvec_synos, y)\n",
    "scores_log = cross_val_score(log_reg, X_cvec_synos, y, cv=6)\n",
    "print 'Cross-validated scores:', scores_log\n",
    "print 'Average score:', scores_log.mean()\n",
    "print 'Standard deviation of score:', scores_log.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.82608696  0.66176471  0.63235294  0.76470588  0.66176471  0.75      ]\n",
      "Average score: 0.716112531969\n",
      "Standard deviation of score: 0.0689529908672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_svmrbf = SVC(kernel='rbf')\n",
    "scores_svm = cross_val_score(model_svmrbf, X_cvec_synos, y, cv=6)\n",
    "print 'Cross-validated scores:', scores_svm\n",
    "print 'Average score:', scores_svm.mean()\n",
    "print 'Standard deviation of score:', scores_svm.std()\n",
    "svm_model = model_svmrbf.fit(X_cvec_synos, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RBF kernel SVM gets 72% accuracy. That is the highest we have seen so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
